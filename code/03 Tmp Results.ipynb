{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94d9739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from predunder.functions import convert_labels, get_metrics, kfold_metrics_to_df, df_to_nparray\n",
    "from predunder.training import train_random_forest, train_xgboost, train_dnn, train_kfold, train_nnrf\n",
    "from predunder.hypertuning import tune_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a5d8c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../train-test-data'\n",
    "NUM_FOLDS = 10\n",
    "TASK_TO_RUN = '2aii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ff1dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_DIR, f'{TASK_TO_RUN}_train.csv'), index_col=0)\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, f'{TASK_TO_RUN}_test.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a935fb90",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a254b5c8",
   "metadata": {},
   "source": [
    "We want to tune the following parameters\n",
    "- `n_estimators`\n",
    "- `max_depth`\n",
    "- `min_samples_split`\n",
    "- `min_samples_leaf`\n",
    "- `bootstrap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c32e74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.04062695205627563.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.10706514684679477.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.08571743291211732.\n",
      "\n",
      "Starting parameters 3...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 3: 0.10269287728042623.\n",
      "\n",
      "Starting parameters 4...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 4: 0.023330128867548653.\n",
      "\n",
      "Starting parameters 5...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# tune oversample technique\u001b[39;00m\n\u001b[0;32m      2\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moversample\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmote\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madasyn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mborderline\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m500\u001b[39m]\n\u001b[0;32m      5\u001b[0m }\n\u001b[1;32m----> 7\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mtune_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTASK_TO_RUN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_FOLDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_random_forest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m best_params\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\src\\predunder\\hypertuning.py:29\u001b[0m, in \u001b[0;36mtune_model\u001b[1;34m(train, label, folds, train_func, param_grid)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, params \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mlist\u001b[39m(ParameterGrid(param_grid))):\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting parameters \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m train_kfold(train, label, folds, train_func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m     30\u001b[0m     score \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKAPPA\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMEAN\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m best_score \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m score:\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\src\\predunder\\training.py:229\u001b[0m, in \u001b[0;36mtrain_kfold\u001b[1;34m(train_set, label, num_fold, train_func, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m predicted \u001b[38;5;241m=\u001b[39m train_func(train, test, label, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    230\u001b[0m accuracy, sensitivity, specificity, kappa \u001b[38;5;241m=\u001b[39m get_metrics(predicted, convert_labels(test[label]))\n\u001b[0;32m    232\u001b[0m acc_per_fold\u001b[38;5;241m.\u001b[39mappend(accuracy)\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\src\\predunder\\training.py:43\u001b[0m, in \u001b[0;36mtrain_random_forest\u001b[1;34m(train, test, label, oversample, to_normalize, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m normalize(X_train)\n\u001b[0;32m     41\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m normalize(X_test)\n\u001b[1;32m---> 43\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m predicted \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\sklearn\\tree\\_classes.py:224\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_classification:\n\u001b[1;32m--> 224\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(y)\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\sklearn\\utils\\multiclass.py:199\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_classification_targets\u001b[39m(y):\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Ensure that target y is of a non-regression type.\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m    Only the following target types (as defined in type_of_target) are allowed:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m        Target values.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    206\u001b[0m     ]:\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\sklearn\\utils\\multiclass.py:363\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;66;03m# Check multiclass\u001b[39;00m\n\u001b[0;32m    362\u001b[0m first_row \u001b[38;5;241m=\u001b[39m y[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(y) \u001b[38;5;28;01melse\u001b[39;00m y\u001b[38;5;241m.\u001b[39mgetrow(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(first_row) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;66;03m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\sklearn\\utils\\_array_api.py:84\u001b[0m, in \u001b[0;36m_NumPyApiWrapper.unique_values\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[0;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tune oversample technique\n",
    "param_grid = {\n",
    "    'oversample': ['none', 'smote', 'adasyn', 'borderline'],\n",
    "    'n_estimators': [200, 500]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_random_forest, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54e6e603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.13341770297580113.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.12792432946384147.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.12356964966088586.\n",
      "\n",
      "Starting parameters 3...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 3: 0.1258576135105512.\n",
      "\n",
      "Starting parameters 4...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 4: 0.0950146230275177.\n",
      "\n",
      "Starting parameters 5...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 5: 0.07240115698414722.\n",
      "\n",
      "Starting parameters 6...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 6: 0.0856788512705596.\n",
      "\n",
      "Starting parameters 7...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 7: 0.0881819200212625.\n",
      "\n",
      "Starting parameters 8...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 8: 0.11284924992622333.\n",
      "\n",
      "Starting parameters 9...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 9: 0.052771698542014.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100, 'oversample': 'adasyn'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune number of estimators\n",
    "param_grid = {\n",
    "    'oversample': ['adasyn'],\n",
    "    'n_estimators': [int(x) for x in np.linspace(100, 1000, num=10)]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_random_forest, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9ecc736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.20917984605594048.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.13668945981517083.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.14744170176770957.\n",
      "\n",
      "Starting parameters 3...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 3: 0.09043059452717707.\n",
      "\n",
      "Starting parameters 4...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 4: 0.08857889769932759.\n",
      "\n",
      "Starting parameters 5...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 5: 0.10109550507878429.\n",
      "\n",
      "Starting parameters 6...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 6: 0.14918777104427822.\n",
      "\n",
      "Starting parameters 7...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 7: 0.031244624486987015.\n",
      "\n",
      "Starting parameters 8...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 8: 0.1455180430551278.\n",
      "\n",
      "Starting parameters 9...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 9: 0.08648534742939877.\n",
      "\n",
      "Starting parameters 10...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 10: 0.16459506994773374.\n",
      "\n",
      "Starting parameters 11...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 11: 0.11520855815408441.\n",
      "\n",
      "Starting parameters 12...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 12: 0.060960486292449614.\n",
      "\n",
      "Starting parameters 13...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 13: 0.10246154165544756.\n",
      "\n",
      "Starting parameters 14...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 14: 0.09884953217581009.\n",
      "\n",
      "Starting parameters 15...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 15: 0.09292847425448214.\n",
      "\n",
      "Starting parameters 16...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 16: 0.08430189988238979.\n",
      "\n",
      "Starting parameters 17...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 17: 0.09182244458258884.\n",
      "\n",
      "Starting parameters 18...\n",
      "Starting fold 1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 18: 0.1224830157068788.\n",
      "\n",
      "Starting parameters 19...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 19: 0.09911123039109312.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2, 'n_estimators': 100, 'oversample': 'adasyn'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune max depth\n",
    "param_grid = {\n",
    "    'oversample': ['adasyn'],\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [int(x) for x in np.linspace(2, 100, num=20)]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_random_forest, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ca7bb3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.2022010808700218.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.18890667667574768.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.18460107447889237.\n",
      "\n",
      "Starting parameters 3...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 3: 0.18663002280460692.\n",
      "\n",
      "Starting parameters 4...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 4: 0.19087791645667335.\n",
      "\n",
      "Starting parameters 5...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 5: 0.16889375920706878.\n",
      "\n",
      "Starting parameters 6...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 6: 0.16763026695063243.\n",
      "\n",
      "Starting parameters 7...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 7: 0.19313035968937142.\n",
      "\n",
      "Starting parameters 8...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 8: 0.1680262046440773.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100,\n",
       " 'oversample': 'adasyn'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune minimum number of samples to split a node and leaf\n",
    "param_grid = {\n",
    "    'oversample': ['adasyn'],\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [2],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_random_forest, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31ffd5b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.20385606959092706.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.20498593591528347.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100,\n",
       " 'oversample': 'adasyn'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune bootstrap\n",
    "param_grid = {\n",
    "    'oversample': ['adasyn'],\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [2],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_random_forest, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e59fd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.66996699669967, 0.656, 0.7358490566037735, 0.25523547340477826)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'bootstrap': False,\n",
    "    'max_depth': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'min_samples_split': 2,\n",
    "    'n_estimators': 100,\n",
    "    'oversample': 'adasyn'\n",
    "}\n",
    "\n",
    "predicted = train_random_forest(train_df, test_df, TASK_TO_RUN, **params)\n",
    "accuracy, sensitivity, specificity, kappa = get_metrics(predicted, convert_labels(test_df[TASK_TO_RUN]))\n",
    "accuracy, sensitivity, specificity, kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caba875c",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a11407f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.044838674772856704.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# tune oversampling\u001b[39;00m\n\u001b[0;32m      2\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moversample\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmote\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madasyn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mborderline\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m500\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale_pos_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     12\u001b[0m }\n\u001b[1;32m---> 14\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mtune_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTASK_TO_RUN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_FOLDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_xgboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m best_params\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\src\\predunder\\hypertuning.py:29\u001b[0m, in \u001b[0;36mtune_model\u001b[1;34m(train, label, folds, train_func, param_grid)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, params \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mlist\u001b[39m(ParameterGrid(param_grid))):\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting parameters \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m train_kfold(train, label, folds, train_func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m     30\u001b[0m     score \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKAPPA\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMEAN\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m best_score \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m score:\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\src\\predunder\\training.py:229\u001b[0m, in \u001b[0;36mtrain_kfold\u001b[1;34m(train_set, label, num_fold, train_func, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m predicted \u001b[38;5;241m=\u001b[39m train_func(train, test, label, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    230\u001b[0m accuracy, sensitivity, specificity, kappa \u001b[38;5;241m=\u001b[39m get_metrics(predicted, convert_labels(test[label]))\n\u001b[0;32m    232\u001b[0m acc_per_fold\u001b[38;5;241m.\u001b[39mappend(accuracy)\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\src\\predunder\\training.py:76\u001b[0m, in \u001b[0;36mtrain_xgboost\u001b[1;34m(train, test, label, oversample, to_normalize, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m normalize(X_train)\n\u001b[0;32m     74\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m normalize(X_test)\n\u001b[1;32m---> 76\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m predicted \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\xgboost\\sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1462\u001b[0m (\n\u001b[0;32m   1463\u001b[0m     model,\n\u001b[0;32m   1464\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1470\u001b[0m )\n\u001b[0;32m   1471\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1472\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1473\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1488\u001b[0m )\n\u001b[1;32m-> 1490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tune oversampling\n",
    "param_grid = {\n",
    "    'oversample': ['none', 'smote', 'adasyn', 'borderline'],\n",
    "    'n_estimators': [200, 500],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [5],\n",
    "    'min_child_weight': [1],\n",
    "    'gamma': [0],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'scale_pos_weight': [1]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_xgboost, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "922da8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.1332436984377238.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.17573551563595052.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.1695822800047609.\n",
      "\n",
      "Starting parameters 3...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 3: 0.18983031579894932.\n",
      "\n",
      "Starting parameters 4...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 4: 0.13440494878797474.\n",
      "\n",
      "Starting parameters 5...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 5: 0.2150854886302696.\n",
      "\n",
      "Starting parameters 6...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 6: 0.05454847979928903.\n",
      "\n",
      "Starting parameters 7...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 7: 0.06383664137650859.\n",
      "\n",
      "Starting parameters 8...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 8: 0.09801105965603714.\n",
      "\n",
      "Starting parameters 9...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 9: 0.13384324342296997.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8,\n",
       " 'gamma': 0,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'n_estimators': 322,\n",
       " 'oversample': 'borderline',\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune number of estimators\n",
    "param_grid = {\n",
    "    'oversample': ['borderline'],\n",
    "    'n_estimators': [int(x) for x in np.linspace(100, 500, num=10)],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [5],\n",
    "    'min_child_weight': [1],\n",
    "    'gamma': [0],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'scale_pos_weight': [1]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_xgboost, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15efea8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.16817914589442104.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.1793521161458721.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.1919756584277849.\n",
      "\n",
      "Starting parameters 3...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 3: 0.16888261957650666.\n",
      "\n",
      "Starting parameters 4...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 4: 0.08801491127260228.\n",
      "\n",
      "Starting parameters 5...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 5: 0.05391216100309948.\n",
      "\n",
      "Starting parameters 6...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 6: 0.06344271470623043.\n",
      "\n",
      "Starting parameters 7...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 7: 0.16234989932964214.\n",
      "\n",
      "Starting parameters 8...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 8: 0.10283928475348633.\n",
      "\n",
      "Starting parameters 9...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 9: 0.08095691696450949.\n",
      "\n",
      "Starting parameters 10...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 10: 0.07641686578376697.\n",
      "\n",
      "Starting parameters 11...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 11: 0.12507777133071157.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8,\n",
       " 'gamma': 0,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 5,\n",
       " 'n_estimators': 322,\n",
       " 'oversample': 'borderline',\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune depth and weight\n",
    "param_grid = {\n",
    "    'oversample': ['borderline'],\n",
    "    'n_estimators': [322],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': range(2,10,2),\n",
    "    'min_child_weight': range(1,6,2),\n",
    "    'gamma': [0],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'scale_pos_weight': [1]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_xgboost, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79533313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.1645762486599897.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.1834455292199334.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.169322216927015.\n",
      "\n",
      "Starting parameters 3...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 3: 0.1013340757297011.\n",
      "\n",
      "Starting parameters 4...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 4: 0.19141368445429843.\n",
      "\n",
      "Starting parameters 5...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 5: 0.17094045203060676.\n",
      "\n",
      "Starting parameters 6...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 6: 0.11296366486721823.\n",
      "\n",
      "Starting parameters 7...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 7: 0.15291797987986153.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8,\n",
       " 'gamma': 0,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 13,\n",
       " 'n_estimators': 322,\n",
       " 'oversample': 'borderline',\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune minimum child weight\n",
    "param_grid = {\n",
    "    'oversample': ['borderline'],\n",
    "    'n_estimators': [322],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [2],\n",
    "    'min_child_weight': range(5,20,2),\n",
    "    'gamma': [0],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'scale_pos_weight': [1]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_xgboost, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b408c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.11453419064394903.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.18229823372190862.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.16879946989716857.\n",
      "\n",
      "Starting parameters 3...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 3: 0.16887423665129148.\n",
      "\n",
      "Starting parameters 4...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 4: 0.16462076302103737.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8,\n",
       " 'gamma': 0.1,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 13,\n",
       " 'n_estimators': 322,\n",
       " 'oversample': 'borderline',\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune gamma\n",
    "param_grid = {\n",
    "    'oversample': ['borderline'],\n",
    "    'n_estimators': [322],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [2],\n",
    "    'min_child_weight': [13],\n",
    "    'gamma': [i/10 for i in range(5)],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'scale_pos_weight': [1]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_xgboost, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2333758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.1412499189776677.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.16454171109878163.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.1270477151241048.\n",
      "\n",
      "Starting parameters 3...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 3: 0.15604050189405702.\n",
      "\n",
      "Starting parameters 4...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 4: 0.15038558265051888.\n",
      "\n",
      "Starting parameters 5...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 5: 0.1437900578207597.\n",
      "\n",
      "Starting parameters 6...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 6: 0.16458167717299235.\n",
      "\n",
      "Starting parameters 7...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 7: 0.1757980023229508.\n",
      "\n",
      "Starting parameters 8...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 8: 0.13329838022644258.\n",
      "\n",
      "Starting parameters 9...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 9: 0.2239510851781063.\n",
      "\n",
      "Starting parameters 10...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 10: 0.11497964503489015.\n",
      "\n",
      "Starting parameters 11...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 11: 0.16658118636200453.\n",
      "\n",
      "Starting parameters 12...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 12: 0.10148708414174097.\n",
      "\n",
      "Starting parameters 13...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 13: 0.11282710308618207.\n",
      "\n",
      "Starting parameters 14...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 14: 0.1439035401006521.\n",
      "\n",
      "Starting parameters 15...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 15: 0.14984322178979387.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8,\n",
       " 'gamma': 0.1,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 13,\n",
       " 'n_estimators': 322,\n",
       " 'oversample': 'borderline',\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune subsample and colsample\n",
    "param_grid = {\n",
    "    'oversample': ['borderline'],\n",
    "    'n_estimators': [322],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [2],\n",
    "    'min_child_weight': [13],\n",
    "    'gamma': [0.1],\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "    'scale_pos_weight': [1]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_xgboost, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6060479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.1089182173551975.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.15950843569253667.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.14650354217756073.\n",
      "\n",
      "Starting parameters 3...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 3: 0.15387235855751452.\n",
      "\n",
      "Starting parameters 4...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 4: 0.1281363048002456.\n",
      "\n",
      "Starting parameters 5...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 5: 0.1346675910477231.\n",
      "\n",
      "Starting parameters 6...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 6: 0.12516301633958887.\n",
      "\n",
      "Starting parameters 7...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 7: 0.11324366470327112.\n",
      "\n",
      "Starting parameters 8...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 8: 0.14762959104118206.\n",
      "\n",
      "Starting parameters 9...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 9: 0.17141471525741006.\n",
      "\n",
      "Starting parameters 10...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 10: 0.1864367734475594.\n",
      "\n",
      "Starting parameters 11...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 11: 0.16350451650520595.\n",
      "\n",
      "Starting parameters 12...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 12: 0.15267127412595322.\n",
      "\n",
      "Starting parameters 13...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 13: 0.16025075535465333.\n",
      "\n",
      "Starting parameters 14...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 14: 0.10452920395240342.\n",
      "\n",
      "Starting parameters 15...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 15: 0.15957523720434438.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8,\n",
       " 'gamma': 0.1,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 13,\n",
       " 'n_estimators': 322,\n",
       " 'oversample': 'borderline',\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune subsample and colsample\n",
    "param_grid = {\n",
    "    'oversample': ['borderline'],\n",
    "    'n_estimators': [322],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [2],\n",
    "    'min_child_weight': [13],\n",
    "    'gamma': [0.1],\n",
    "    'subsample':[i/100 for i in range(60,80,5)],\n",
    "    'colsample_bytree':[i/100 for i in range(70,90,5)],\n",
    "    'scale_pos_weight': [1]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_xgboost, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3388bae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.1331789730048561.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.12740602972013743.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.11542642711493464.\n",
      "\n",
      "Starting parameters 3...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 3: 0.1684215449500725.\n",
      "\n",
      "Starting parameters 4...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 4: 0.0.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8,\n",
       " 'gamma': 0.1,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 13,\n",
       " 'n_estimators': 322,\n",
       " 'oversample': 'borderline',\n",
       " 'reg_alpha': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune regularization\n",
    "param_grid = {\n",
    "    'oversample': ['borderline'],\n",
    "    'n_estimators': [322],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [2],\n",
    "    'min_child_weight': [13],\n",
    "    'gamma': [0.1],\n",
    "    'subsample':[0.7],\n",
    "    'colsample_bytree':[0.8],\n",
    "    'scale_pos_weight': [1],\n",
    "    'reg_alpha': [1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_xgboost, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01dcddc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.16900459216205882.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.19942025042218314.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.15741753359172983.\n",
      "\n",
      "Starting parameters 3...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 3: 0.17604520735209286.\n",
      "\n",
      "Starting parameters 4...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 4: 0.16547032308712223.\n",
      "\n",
      "Starting parameters 5...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 5: 0.16044718748301795.\n",
      "\n",
      "Starting parameters 6...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 6: 0.17687465140074324.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8,\n",
       " 'gamma': 0.1,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 13,\n",
       " 'n_estimators': 322,\n",
       " 'oversample': 'borderline',\n",
       " 'reg_alpha': 0.5,\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune regularization\n",
    "param_grid = {\n",
    "    'oversample': ['borderline'],\n",
    "    'n_estimators': [322],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [2],\n",
    "    'min_child_weight': [13],\n",
    "    'gamma': [0.1],\n",
    "    'subsample':[0.7],\n",
    "    'colsample_bytree':[0.8],\n",
    "    'scale_pos_weight': [1],\n",
    "    'reg_alpha': [0.3, 0.5, 0.8, 1, 3, 5, 8]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_xgboost, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "642bcef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.17887555863145313.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8,\n",
       " 'gamma': 0.1,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 13,\n",
       " 'n_estimators': 322,\n",
       " 'oversample': 'borderline',\n",
       " 'reg_alpha': 0.5,\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lower learning rate\n",
    "param_grid = {\n",
    "    'oversample': ['borderline'],\n",
    "    'n_estimators': [322],\n",
    "    'learning_rate': [0.01],\n",
    "    'max_depth': [2],\n",
    "    'min_child_weight': [13],\n",
    "    'gamma': [0.1],\n",
    "    'subsample':[0.7],\n",
    "    'colsample_bytree':[0.8],\n",
    "    'scale_pos_weight': [1],\n",
    "    'reg_alpha': [0.5]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_xgboost, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60df1800",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7128712871287128, 0.76, 0.49056603773584906, 0.20120602405987692)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "'colsample_bytree': 0.8,\n",
    "'gamma': 0.1,\n",
    "'learning_rate': 0.01,\n",
    "'max_depth': 2,\n",
    "'min_child_weight': 13,\n",
    "'n_estimators': 322,\n",
    "'oversample': 'borderline',\n",
    "'reg_alpha': 0.5,\n",
    "'scale_pos_weight': 1,\n",
    "'subsample': 0.7\n",
    "}\n",
    "\n",
    "predicted = train_xgboost(train_df, test_df, TASK_TO_RUN, **params)\n",
    "accuracy, sensitivity, specificity, kappa = get_metrics(predicted, convert_labels(test_df[TASK_TO_RUN]))\n",
    "accuracy, sensitivity, specificity, kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd4fb6b",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1d889e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['CHILD_SEX',\n",
       "  'IDD_SCORE',\n",
       "  'AGE',\n",
       "  'HHID_count',\n",
       "  'HH_AGE',\n",
       "  'FOOD_EXPENSE_WEEKLY',\n",
       "  'NON-FOOD_EXPENSE_WEEKLY',\n",
       "  'HDD_SCORE',\n",
       "  'FOOD_INSECURITY',\n",
       "  'YoungBoys',\n",
       "  'YoungGirls',\n",
       "  'AverageMonthlyIncome',\n",
       "  'BEN_4PS',\n",
       "  'AREA_TYPE',\n",
       "  'FOOD_EXPENSE_WEEKLY_pc',\n",
       "  'NON-FOOD_EXPENSE_WEEKLY_pc',\n",
       "  'AverageMonthlyIncome_pc'],)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.drop([TASK_TO_RUN], axis=1).columns.tolist(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4bde233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Epoch 1/30\n",
      "28/28 [==============================] - 1s 13ms/step - loss: 16.3684 - accuracy: 0.6359 - true_positives_2: 129.0000 - true_negatives_2: 9.0000 - false_positives_2: 28.0000 - false_negatives_2: 51.0000 - val_loss: 5.5961 - val_accuracy: 0.5273 - val_true_positives_2: 25.0000 - val_true_negatives_2: 4.0000 - val_false_positives_2: 6.0000 - val_false_negatives_2: 20.0000\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4702 - accuracy: 0.5300 - true_positives_2: 99.0000 - true_negatives_2: 16.0000 - false_positives_2: 21.0000 - false_negatives_2: 81.0000 - val_loss: 0.6894 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.6799 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6759 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.6719 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.6638 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.6563 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.6492 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.6421 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.6351 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.6287 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.6225 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.6173 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.6115 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.6060 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.6006 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.5954 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.5908 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.5862 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.5820 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.5782 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.5739 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.5702 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.5661 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.5623 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.5586 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.5553 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.5514 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 28/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.5482 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 29/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.5449 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "Epoch 30/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.8295 - true_positives_2: 180.0000 - true_negatives_2: 0.0000e+00 - false_positives_2: 37.0000 - false_negatives_2: 0.0000e+00 - val_loss: 0.5418 - val_accuracy: 0.8182 - val_true_positives_2: 45.0000 - val_true_negatives_2: 0.0000e+00 - val_false_positives_2: 10.0000 - val_false_negatives_2: 0.0000e+00\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Epoch 1/30\n",
      "28/28 [==============================] - 1s 11ms/step - loss: 1.2300 - accuracy: 0.7880 - true_positives_3: 166.0000 - true_negatives_3: 5.0000 - false_positives_3: 32.0000 - false_negatives_3: 14.0000 - val_loss: 1.0839 - val_accuracy: 0.8364 - val_true_positives_3: 46.0000 - val_true_negatives_3: 0.0000e+00 - val_false_positives_3: 9.0000 - val_false_negatives_3: 0.0000e+00\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.8295 - true_positives_3: 180.0000 - true_negatives_3: 0.0000e+00 - false_positives_3: 37.0000 - false_negatives_3: 0.0000e+00 - val_loss: 1.2055 - val_accuracy: 0.8364 - val_true_positives_3: 46.0000 - val_true_negatives_3: 0.0000e+00 - val_false_positives_3: 9.0000 - val_false_negatives_3: 0.0000e+00\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.8295 - true_positives_3: 180.0000 - true_negatives_3: 0.0000e+00 - false_positives_3: 37.0000 - false_negatives_3: 0.0000e+00 - val_loss: 0.6335 - val_accuracy: 0.8364 - val_true_positives_3: 46.0000 - val_true_negatives_3: 0.0000e+00 - val_false_positives_3: 9.0000 - val_false_negatives_3: 0.0000e+00\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.8295 - true_positives_3: 180.0000 - true_negatives_3: 0.0000e+00 - false_positives_3: 37.0000 - false_negatives_3: 0.0000e+00 - val_loss: 0.6033 - val_accuracy: 0.8364 - val_true_positives_3: 46.0000 - val_true_negatives_3: 0.0000e+00 - val_false_positives_3: 9.0000 - val_false_negatives_3: 0.0000e+00\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.8295 - true_positives_3: 180.0000 - true_negatives_3: 0.0000e+00 - false_positives_3: 37.0000 - false_negatives_3: 0.0000e+00 - val_loss: 0.7767 - val_accuracy: 0.8364 - val_true_positives_3: 46.0000 - val_true_negatives_3: 0.0000e+00 - val_false_positives_3: 9.0000 - val_false_negatives_3: 0.0000e+00\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.8295 - true_positives_3: 180.0000 - true_negatives_3: 0.0000e+00 - false_positives_3: 37.0000 - false_negatives_3: 0.0000e+00 - val_loss: 0.8146 - val_accuracy: 0.8364 - val_true_positives_3: 46.0000 - val_true_negatives_3: 0.0000e+00 - val_false_positives_3: 9.0000 - val_false_negatives_3: 0.0000e+00\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.8295 - true_positives_3: 180.0000 - true_negatives_3: 0.0000e+00 - false_positives_3: 37.0000 - false_negatives_3: 0.0000e+00 - val_loss: 0.7156 - val_accuracy: 0.8364 - val_true_positives_3: 46.0000 - val_true_negatives_3: 0.0000e+00 - val_false_positives_3: 9.0000 - val_false_negatives_3: 0.0000e+00\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6194 - accuracy: 0.8295 - true_positives_3: 180.0000 - true_negatives_3: 0.0000e+00 - false_positives_3: 37.0000 - false_negatives_3: 0.0000e+00 - val_loss: 0.5905 - val_accuracy: 0.8364 - val_true_positives_3: 46.0000 - val_true_negatives_3: 0.0000e+00 - val_false_positives_3: 9.0000 - val_false_negatives_3: 0.0000e+00\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.8295 - true_positives_3: 180.0000 - true_negatives_3: 0.0000e+00 - false_positives_3: 37.0000 - false_negatives_3: 0.0000e+00 - val_loss: 0.7290 - val_accuracy: 0.8364 - val_true_positives_3: 46.0000 - val_true_negatives_3: 0.0000e+00 - val_false_positives_3: 9.0000 - val_false_negatives_3: 0.0000e+00\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 0.8295 - true_positives_3: 180.0000 - true_negatives_3: 0.0000e+00 - false_positives_3: 37.0000 - false_negatives_3: 0.0000e+00 - val_loss: 1.8107 - val_accuracy: 0.8364 - val_true_positives_3: 46.0000 - val_true_negatives_3: 0.0000e+00 - val_false_positives_3: 9.0000 - val_false_negatives_3: 0.0000e+00\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.8295 - true_positives_3: 180.0000 - true_negatives_3: 0.0000e+00 - false_positives_3: 37.0000 - false_negatives_3: 0.0000e+00 - val_loss: 4.0271 - val_accuracy: 0.8364 - val_true_positives_3: 46.0000 - val_true_negatives_3: 0.0000e+00 - val_false_positives_3: 9.0000 - val_false_negatives_3: 0.0000e+00\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.8295 - true_positives_3: 180.0000 - true_negatives_3: 0.0000e+00 - false_positives_3: 37.0000 - false_negatives_3: 0.0000e+00 - val_loss: 5.7404 - val_accuracy: 0.8364 - val_true_positives_3: 46.0000 - val_true_negatives_3: 0.0000e+00 - val_false_positives_3: 9.0000 - val_false_negatives_3: 0.0000e+00\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.8295 - true_positives_3: 180.0000 - true_negatives_3: 0.0000e+00 - false_positives_3: 37.0000 - false_negatives_3: 0.0000e+00 - val_loss: 1.9630 - val_accuracy: 0.8364 - val_true_positives_3: 46.0000 - val_true_negatives_3: 0.0000e+00 - val_false_positives_3: 9.0000 - val_false_negatives_3: 0.0000e+00\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Epoch 1/30\n",
      "28/28 [==============================] - 1s 17ms/step - loss: 10.9594 - accuracy: 0.7235 - true_positives_4: 155.0000 - true_negatives_4: 2.0000 - false_positives_4: 35.0000 - false_negatives_4: 25.0000 - val_loss: 2.5818 - val_accuracy: 0.4909 - val_true_positives_4: 22.0000 - val_true_negatives_4: 5.0000 - val_false_positives_4: 4.0000 - val_false_negatives_4: 24.0000\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3.1935 - accuracy: 0.3687 - true_positives_4: 61.0000 - true_negatives_4: 19.0000 - false_positives_4: 18.0000 - false_negatives_4: 119.0000 - val_loss: 1.6388 - val_accuracy: 0.3091 - val_true_positives_4: 12.0000 - val_true_negatives_4: 5.0000 - val_false_positives_4: 4.0000 - val_false_negatives_4: 34.0000\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.6088 - accuracy: 0.6544 - true_positives_4: 134.0000 - true_negatives_4: 8.0000 - false_positives_4: 29.0000 - false_negatives_4: 46.0000 - val_loss: 1.0641 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8298 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.8188 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.7021 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.7209 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.7290 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.6632 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.6365 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.6376 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.6544 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.6217 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.6195 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.6165 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.6107 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.6017 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.5986 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.5987 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.5953 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.5992 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.6019 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.5810 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.5796 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.5629 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.5673 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.5649 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.5636 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.5737 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "Epoch 28/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.8295 - true_positives_4: 180.0000 - true_negatives_4: 0.0000e+00 - false_positives_4: 37.0000 - false_negatives_4: 0.0000e+00 - val_loss: 0.5641 - val_accuracy: 0.8364 - val_true_positives_4: 46.0000 - val_true_negatives_4: 0.0000e+00 - val_false_positives_4: 9.0000 - val_false_negatives_4: 0.0000e+00\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Epoch 1/30\n",
      "28/28 [==============================] - 1s 11ms/step - loss: 139.4452 - accuracy: 0.2798 - true_positives_5: 31.0000 - true_negatives_5: 30.0000 - false_positives_5: 8.0000 - false_negatives_5: 149.0000 - val_loss: 29.7801 - val_accuracy: 0.7818 - val_true_positives_5: 39.0000 - val_true_negatives_5: 4.0000 - val_false_positives_5: 5.0000 - val_false_negatives_5: 7.0000\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.7031 - accuracy: 0.8165 - true_positives_5: 177.0000 - true_negatives_5: 1.0000 - false_positives_5: 37.0000 - false_negatives_5: 3.0000 - val_loss: 0.6784 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.6730 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.6673 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.6614 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.6556 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.6497 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.6441 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.6381 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.6326 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.6268 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.6209 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.6151 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.6096 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.6043 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.5995 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.5946 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.5901 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.5853 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.5805 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.5762 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.5716 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.5670 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.5632 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.5593 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.5553 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.5518 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 28/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.5486 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 29/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.5448 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "Epoch 30/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.8257 - true_positives_5: 180.0000 - true_negatives_5: 0.0000e+00 - false_positives_5: 38.0000 - false_negatives_5: 0.0000e+00 - val_loss: 0.5410 - val_accuracy: 0.8364 - val_true_positives_5: 46.0000 - val_true_negatives_5: 0.0000e+00 - val_false_positives_5: 9.0000 - val_false_negatives_5: 0.0000e+00\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Epoch 1/30\n",
      "28/28 [==============================] - 1s 11ms/step - loss: 19.2408 - accuracy: 0.6330 - true_positives_6: 134.0000 - true_negatives_6: 4.0000 - false_positives_6: 34.0000 - false_negatives_6: 46.0000 - val_loss: 7.7230 - val_accuracy: 0.4182 - val_true_positives_6: 19.0000 - val_true_negatives_6: 4.0000 - val_false_positives_6: 5.0000 - val_false_negatives_6: 27.0000\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 5.3876 - accuracy: 0.3899 - true_positives_6: 66.0000 - true_negatives_6: 19.0000 - false_positives_6: 19.0000 - false_negatives_6: 114.0000 - val_loss: 4.2437 - val_accuracy: 0.3455 - val_true_positives_6: 14.0000 - val_true_negatives_6: 5.0000 - val_false_positives_6: 4.0000 - val_false_negatives_6: 32.0000\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.4301 - accuracy: 0.7982 - true_positives_6: 170.0000 - true_negatives_6: 4.0000 - false_positives_6: 34.0000 - false_negatives_6: 10.0000 - val_loss: 3.5986 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4282 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 3.0068 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.0777 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 2.7204 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8821 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 2.6238 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.7603 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 1.8791 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 1.7560 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6271 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 1.6260 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 1.7296 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 1.6461 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6300 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 1.7246 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.7140 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 2.5407 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.7539 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 1.5865 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6682 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 1.1307 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 0.9533 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 1.1268 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 1.0603 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 1.1197 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 1.0091 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.8257 - true_positives_6: 180.0000 - true_negatives_6: 0.0000e+00 - false_positives_6: 38.0000 - false_negatives_6: 0.0000e+00 - val_loss: 1.0973 - val_accuracy: 0.8364 - val_true_positives_6: 46.0000 - val_true_negatives_6: 0.0000e+00 - val_false_positives_6: 9.0000 - val_false_negatives_6: 0.0000e+00\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 11ms/step - loss: 15.3325 - accuracy: 0.3853 - true_positives_7: 62.0000 - true_negatives_7: 22.0000 - false_positives_7: 16.0000 - false_negatives_7: 118.0000 - val_loss: 5.0980 - val_accuracy: 0.6909 - val_true_positives_7: 36.0000 - val_true_negatives_7: 2.0000 - val_false_positives_7: 7.0000 - val_false_negatives_7: 10.0000\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.5616 - accuracy: 0.5963 - true_positives_7: 117.0000 - true_negatives_7: 13.0000 - false_positives_7: 25.0000 - false_negatives_7: 63.0000 - val_loss: 2.6386 - val_accuracy: 0.6182 - val_true_positives_7: 33.0000 - val_true_negatives_7: 1.0000 - val_false_positives_7: 8.0000 - val_false_negatives_7: 13.0000\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.1413 - accuracy: 0.7890 - true_positives_7: 167.0000 - true_negatives_7: 5.0000 - false_positives_7: 33.0000 - false_negatives_7: 13.0000 - val_loss: 1.5049 - val_accuracy: 0.7455 - val_true_positives_7: 39.0000 - val_true_negatives_7: 2.0000 - val_false_positives_7: 7.0000 - val_false_negatives_7: 7.0000\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.0581 - accuracy: 0.7248 - true_positives_7: 154.0000 - true_negatives_7: 4.0000 - false_positives_7: 34.0000 - false_negatives_7: 26.0000 - val_loss: 1.1012 - val_accuracy: 0.7636 - val_true_positives_7: 42.0000 - val_true_negatives_7: 0.0000e+00 - val_false_positives_7: 9.0000 - val_false_negatives_7: 4.0000\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8504 - accuracy: 0.8257 - true_positives_7: 176.0000 - true_negatives_7: 4.0000 - false_positives_7: 34.0000 - false_negatives_7: 4.0000 - val_loss: 1.0074 - val_accuracy: 0.8364 - val_true_positives_7: 46.0000 - val_true_negatives_7: 0.0000e+00 - val_false_positives_7: 9.0000 - val_false_negatives_7: 0.0000e+00\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.7780 - accuracy: 0.8257 - true_positives_7: 177.0000 - true_negatives_7: 3.0000 - false_positives_7: 35.0000 - false_negatives_7: 3.0000 - val_loss: 0.8735 - val_accuracy: 0.8364 - val_true_positives_7: 46.0000 - val_true_negatives_7: 0.0000e+00 - val_false_positives_7: 9.0000 - val_false_negatives_7: 0.0000e+00\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.8257 - true_positives_7: 178.0000 - true_negatives_7: 2.0000 - false_positives_7: 36.0000 - false_negatives_7: 2.0000 - val_loss: 0.8028 - val_accuracy: 0.8364 - val_true_positives_7: 46.0000 - val_true_negatives_7: 0.0000e+00 - val_false_positives_7: 9.0000 - val_false_negatives_7: 0.0000e+00\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.8257 - true_positives_7: 178.0000 - true_negatives_7: 2.0000 - false_positives_7: 36.0000 - false_negatives_7: 2.0000 - val_loss: 0.6877 - val_accuracy: 0.8364 - val_true_positives_7: 46.0000 - val_true_negatives_7: 0.0000e+00 - val_false_positives_7: 9.0000 - val_false_negatives_7: 0.0000e+00\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.8257 - true_positives_7: 178.0000 - true_negatives_7: 2.0000 - false_positives_7: 36.0000 - false_negatives_7: 2.0000 - val_loss: 0.6735 - val_accuracy: 0.8364 - val_true_positives_7: 46.0000 - val_true_negatives_7: 0.0000e+00 - val_false_positives_7: 9.0000 - val_false_negatives_7: 0.0000e+00\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.8303 - true_positives_7: 179.0000 - true_negatives_7: 2.0000 - false_positives_7: 36.0000 - false_negatives_7: 1.0000 - val_loss: 0.7252 - val_accuracy: 0.8364 - val_true_positives_7: 46.0000 - val_true_negatives_7: 0.0000e+00 - val_false_positives_7: 9.0000 - val_false_negatives_7: 0.0000e+00\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.8257 - true_positives_7: 179.0000 - true_negatives_7: 1.0000 - false_positives_7: 37.0000 - false_negatives_7: 1.0000 - val_loss: 0.7561 - val_accuracy: 0.8364 - val_true_positives_7: 46.0000 - val_true_negatives_7: 0.0000e+00 - val_false_positives_7: 9.0000 - val_false_negatives_7: 0.0000e+00\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.8257 - true_positives_7: 179.0000 - true_negatives_7: 1.0000 - false_positives_7: 37.0000 - false_negatives_7: 1.0000 - val_loss: 0.7568 - val_accuracy: 0.8364 - val_true_positives_7: 46.0000 - val_true_negatives_7: 0.0000e+00 - val_false_positives_7: 9.0000 - val_false_negatives_7: 0.0000e+00\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.8257 - true_positives_7: 179.0000 - true_negatives_7: 1.0000 - false_positives_7: 37.0000 - false_negatives_7: 1.0000 - val_loss: 0.7497 - val_accuracy: 0.8364 - val_true_positives_7: 46.0000 - val_true_negatives_7: 0.0000e+00 - val_false_positives_7: 9.0000 - val_false_negatives_7: 0.0000e+00\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6034 - accuracy: 0.8257 - true_positives_7: 179.0000 - true_negatives_7: 1.0000 - false_positives_7: 37.0000 - false_negatives_7: 1.0000 - val_loss: 0.7461 - val_accuracy: 0.8364 - val_true_positives_7: 46.0000 - val_true_negatives_7: 0.0000e+00 - val_false_positives_7: 9.0000 - val_false_negatives_7: 0.0000e+00\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Epoch 1/30\n",
      "28/28 [==============================] - 1s 11ms/step - loss: 11.2525 - accuracy: 0.8257 - true_positives_8: 180.0000 - true_negatives_8: 0.0000e+00 - false_positives_8: 38.0000 - false_negatives_8: 0.0000e+00 - val_loss: 4.8725 - val_accuracy: 0.8364 - val_true_positives_8: 46.0000 - val_true_negatives_8: 0.0000e+00 - val_false_positives_8: 9.0000 - val_false_negatives_8: 0.0000e+00\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.3349 - accuracy: 0.8257 - true_positives_8: 180.0000 - true_negatives_8: 0.0000e+00 - false_positives_8: 38.0000 - false_negatives_8: 0.0000e+00 - val_loss: 2.5997 - val_accuracy: 0.8364 - val_true_positives_8: 46.0000 - val_true_negatives_8: 0.0000e+00 - val_false_positives_8: 9.0000 - val_false_negatives_8: 0.0000e+00\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3.1116 - accuracy: 0.8257 - true_positives_8: 180.0000 - true_negatives_8: 0.0000e+00 - false_positives_8: 38.0000 - false_negatives_8: 0.0000e+00 - val_loss: 1.3989 - val_accuracy: 0.8364 - val_true_positives_8: 46.0000 - val_true_negatives_8: 0.0000e+00 - val_false_positives_8: 9.0000 - val_false_negatives_8: 0.0000e+00\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.9357 - accuracy: 0.8257 - true_positives_8: 180.0000 - true_negatives_8: 0.0000e+00 - false_positives_8: 38.0000 - false_negatives_8: 0.0000e+00 - val_loss: 0.8137 - val_accuracy: 0.8364 - val_true_positives_8: 46.0000 - val_true_negatives_8: 0.0000e+00 - val_false_positives_8: 9.0000 - val_false_negatives_8: 0.0000e+00\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.1736 - accuracy: 0.8257 - true_positives_8: 180.0000 - true_negatives_8: 0.0000e+00 - false_positives_8: 38.0000 - false_negatives_8: 0.0000e+00 - val_loss: 0.5928 - val_accuracy: 0.8364 - val_true_positives_8: 46.0000 - val_true_negatives_8: 0.0000e+00 - val_false_positives_8: 9.0000 - val_false_negatives_8: 0.0000e+00\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8058 - accuracy: 0.8073 - true_positives_8: 176.0000 - true_negatives_8: 0.0000e+00 - false_positives_8: 38.0000 - false_negatives_8: 4.0000 - val_loss: 0.6250 - val_accuracy: 0.7636 - val_true_positives_8: 41.0000 - val_true_negatives_8: 1.0000 - val_false_positives_8: 8.0000 - val_false_negatives_8: 5.0000\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.7982 - true_positives_8: 172.0000 - true_negatives_8: 2.0000 - false_positives_8: 36.0000 - false_negatives_8: 8.0000 - val_loss: 0.6473 - val_accuracy: 0.7636 - val_true_positives_8: 41.0000 - val_true_negatives_8: 1.0000 - val_false_positives_8: 8.0000 - val_false_negatives_8: 5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.8028 - true_positives_8: 173.0000 - true_negatives_8: 2.0000 - false_positives_8: 36.0000 - false_negatives_8: 7.0000 - val_loss: 0.5909 - val_accuracy: 0.7818 - val_true_positives_8: 42.0000 - val_true_negatives_8: 1.0000 - val_false_positives_8: 8.0000 - val_false_negatives_8: 4.0000\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.8073 - true_positives_8: 173.0000 - true_negatives_8: 3.0000 - false_positives_8: 35.0000 - false_negatives_8: 7.0000 - val_loss: 0.5758 - val_accuracy: 0.7818 - val_true_positives_8: 42.0000 - val_true_negatives_8: 1.0000 - val_false_positives_8: 8.0000 - val_false_negatives_8: 4.0000\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.8028 - true_positives_8: 173.0000 - true_negatives_8: 2.0000 - false_positives_8: 36.0000 - false_negatives_8: 7.0000 - val_loss: 0.5578 - val_accuracy: 0.7818 - val_true_positives_8: 42.0000 - val_true_negatives_8: 1.0000 - val_false_positives_8: 8.0000 - val_false_negatives_8: 4.0000\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7982 - true_positives_8: 171.0000 - true_negatives_8: 3.0000 - false_positives_8: 35.0000 - false_negatives_8: 9.0000 - val_loss: 0.5717 - val_accuracy: 0.7818 - val_true_positives_8: 42.0000 - val_true_negatives_8: 1.0000 - val_false_positives_8: 8.0000 - val_false_negatives_8: 4.0000\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7936 - true_positives_8: 170.0000 - true_negatives_8: 3.0000 - false_positives_8: 35.0000 - false_negatives_8: 10.0000 - val_loss: 0.5622 - val_accuracy: 0.7818 - val_true_positives_8: 42.0000 - val_true_negatives_8: 1.0000 - val_false_positives_8: 8.0000 - val_false_negatives_8: 4.0000\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7982 - true_positives_8: 171.0000 - true_negatives_8: 3.0000 - false_positives_8: 35.0000 - false_negatives_8: 9.0000 - val_loss: 0.5573 - val_accuracy: 0.8000 - val_true_positives_8: 43.0000 - val_true_negatives_8: 1.0000 - val_false_positives_8: 8.0000 - val_false_negatives_8: 3.0000\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7982 - true_positives_8: 172.0000 - true_negatives_8: 2.0000 - false_positives_8: 36.0000 - false_negatives_8: 8.0000 - val_loss: 0.5627 - val_accuracy: 0.7818 - val_true_positives_8: 42.0000 - val_true_negatives_8: 1.0000 - val_false_positives_8: 8.0000 - val_false_negatives_8: 4.0000\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7982 - true_positives_8: 171.0000 - true_negatives_8: 3.0000 - false_positives_8: 35.0000 - false_negatives_8: 9.0000 - val_loss: 0.5720 - val_accuracy: 0.8000 - val_true_positives_8: 43.0000 - val_true_negatives_8: 1.0000 - val_false_positives_8: 8.0000 - val_false_negatives_8: 3.0000\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7890 - true_positives_8: 169.0000 - true_negatives_8: 3.0000 - false_positives_8: 35.0000 - false_negatives_8: 11.0000 - val_loss: 0.5603 - val_accuracy: 0.8000 - val_true_positives_8: 43.0000 - val_true_negatives_8: 1.0000 - val_false_positives_8: 8.0000 - val_false_negatives_8: 3.0000\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.8028 - true_positives_8: 172.0000 - true_negatives_8: 3.0000 - false_positives_8: 35.0000 - false_negatives_8: 8.0000 - val_loss: 0.4994 - val_accuracy: 0.8182 - val_true_positives_8: 44.0000 - val_true_negatives_8: 1.0000 - val_false_positives_8: 8.0000 - val_false_negatives_8: 2.0000\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.8165 - true_positives_8: 177.0000 - true_negatives_8: 1.0000 - false_positives_8: 37.0000 - false_negatives_8: 3.0000 - val_loss: 0.5671 - val_accuracy: 0.7818 - val_true_positives_8: 42.0000 - val_true_negatives_8: 1.0000 - val_false_positives_8: 8.0000 - val_false_negatives_8: 4.0000\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7844 - true_positives_8: 168.0000 - true_negatives_8: 3.0000 - false_positives_8: 35.0000 - false_negatives_8: 12.0000 - val_loss: 0.5270 - val_accuracy: 0.8000 - val_true_positives_8: 43.0000 - val_true_negatives_8: 1.0000 - val_false_positives_8: 8.0000 - val_false_negatives_8: 3.0000\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7982 - true_positives_8: 171.0000 - true_negatives_8: 3.0000 - false_positives_8: 35.0000 - false_negatives_8: 9.0000 - val_loss: 0.5014 - val_accuracy: 0.8182 - val_true_positives_8: 44.0000 - val_true_negatives_8: 1.0000 - val_false_positives_8: 8.0000 - val_false_negatives_8: 2.0000\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.8028 - true_positives_8: 173.0000 - true_negatives_8: 2.0000 - false_positives_8: 36.0000 - false_negatives_8: 7.0000 - val_loss: 0.5100 - val_accuracy: 0.8182 - val_true_positives_8: 44.0000 - val_true_negatives_8: 1.0000 - val_false_positives_8: 8.0000 - val_false_negatives_8: 2.0000\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.8028 - true_positives_8: 174.0000 - true_negatives_8: 1.0000 - false_positives_8: 37.0000 - false_negatives_8: 6.0000 - val_loss: 0.5141 - val_accuracy: 0.8182 - val_true_positives_8: 44.0000 - val_true_negatives_8: 1.0000 - val_false_positives_8: 8.0000 - val_false_negatives_8: 2.0000\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Epoch 1/30\n",
      "28/28 [==============================] - 1s 11ms/step - loss: 36.3686 - accuracy: 0.6468 - true_positives_9: 133.0000 - true_negatives_9: 8.0000 - false_positives_9: 30.0000 - false_negatives_9: 47.0000 - val_loss: 8.3497 - val_accuracy: 0.4364 - val_true_positives_9: 20.0000 - val_true_negatives_9: 4.0000 - val_false_positives_9: 5.0000 - val_false_negatives_9: 26.0000\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.5607 - accuracy: 0.5000 - true_positives_9: 88.0000 - true_negatives_9: 21.0000 - false_positives_9: 17.0000 - false_negatives_9: 92.0000 - val_loss: 3.7675 - val_accuracy: 0.7818 - val_true_positives_9: 43.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 3.0000\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.9783 - accuracy: 0.8257 - true_positives_9: 178.0000 - true_negatives_9: 2.0000 - false_positives_9: 36.0000 - false_negatives_9: 2.0000 - val_loss: 0.6709 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.6733 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.6636 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.6547 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.6470 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.6388 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.6312 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6302 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.6245 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.6174 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.6106 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.6045 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.5983 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.5926 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.5869 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.5817 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.5762 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.5712 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.5666 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.5617 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.5576 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.5532 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.5491 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.5453 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.5416 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.5378 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.5343 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 29/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.5311 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "Epoch 30/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.8257 - true_positives_9: 180.0000 - true_negatives_9: 0.0000e+00 - false_positives_9: 38.0000 - false_negatives_9: 0.0000e+00 - val_loss: 0.5278 - val_accuracy: 0.8364 - val_true_positives_9: 46.0000 - val_true_negatives_9: 0.0000e+00 - val_false_positives_9: 9.0000 - val_false_negatives_9: 0.0000e+00\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Epoch 1/30\n",
      "28/28 [==============================] - 1s 11ms/step - loss: 1.8979 - accuracy: 0.6560 - true_positives_10: 134.0000 - true_negatives_10: 9.0000 - false_positives_10: 29.0000 - false_negatives_10: 46.0000 - val_loss: 0.5714 - val_accuracy: 0.8364 - val_true_positives_10: 46.0000 - val_true_negatives_10: 0.0000e+00 - val_false_positives_10: 9.0000 - val_false_negatives_10: 0.0000e+00\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.7765 - accuracy: 0.8211 - true_positives_10: 179.0000 - true_negatives_10: 0.0000e+00 - false_positives_10: 38.0000 - false_negatives_10: 1.0000 - val_loss: 0.6146 - val_accuracy: 0.8364 - val_true_positives_10: 46.0000 - val_true_negatives_10: 0.0000e+00 - val_false_positives_10: 9.0000 - val_false_negatives_10: 0.0000e+00\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.8257 - true_positives_10: 180.0000 - true_negatives_10: 0.0000e+00 - false_positives_10: 38.0000 - false_negatives_10: 0.0000e+00 - val_loss: 0.6221 - val_accuracy: 0.8364 - val_true_positives_10: 46.0000 - val_true_negatives_10: 0.0000e+00 - val_false_positives_10: 9.0000 - val_false_negatives_10: 0.0000e+00\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.8257 - true_positives_10: 180.0000 - true_negatives_10: 0.0000e+00 - false_positives_10: 38.0000 - false_negatives_10: 0.0000e+00 - val_loss: 0.6017 - val_accuracy: 0.8364 - val_true_positives_10: 46.0000 - val_true_negatives_10: 0.0000e+00 - val_false_positives_10: 9.0000 - val_false_negatives_10: 0.0000e+00\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.8257 - true_positives_10: 180.0000 - true_negatives_10: 0.0000e+00 - false_positives_10: 38.0000 - false_negatives_10: 0.0000e+00 - val_loss: 0.5579 - val_accuracy: 0.8364 - val_true_positives_10: 46.0000 - val_true_negatives_10: 0.0000e+00 - val_false_positives_10: 9.0000 - val_false_negatives_10: 0.0000e+00\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.8257 - true_positives_10: 180.0000 - true_negatives_10: 0.0000e+00 - false_positives_10: 38.0000 - false_negatives_10: 0.0000e+00 - val_loss: 0.5666 - val_accuracy: 0.8364 - val_true_positives_10: 46.0000 - val_true_negatives_10: 0.0000e+00 - val_false_positives_10: 9.0000 - val_false_negatives_10: 0.0000e+00\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.8257 - true_positives_10: 180.0000 - true_negatives_10: 0.0000e+00 - false_positives_10: 38.0000 - false_negatives_10: 0.0000e+00 - val_loss: 0.5738 - val_accuracy: 0.8364 - val_true_positives_10: 46.0000 - val_true_negatives_10: 0.0000e+00 - val_false_positives_10: 9.0000 - val_false_negatives_10: 0.0000e+00\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.8257 - true_positives_10: 180.0000 - true_negatives_10: 0.0000e+00 - false_positives_10: 38.0000 - false_negatives_10: 0.0000e+00 - val_loss: 0.5815 - val_accuracy: 0.8364 - val_true_positives_10: 46.0000 - val_true_negatives_10: 0.0000e+00 - val_false_positives_10: 9.0000 - val_false_negatives_10: 0.0000e+00\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.8257 - true_positives_10: 180.0000 - true_negatives_10: 0.0000e+00 - false_positives_10: 38.0000 - false_negatives_10: 0.0000e+00 - val_loss: 0.5655 - val_accuracy: 0.8364 - val_true_positives_10: 46.0000 - val_true_negatives_10: 0.0000e+00 - val_false_positives_10: 9.0000 - val_false_negatives_10: 0.0000e+00\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.8257 - true_positives_10: 180.0000 - true_negatives_10: 0.0000e+00 - false_positives_10: 38.0000 - false_negatives_10: 0.0000e+00 - val_loss: 0.5837 - val_accuracy: 0.8364 - val_true_positives_10: 46.0000 - val_true_negatives_10: 0.0000e+00 - val_false_positives_10: 9.0000 - val_false_negatives_10: 0.0000e+00\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Epoch 1/30\n",
      "28/28 [==============================] - 1s 12ms/step - loss: 4.5857 - accuracy: 0.6193 - true_positives_11: 127.0000 - true_negatives_11: 8.0000 - false_positives_11: 30.0000 - false_negatives_11: 53.0000 - val_loss: 0.9760 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9867 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9914 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9848 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9799 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9739 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9687 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6279 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9640 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6216 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9593 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9547 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9503 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9463 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9421 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9384 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9348 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9315 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9281 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9245 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9220 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9190 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9159 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9138 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9110 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9086 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9063 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9039 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.9014 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.8994 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 29/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.8974 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "Epoch 30/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.8257 - true_positives_11: 180.0000 - true_negatives_11: 0.0000e+00 - false_positives_11: 38.0000 - false_negatives_11: 0.0000e+00 - val_loss: 0.8955 - val_accuracy: 0.8364 - val_true_positives_11: 46.0000 - val_true_negatives_11: 0.0000e+00 - val_false_positives_11: 9.0000 - val_false_negatives_11: 0.0000e+00\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.023529411764705917.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 1s 8ms/step - loss: 8.5646 - accuracy: 0.5417 - true_positives_12: 104.0000 - true_negatives_12: 91.0000 - false_positives_12: 89.0000 - false_negatives_12: 76.0000 - val_loss: 3.9833 - val_accuracy: 0.5455 - val_true_positives_12: 24.0000 - val_true_negatives_12: 6.0000 - val_false_positives_12: 4.0000 - val_false_negatives_12: 21.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 3.3606 - accuracy: 0.4944 - true_positives_12: 97.0000 - true_negatives_12: 81.0000 - false_positives_12: 99.0000 - false_negatives_12: 83.0000 - val_loss: 2.0621 - val_accuracy: 0.5455 - val_true_positives_12: 22.0000 - val_true_negatives_12: 8.0000 - val_false_positives_12: 2.0000 - val_false_negatives_12: 23.0000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 1.2341 - accuracy: 0.5361 - true_positives_12: 58.0000 - true_negatives_12: 135.0000 - false_positives_12: 45.0000 - false_negatives_12: 122.0000 - val_loss: 1.4477 - val_accuracy: 0.2000 - val_true_positives_12: 2.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 43.0000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7498 - accuracy: 0.5139 - true_positives_12: 8.0000 - true_negatives_12: 177.0000 - false_positives_12: 3.0000 - false_negatives_12: 172.0000 - val_loss: 1.2822 - val_accuracy: 0.2000 - val_true_positives_12: 2.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 43.0000\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 0.5139 - true_positives_12: 6.0000 - true_negatives_12: 179.0000 - false_positives_12: 1.0000 - false_negatives_12: 174.0000 - val_loss: 1.2092 - val_accuracy: 0.2000 - val_true_positives_12: 2.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 43.0000\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1746 - val_accuracy: 0.2000 - val_true_positives_12: 2.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 43.0000\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5139 - true_positives_12: 6.0000 - true_negatives_12: 179.0000 - false_positives_12: 1.0000 - false_negatives_12: 174.0000 - val_loss: 1.1298 - val_accuracy: 0.2000 - val_true_positives_12: 2.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 43.0000\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1237 - val_accuracy: 0.2000 - val_true_positives_12: 2.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 43.0000\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1209 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1174 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1183 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1151 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1167 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1136 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1115 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1119 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1104 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1101 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 19/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1273 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.5167 - true_positives_12: 7.0000 - true_negatives_12: 179.0000 - false_positives_12: 1.0000 - false_negatives_12: 173.0000 - val_loss: 1.1042 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1087 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1112 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 23/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1036 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 24/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1062 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 25/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1046 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 26/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.0992 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 27/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.0999 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 28/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.1048 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 29/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.0997 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "Epoch 30/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.5083 - true_positives_12: 3.0000 - true_negatives_12: 180.0000 - false_positives_12: 0.0000e+00 - false_negatives_12: 177.0000 - val_loss: 1.0974 - val_accuracy: 0.2182 - val_true_positives_12: 3.0000 - val_true_negatives_12: 9.0000 - val_false_positives_12: 1.0000 - val_false_negatives_12: 42.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 1s 8ms/step - loss: 532.0477 - accuracy: 0.5000 - true_positives_13: 0.0000e+00 - true_negatives_13: 180.0000 - false_positives_13: 0.0000e+00 - false_negatives_13: 180.0000 - val_loss: 538.6238 - val_accuracy: 0.1636 - val_true_positives_13: 0.0000e+00 - val_true_negatives_13: 9.0000 - val_false_positives_13: 0.0000e+00 - val_false_negatives_13: 46.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 146.0868 - accuracy: 0.5278 - true_positives_13: 13.0000 - true_negatives_13: 177.0000 - false_positives_13: 3.0000 - false_negatives_13: 167.0000 - val_loss: 72.6289 - val_accuracy: 0.2727 - val_true_positives_13: 10.0000 - val_true_negatives_13: 5.0000 - val_false_positives_13: 4.0000 - val_false_negatives_13: 36.0000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.4476 - accuracy: 0.5500 - true_positives_13: 147.0000 - true_negatives_13: 51.0000 - false_positives_13: 129.0000 - false_negatives_13: 33.0000 - val_loss: 0.9947 - val_accuracy: 0.8182 - val_true_positives_13: 45.0000 - val_true_negatives_13: 0.0000e+00 - val_false_positives_13: 9.0000 - val_false_negatives_13: 1.0000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.8558 - accuracy: 0.5250 - true_positives_13: 177.0000 - true_negatives_13: 12.0000 - false_positives_13: 168.0000 - false_negatives_13: 3.0000 - val_loss: 0.6610 - val_accuracy: 0.8364 - val_true_positives_13: 46.0000 - val_true_negatives_13: 0.0000e+00 - val_false_positives_13: 9.0000 - val_false_negatives_13: 0.0000e+00\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7574 - accuracy: 0.5306 - true_positives_13: 179.0000 - true_negatives_13: 12.0000 - false_positives_13: 168.0000 - false_negatives_13: 1.0000 - val_loss: 0.6611 - val_accuracy: 0.8364 - val_true_positives_13: 46.0000 - val_true_negatives_13: 0.0000e+00 - val_false_positives_13: 9.0000 - val_false_negatives_13: 0.0000e+00\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7372 - accuracy: 0.5222 - true_positives_13: 179.0000 - true_negatives_13: 9.0000 - false_positives_13: 171.0000 - false_negatives_13: 1.0000 - val_loss: 0.6619 - val_accuracy: 0.8364 - val_true_positives_13: 46.0000 - val_true_negatives_13: 0.0000e+00 - val_false_positives_13: 9.0000 - val_false_negatives_13: 0.0000e+00\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7115 - accuracy: 0.5194 - true_positives_13: 179.0000 - true_negatives_13: 8.0000 - false_positives_13: 172.0000 - false_negatives_13: 1.0000 - val_loss: 0.6618 - val_accuracy: 0.8364 - val_true_positives_13: 46.0000 - val_true_negatives_13: 0.0000e+00 - val_false_positives_13: 9.0000 - val_false_negatives_13: 0.0000e+00\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7032 - accuracy: 0.5056 - true_positives_13: 179.0000 - true_negatives_13: 3.0000 - false_positives_13: 177.0000 - false_negatives_13: 1.0000 - val_loss: 0.6624 - val_accuracy: 0.8364 - val_true_positives_13: 46.0000 - val_true_negatives_13: 0.0000e+00 - val_false_positives_13: 9.0000 - val_false_negatives_13: 0.0000e+00\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5000 - true_positives_13: 180.0000 - true_negatives_13: 0.0000e+00 - false_positives_13: 180.0000 - false_negatives_13: 0.0000e+00 - val_loss: 0.6643 - val_accuracy: 0.8364 - val_true_positives_13: 46.0000 - val_true_negatives_13: 0.0000e+00 - val_false_positives_13: 9.0000 - val_false_negatives_13: 0.0000e+00\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 1s 8ms/step - loss: 11.1518 - accuracy: 0.5056 - true_positives_14: 127.0000 - true_negatives_14: 55.0000 - false_positives_14: 125.0000 - false_negatives_14: 53.0000 - val_loss: 6.2820 - val_accuracy: 0.6182 - val_true_positives_14: 34.0000 - val_true_negatives_14: 0.0000e+00 - val_false_positives_14: 9.0000 - val_false_negatives_14: 12.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 3.5528 - accuracy: 0.4972 - true_positives_14: 150.0000 - true_negatives_14: 29.0000 - false_positives_14: 151.0000 - false_negatives_14: 30.0000 - val_loss: 2.1031 - val_accuracy: 0.7636 - val_true_positives_14: 42.0000 - val_true_negatives_14: 0.0000e+00 - val_false_positives_14: 9.0000 - val_false_negatives_14: 4.0000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.7495 - accuracy: 0.5278 - true_positives_14: 171.0000 - true_negatives_14: 19.0000 - false_positives_14: 161.0000 - false_negatives_14: 9.0000 - val_loss: 3.6578 - val_accuracy: 0.7636 - val_true_positives_14: 42.0000 - val_true_negatives_14: 0.0000e+00 - val_false_positives_14: 9.0000 - val_false_negatives_14: 4.0000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.1190 - accuracy: 0.5194 - true_positives_14: 173.0000 - true_negatives_14: 14.0000 - false_positives_14: 166.0000 - false_negatives_14: 7.0000 - val_loss: 6.0005 - val_accuracy: 0.7273 - val_true_positives_14: 40.0000 - val_true_negatives_14: 0.0000e+00 - val_false_positives_14: 9.0000 - val_false_negatives_14: 6.0000\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 1.4660 - accuracy: 0.5194 - true_positives_14: 172.0000 - true_negatives_14: 15.0000 - false_positives_14: 165.0000 - false_negatives_14: 8.0000 - val_loss: 3.2620 - val_accuracy: 0.7818 - val_true_positives_14: 43.0000 - val_true_negatives_14: 0.0000e+00 - val_false_positives_14: 9.0000 - val_false_negatives_14: 3.0000\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 4.2767 - accuracy: 0.5111 - true_positives_14: 174.0000 - true_negatives_14: 10.0000 - false_positives_14: 170.0000 - false_negatives_14: 6.0000 - val_loss: 1.3291 - val_accuracy: 0.8000 - val_true_positives_14: 44.0000 - val_true_negatives_14: 0.0000e+00 - val_false_positives_14: 9.0000 - val_false_negatives_14: 2.0000\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.1992 - accuracy: 0.5306 - true_positives_14: 103.0000 - true_negatives_14: 88.0000 - false_positives_14: 92.0000 - false_negatives_14: 77.0000 - val_loss: 2.8324 - val_accuracy: 0.7636 - val_true_positives_14: 42.0000 - val_true_negatives_14: 0.0000e+00 - val_false_positives_14: 9.0000 - val_false_negatives_14: 4.0000\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 1.6966 - accuracy: 0.5306 - true_positives_14: 176.0000 - true_negatives_14: 15.0000 - false_positives_14: 165.0000 - false_negatives_14: 4.0000 - val_loss: 3.1152 - val_accuracy: 0.7818 - val_true_positives_14: 43.0000 - val_true_negatives_14: 0.0000e+00 - val_false_positives_14: 9.0000 - val_false_negatives_14: 3.0000\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.4575 - accuracy: 0.5250 - true_positives_14: 177.0000 - true_negatives_14: 12.0000 - false_positives_14: 168.0000 - false_negatives_14: 3.0000 - val_loss: 0.7991 - val_accuracy: 0.8182 - val_true_positives_14: 45.0000 - val_true_negatives_14: 0.0000e+00 - val_false_positives_14: 9.0000 - val_false_negatives_14: 1.0000\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.3800 - accuracy: 0.5222 - true_positives_14: 175.0000 - true_negatives_14: 13.0000 - false_positives_14: 167.0000 - false_negatives_14: 5.0000 - val_loss: 0.6663 - val_accuracy: 0.8182 - val_true_positives_14: 45.0000 - val_true_negatives_14: 0.0000e+00 - val_false_positives_14: 9.0000 - val_false_negatives_14: 1.0000\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.9242 - accuracy: 0.4861 - true_positives_14: 114.0000 - true_negatives_14: 61.0000 - false_positives_14: 119.0000 - false_negatives_14: 66.0000 - val_loss: 0.6350 - val_accuracy: 0.8182 - val_true_positives_14: 45.0000 - val_true_negatives_14: 0.0000e+00 - val_false_positives_14: 9.0000 - val_false_negatives_14: 1.0000\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.2951 - accuracy: 0.5167 - true_positives_14: 178.0000 - true_negatives_14: 8.0000 - false_positives_14: 172.0000 - false_negatives_14: 2.0000 - val_loss: 0.6615 - val_accuracy: 0.8182 - val_true_positives_14: 45.0000 - val_true_negatives_14: 0.0000e+00 - val_false_positives_14: 9.0000 - val_false_negatives_14: 1.0000\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 1.0432 - accuracy: 0.5194 - true_positives_14: 178.0000 - true_negatives_14: 9.0000 - false_positives_14: 171.0000 - false_negatives_14: 2.0000 - val_loss: 0.6921 - val_accuracy: 0.8182 - val_true_positives_14: 45.0000 - val_true_negatives_14: 0.0000e+00 - val_false_positives_14: 9.0000 - val_false_negatives_14: 1.0000\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.7504 - accuracy: 0.4694 - true_positives_14: 14.0000 - true_negatives_14: 155.0000 - false_positives_14: 25.0000 - false_negatives_14: 166.0000 - val_loss: 0.6175 - val_accuracy: 0.8364 - val_true_positives_14: 46.0000 - val_true_negatives_14: 0.0000e+00 - val_false_positives_14: 9.0000 - val_false_negatives_14: 0.0000e+00\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.2425 - accuracy: 0.4722 - true_positives_14: 116.0000 - true_negatives_14: 54.0000 - false_positives_14: 126.0000 - false_negatives_14: 64.0000 - val_loss: 0.6426 - val_accuracy: 0.8364 - val_true_positives_14: 46.0000 - val_true_negatives_14: 0.0000e+00 - val_false_positives_14: 9.0000 - val_false_negatives_14: 0.0000e+00\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 1.7185 - accuracy: 0.5139 - true_positives_14: 21.0000 - true_negatives_14: 164.0000 - false_positives_14: 16.0000 - false_negatives_14: 159.0000 - val_loss: 0.6558 - val_accuracy: 0.2727 - val_true_positives_14: 6.0000 - val_true_negatives_14: 9.0000 - val_false_positives_14: 0.0000e+00 - val_false_negatives_14: 40.0000\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 3.9841 - accuracy: 0.4972 - true_positives_14: 10.0000 - true_negatives_14: 169.0000 - false_positives_14: 11.0000 - false_negatives_14: 170.0000 - val_loss: 0.6146 - val_accuracy: 0.2909 - val_true_positives_14: 7.0000 - val_true_negatives_14: 9.0000 - val_false_positives_14: 0.0000e+00 - val_false_negatives_14: 39.0000\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.7132 - accuracy: 0.5083 - true_positives_14: 7.0000 - true_negatives_14: 176.0000 - false_positives_14: 4.0000 - false_negatives_14: 173.0000 - val_loss: 0.6904 - val_accuracy: 0.2000 - val_true_positives_14: 2.0000 - val_true_negatives_14: 9.0000 - val_false_positives_14: 0.0000e+00 - val_false_negatives_14: 44.0000\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6996 - accuracy: 0.5111 - true_positives_14: 5.0000 - true_negatives_14: 179.0000 - false_positives_14: 1.0000 - false_negatives_14: 175.0000 - val_loss: 0.7171 - val_accuracy: 0.1818 - val_true_positives_14: 1.0000 - val_true_negatives_14: 9.0000 - val_false_positives_14: 0.0000e+00 - val_false_negatives_14: 45.0000\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.5083 - true_positives_14: 3.0000 - true_negatives_14: 180.0000 - false_positives_14: 0.0000e+00 - false_negatives_14: 177.0000 - val_loss: 0.7297 - val_accuracy: 0.1818 - val_true_positives_14: 1.0000 - val_true_negatives_14: 9.0000 - val_false_positives_14: 0.0000e+00 - val_false_negatives_14: 45.0000\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.5083 - true_positives_14: 3.0000 - true_negatives_14: 180.0000 - false_positives_14: 0.0000e+00 - false_negatives_14: 177.0000 - val_loss: 0.7359 - val_accuracy: 0.1818 - val_true_positives_14: 1.0000 - val_true_negatives_14: 9.0000 - val_false_positives_14: 0.0000e+00 - val_false_negatives_14: 45.0000\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.4750 - true_positives_14: 13.0000 - true_negatives_14: 158.0000 - false_positives_14: 22.0000 - false_negatives_14: 167.0000 - val_loss: 0.7449 - val_accuracy: 0.1818 - val_true_positives_14: 1.0000 - val_true_negatives_14: 9.0000 - val_false_positives_14: 0.0000e+00 - val_false_negatives_14: 45.0000\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 2s 8ms/step - loss: 3.3387 - accuracy: 0.4667 - true_positives_15: 146.0000 - true_negatives_15: 22.0000 - false_positives_15: 158.0000 - false_negatives_15: 34.0000 - val_loss: 1.0899 - val_accuracy: 0.4545 - val_true_positives_15: 20.0000 - val_true_negatives_15: 5.0000 - val_false_positives_15: 4.0000 - val_false_negatives_15: 26.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.8848 - accuracy: 0.5194 - true_positives_15: 57.0000 - true_negatives_15: 130.0000 - false_positives_15: 50.0000 - false_negatives_15: 123.0000 - val_loss: 0.8362 - val_accuracy: 0.2364 - val_true_positives_15: 7.0000 - val_true_negatives_15: 6.0000 - val_false_positives_15: 3.0000 - val_false_negatives_15: 39.0000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7285 - accuracy: 0.4944 - true_positives_15: 30.0000 - true_negatives_15: 148.0000 - false_positives_15: 32.0000 - false_negatives_15: 150.0000 - val_loss: 0.7380 - val_accuracy: 0.2182 - val_true_positives_15: 5.0000 - val_true_negatives_15: 7.0000 - val_false_positives_15: 2.0000 - val_false_negatives_15: 41.0000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7098 - accuracy: 0.5056 - true_positives_15: 27.0000 - true_negatives_15: 155.0000 - false_positives_15: 25.0000 - false_negatives_15: 153.0000 - val_loss: 0.7493 - val_accuracy: 0.2364 - val_true_positives_15: 6.0000 - val_true_negatives_15: 7.0000 - val_false_positives_15: 2.0000 - val_false_negatives_15: 40.0000\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7014 - accuracy: 0.5167 - true_positives_15: 29.0000 - true_negatives_15: 157.0000 - false_positives_15: 23.0000 - false_negatives_15: 151.0000 - val_loss: 0.7499 - val_accuracy: 0.2364 - val_true_positives_15: 6.0000 - val_true_negatives_15: 7.0000 - val_false_positives_15: 2.0000 - val_false_negatives_15: 40.0000\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6965 - accuracy: 0.5194 - true_positives_15: 28.0000 - true_negatives_15: 159.0000 - false_positives_15: 21.0000 - false_negatives_15: 152.0000 - val_loss: 0.7439 - val_accuracy: 0.2364 - val_true_positives_15: 6.0000 - val_true_negatives_15: 7.0000 - val_false_positives_15: 2.0000 - val_false_negatives_15: 40.0000\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5167 - true_positives_15: 27.0000 - true_negatives_15: 159.0000 - false_positives_15: 21.0000 - false_negatives_15: 153.0000 - val_loss: 0.7499 - val_accuracy: 0.2364 - val_true_positives_15: 6.0000 - val_true_negatives_15: 7.0000 - val_false_positives_15: 2.0000 - val_false_negatives_15: 40.0000\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5250 - true_positives_15: 26.0000 - true_negatives_15: 163.0000 - false_positives_15: 17.0000 - false_negatives_15: 154.0000 - val_loss: 0.7462 - val_accuracy: 0.2364 - val_true_positives_15: 6.0000 - val_true_negatives_15: 7.0000 - val_false_positives_15: 2.0000 - val_false_negatives_15: 40.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 1s 7ms/step - loss: 4.3849 - accuracy: 0.4889 - true_positives_16: 22.0000 - true_negatives_16: 154.0000 - false_positives_16: 26.0000 - false_negatives_16: 158.0000 - val_loss: 0.7009 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.7001 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6998 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6999 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6994 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6975 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6978 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6983 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6978 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6967 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6972 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6960 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6971 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6958 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6970 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6961 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6972 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6952 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 19/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6950 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6958 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6952 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6944 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 23/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6945 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 24/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6944 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 25/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6953 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 26/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6936 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 27/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6945 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 28/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6941 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6945 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "Epoch 30/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_16: 0.0000e+00 - true_negatives_16: 180.0000 - false_positives_16: 0.0000e+00 - false_negatives_16: 180.0000 - val_loss: 0.6943 - val_accuracy: 0.1636 - val_true_positives_16: 0.0000e+00 - val_true_negatives_16: 9.0000 - val_false_positives_16: 0.0000e+00 - val_false_negatives_16: 46.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 1s 8ms/step - loss: 0.6932 - accuracy: 0.4944 - true_positives_17: 171.0000 - true_negatives_17: 7.0000 - false_positives_17: 173.0000 - false_negatives_17: 9.0000 - val_loss: 0.6914 - val_accuracy: 0.8364 - val_true_positives_17: 46.0000 - val_true_negatives_17: 0.0000e+00 - val_false_positives_17: 9.0000 - val_false_negatives_17: 0.0000e+00\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_17: 180.0000 - true_negatives_17: 0.0000e+00 - false_positives_17: 180.0000 - false_negatives_17: 0.0000e+00 - val_loss: 0.6918 - val_accuracy: 0.8364 - val_true_positives_17: 46.0000 - val_true_negatives_17: 0.0000e+00 - val_false_positives_17: 9.0000 - val_false_negatives_17: 0.0000e+00\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_17: 180.0000 - true_negatives_17: 0.0000e+00 - false_positives_17: 180.0000 - false_negatives_17: 0.0000e+00 - val_loss: 0.6928 - val_accuracy: 0.8364 - val_true_positives_17: 46.0000 - val_true_negatives_17: 0.0000e+00 - val_false_positives_17: 9.0000 - val_false_negatives_17: 0.0000e+00\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_17: 180.0000 - true_negatives_17: 0.0000e+00 - false_positives_17: 180.0000 - false_negatives_17: 0.0000e+00 - val_loss: 0.6916 - val_accuracy: 0.8364 - val_true_positives_17: 46.0000 - val_true_negatives_17: 0.0000e+00 - val_false_positives_17: 9.0000 - val_false_negatives_17: 0.0000e+00\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_17: 180.0000 - true_negatives_17: 0.0000e+00 - false_positives_17: 180.0000 - false_negatives_17: 0.0000e+00 - val_loss: 0.6921 - val_accuracy: 0.8364 - val_true_positives_17: 46.0000 - val_true_negatives_17: 0.0000e+00 - val_false_positives_17: 9.0000 - val_false_negatives_17: 0.0000e+00\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4500 - true_positives_17: 99.0000 - true_negatives_17: 63.0000 - false_positives_17: 117.0000 - false_negatives_17: 81.0000 - val_loss: 0.6927 - val_accuracy: 0.8364 - val_true_positives_17: 46.0000 - val_true_negatives_17: 0.0000e+00 - val_false_positives_17: 9.0000 - val_false_negatives_17: 0.0000e+00\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 1s 8ms/step - loss: 4.9520 - accuracy: 0.5056 - true_positives_18: 162.0000 - true_negatives_18: 20.0000 - false_positives_18: 160.0000 - false_negatives_18: 18.0000 - val_loss: 3.6644 - val_accuracy: 0.8000 - val_true_positives_18: 44.0000 - val_true_negatives_18: 0.0000e+00 - val_false_positives_18: 9.0000 - val_false_negatives_18: 2.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 1.1575 - accuracy: 0.5083 - true_positives_18: 177.0000 - true_negatives_18: 6.0000 - false_positives_18: 174.0000 - false_negatives_18: 3.0000 - val_loss: 2.0349 - val_accuracy: 0.8000 - val_true_positives_18: 44.0000 - val_true_negatives_18: 0.0000e+00 - val_false_positives_18: 9.0000 - val_false_negatives_18: 2.0000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7852 - accuracy: 0.5083 - true_positives_18: 179.0000 - true_negatives_18: 4.0000 - false_positives_18: 176.0000 - false_negatives_18: 1.0000 - val_loss: 1.6161 - val_accuracy: 0.8000 - val_true_positives_18: 44.0000 - val_true_negatives_18: 0.0000e+00 - val_false_positives_18: 9.0000 - val_false_negatives_18: 2.0000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7378 - accuracy: 0.5056 - true_positives_18: 179.0000 - true_negatives_18: 3.0000 - false_positives_18: 177.0000 - false_negatives_18: 1.0000 - val_loss: 1.3783 - val_accuracy: 0.8000 - val_true_positives_18: 44.0000 - val_true_negatives_18: 0.0000e+00 - val_false_positives_18: 9.0000 - val_false_negatives_18: 2.0000\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7090 - accuracy: 0.4972 - true_positives_18: 179.0000 - true_negatives_18: 0.0000e+00 - false_positives_18: 180.0000 - false_negatives_18: 1.0000 - val_loss: 0.8521 - val_accuracy: 0.8000 - val_true_positives_18: 44.0000 - val_true_negatives_18: 0.0000e+00 - val_false_positives_18: 9.0000 - val_false_negatives_18: 2.0000\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_18: 180.0000 - true_negatives_18: 0.0000e+00 - false_positives_18: 180.0000 - false_negatives_18: 0.0000e+00 - val_loss: 0.7000 - val_accuracy: 0.8182 - val_true_positives_18: 45.0000 - val_true_negatives_18: 0.0000e+00 - val_false_positives_18: 9.0000 - val_false_negatives_18: 1.0000\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_18: 180.0000 - true_negatives_18: 0.0000e+00 - false_positives_18: 180.0000 - false_negatives_18: 0.0000e+00 - val_loss: 0.7001 - val_accuracy: 0.8182 - val_true_positives_18: 45.0000 - val_true_negatives_18: 0.0000e+00 - val_false_positives_18: 9.0000 - val_false_negatives_18: 1.0000\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_18: 180.0000 - true_negatives_18: 0.0000e+00 - false_positives_18: 180.0000 - false_negatives_18: 0.0000e+00 - val_loss: 0.7006 - val_accuracy: 0.8182 - val_true_positives_18: 45.0000 - val_true_negatives_18: 0.0000e+00 - val_false_positives_18: 9.0000 - val_false_negatives_18: 1.0000\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_18: 180.0000 - true_negatives_18: 0.0000e+00 - false_positives_18: 180.0000 - false_negatives_18: 0.0000e+00 - val_loss: 0.7010 - val_accuracy: 0.8182 - val_true_positives_18: 45.0000 - val_true_negatives_18: 0.0000e+00 - val_false_positives_18: 9.0000 - val_false_negatives_18: 1.0000\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_18: 180.0000 - true_negatives_18: 0.0000e+00 - false_positives_18: 180.0000 - false_negatives_18: 0.0000e+00 - val_loss: 0.7008 - val_accuracy: 0.8182 - val_true_positives_18: 45.0000 - val_true_negatives_18: 0.0000e+00 - val_false_positives_18: 9.0000 - val_false_negatives_18: 1.0000\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_18: 180.0000 - true_negatives_18: 0.0000e+00 - false_positives_18: 180.0000 - false_negatives_18: 0.0000e+00 - val_loss: 0.6998 - val_accuracy: 0.8182 - val_true_positives_18: 45.0000 - val_true_negatives_18: 0.0000e+00 - val_false_positives_18: 9.0000 - val_false_negatives_18: 1.0000\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_18: 180.0000 - true_negatives_18: 0.0000e+00 - false_positives_18: 180.0000 - false_negatives_18: 0.0000e+00 - val_loss: 0.7010 - val_accuracy: 0.8182 - val_true_positives_18: 45.0000 - val_true_negatives_18: 0.0000e+00 - val_false_positives_18: 9.0000 - val_false_negatives_18: 1.0000\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_18: 180.0000 - true_negatives_18: 0.0000e+00 - false_positives_18: 180.0000 - false_negatives_18: 0.0000e+00 - val_loss: 0.7016 - val_accuracy: 0.8182 - val_true_positives_18: 45.0000 - val_true_negatives_18: 0.0000e+00 - val_false_positives_18: 9.0000 - val_false_negatives_18: 1.0000\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_18: 180.0000 - true_negatives_18: 0.0000e+00 - false_positives_18: 180.0000 - false_negatives_18: 0.0000e+00 - val_loss: 0.7012 - val_accuracy: 0.8182 - val_true_positives_18: 45.0000 - val_true_negatives_18: 0.0000e+00 - val_false_positives_18: 9.0000 - val_false_negatives_18: 1.0000\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_18: 180.0000 - true_negatives_18: 0.0000e+00 - false_positives_18: 180.0000 - false_negatives_18: 0.0000e+00 - val_loss: 0.7009 - val_accuracy: 0.8182 - val_true_positives_18: 45.0000 - val_true_negatives_18: 0.0000e+00 - val_false_positives_18: 9.0000 - val_false_negatives_18: 1.0000\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_18: 180.0000 - true_negatives_18: 0.0000e+00 - false_positives_18: 180.0000 - false_negatives_18: 0.0000e+00 - val_loss: 0.7007 - val_accuracy: 0.8182 - val_true_positives_18: 45.0000 - val_true_negatives_18: 0.0000e+00 - val_false_positives_18: 9.0000 - val_false_negatives_18: 1.0000\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 1s 8ms/step - loss: 16.0990 - accuracy: 0.4667 - true_positives_19: 60.0000 - true_negatives_19: 108.0000 - false_positives_19: 72.0000 - false_negatives_19: 120.0000 - val_loss: 3.0299 - val_accuracy: 0.6727 - val_true_positives_19: 31.0000 - val_true_negatives_19: 6.0000 - val_false_positives_19: 3.0000 - val_false_negatives_19: 15.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.6057 - accuracy: 0.4056 - true_positives_19: 113.0000 - true_negatives_19: 33.0000 - false_positives_19: 147.0000 - false_negatives_19: 67.0000 - val_loss: 2.5319 - val_accuracy: 0.7455 - val_true_positives_19: 36.0000 - val_true_negatives_19: 5.0000 - val_false_positives_19: 4.0000 - val_false_negatives_19: 10.0000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 1.6977 - accuracy: 0.4417 - true_positives_19: 117.0000 - true_negatives_19: 42.0000 - false_positives_19: 138.0000 - false_negatives_19: 63.0000 - val_loss: 0.6595 - val_accuracy: 0.8545 - val_true_positives_19: 46.0000 - val_true_negatives_19: 1.0000 - val_false_positives_19: 8.0000 - val_false_negatives_19: 0.0000e+00\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5083 - true_positives_19: 180.0000 - true_negatives_19: 3.0000 - false_positives_19: 177.0000 - false_negatives_19: 0.0000e+00 - val_loss: 0.6598 - val_accuracy: 0.8545 - val_true_positives_19: 46.0000 - val_true_negatives_19: 1.0000 - val_false_positives_19: 8.0000 - val_false_negatives_19: 0.0000e+00\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5083 - true_positives_19: 180.0000 - true_negatives_19: 3.0000 - false_positives_19: 177.0000 - false_negatives_19: 0.0000e+00 - val_loss: 0.6594 - val_accuracy: 0.8545 - val_true_positives_19: 46.0000 - val_true_negatives_19: 1.0000 - val_false_positives_19: 8.0000 - val_false_negatives_19: 0.0000e+00\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5083 - true_positives_19: 180.0000 - true_negatives_19: 3.0000 - false_positives_19: 177.0000 - false_negatives_19: 0.0000e+00 - val_loss: 0.6601 - val_accuracy: 0.8545 - val_true_positives_19: 46.0000 - val_true_negatives_19: 1.0000 - val_false_positives_19: 8.0000 - val_false_negatives_19: 0.0000e+00\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5083 - true_positives_19: 180.0000 - true_negatives_19: 3.0000 - false_positives_19: 177.0000 - false_negatives_19: 0.0000e+00 - val_loss: 0.6611 - val_accuracy: 0.8545 - val_true_positives_19: 46.0000 - val_true_negatives_19: 1.0000 - val_false_positives_19: 8.0000 - val_false_negatives_19: 0.0000e+00\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5083 - true_positives_19: 180.0000 - true_negatives_19: 3.0000 - false_positives_19: 177.0000 - false_negatives_19: 0.0000e+00 - val_loss: 0.6624 - val_accuracy: 0.8545 - val_true_positives_19: 46.0000 - val_true_negatives_19: 1.0000 - val_false_positives_19: 8.0000 - val_false_negatives_19: 0.0000e+00\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5083 - true_positives_19: 180.0000 - true_negatives_19: 3.0000 - false_positives_19: 177.0000 - false_negatives_19: 0.0000e+00 - val_loss: 0.6622 - val_accuracy: 0.8545 - val_true_positives_19: 46.0000 - val_true_negatives_19: 1.0000 - val_false_positives_19: 8.0000 - val_false_negatives_19: 0.0000e+00\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5083 - true_positives_19: 180.0000 - true_negatives_19: 3.0000 - false_positives_19: 177.0000 - false_negatives_19: 0.0000e+00 - val_loss: 0.6631 - val_accuracy: 0.8545 - val_true_positives_19: 46.0000 - val_true_negatives_19: 1.0000 - val_false_positives_19: 8.0000 - val_false_negatives_19: 0.0000e+00\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 1s 8ms/step - loss: 15.7379 - accuracy: 0.4972 - true_positives_20: 120.0000 - true_negatives_20: 59.0000 - false_positives_20: 121.0000 - false_negatives_20: 60.0000 - val_loss: 1.0196 - val_accuracy: 0.7455 - val_true_positives_20: 41.0000 - val_true_negatives_20: 0.0000e+00 - val_false_positives_20: 9.0000 - val_false_negatives_20: 5.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7338 - accuracy: 0.5167 - true_positives_20: 178.0000 - true_negatives_20: 8.0000 - false_positives_20: 172.0000 - false_negatives_20: 2.0000 - val_loss: 0.6827 - val_accuracy: 0.8364 - val_true_positives_20: 46.0000 - val_true_negatives_20: 0.0000e+00 - val_false_positives_20: 9.0000 - val_false_negatives_20: 0.0000e+00\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7264 - accuracy: 0.5083 - true_positives_20: 179.0000 - true_negatives_20: 4.0000 - false_positives_20: 176.0000 - false_negatives_20: 1.0000 - val_loss: 0.6829 - val_accuracy: 0.8364 - val_true_positives_20: 46.0000 - val_true_negatives_20: 0.0000e+00 - val_false_positives_20: 9.0000 - val_false_negatives_20: 0.0000e+00\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7068 - accuracy: 0.5083 - true_positives_20: 179.0000 - true_negatives_20: 4.0000 - false_positives_20: 176.0000 - false_negatives_20: 1.0000 - val_loss: 0.6827 - val_accuracy: 0.8364 - val_true_positives_20: 46.0000 - val_true_negatives_20: 0.0000e+00 - val_false_positives_20: 9.0000 - val_false_negatives_20: 0.0000e+00\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5083 - true_positives_20: 179.0000 - true_negatives_20: 4.0000 - false_positives_20: 176.0000 - false_negatives_20: 1.0000 - val_loss: 0.6835 - val_accuracy: 0.8364 - val_true_positives_20: 46.0000 - val_true_negatives_20: 0.0000e+00 - val_false_positives_20: 9.0000 - val_false_negatives_20: 0.0000e+00\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.5028 - true_positives_20: 179.0000 - true_negatives_20: 2.0000 - false_positives_20: 178.0000 - false_negatives_20: 1.0000 - val_loss: 0.6841 - val_accuracy: 0.8364 - val_true_positives_20: 46.0000 - val_true_negatives_20: 0.0000e+00 - val_false_positives_20: 9.0000 - val_false_negatives_20: 0.0000e+00\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_20: 180.0000 - true_negatives_20: 0.0000e+00 - false_positives_20: 180.0000 - false_negatives_20: 0.0000e+00 - val_loss: 0.6847 - val_accuracy: 0.8364 - val_true_positives_20: 46.0000 - val_true_negatives_20: 0.0000e+00 - val_false_positives_20: 9.0000 - val_false_negatives_20: 0.0000e+00\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_20: 180.0000 - true_negatives_20: 0.0000e+00 - false_positives_20: 180.0000 - false_negatives_20: 0.0000e+00 - val_loss: 0.6845 - val_accuracy: 0.8364 - val_true_positives_20: 46.0000 - val_true_negatives_20: 0.0000e+00 - val_false_positives_20: 9.0000 - val_false_negatives_20: 0.0000e+00\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_20: 180.0000 - true_negatives_20: 0.0000e+00 - false_positives_20: 180.0000 - false_negatives_20: 0.0000e+00 - val_loss: 0.6844 - val_accuracy: 0.8364 - val_true_positives_20: 46.0000 - val_true_negatives_20: 0.0000e+00 - val_false_positives_20: 9.0000 - val_false_negatives_20: 0.0000e+00\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 2s 8ms/step - loss: 148.5615 - accuracy: 0.5056 - true_positives_21: 103.0000 - true_negatives_21: 79.0000 - false_positives_21: 101.0000 - false_negatives_21: 77.0000 - val_loss: 82.2689 - val_accuracy: 0.3091 - val_true_positives_21: 9.0000 - val_true_negatives_21: 8.0000 - val_false_positives_21: 1.0000 - val_false_negatives_21: 37.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 26.2036 - accuracy: 0.5167 - true_positives_21: 67.0000 - true_negatives_21: 119.0000 - false_positives_21: 61.0000 - false_negatives_21: 113.0000 - val_loss: 25.7834 - val_accuracy: 0.5273 - val_true_positives_21: 25.0000 - val_true_negatives_21: 4.0000 - val_false_positives_21: 5.0000 - val_false_negatives_21: 21.0000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.2428 - accuracy: 0.5111 - true_positives_21: 92.0000 - true_negatives_21: 92.0000 - false_positives_21: 88.0000 - false_negatives_21: 88.0000 - val_loss: 16.5682 - val_accuracy: 0.4909 - val_true_positives_21: 24.0000 - val_true_negatives_21: 3.0000 - val_false_positives_21: 6.0000 - val_false_negatives_21: 22.0000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.7226 - accuracy: 0.5333 - true_positives_21: 112.0000 - true_negatives_21: 80.0000 - false_positives_21: 100.0000 - false_negatives_21: 68.0000 - val_loss: 11.7065 - val_accuracy: 0.6545 - val_true_positives_21: 34.0000 - val_true_negatives_21: 2.0000 - val_false_positives_21: 7.0000 - val_false_negatives_21: 12.0000\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 5.9788 - accuracy: 0.5750 - true_positives_21: 115.0000 - true_negatives_21: 92.0000 - false_positives_21: 88.0000 - false_negatives_21: 65.0000 - val_loss: 9.6916 - val_accuracy: 0.5636 - val_true_positives_21: 28.0000 - val_true_negatives_21: 3.0000 - val_false_positives_21: 6.0000 - val_false_negatives_21: 18.0000\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 4.1716 - accuracy: 0.5556 - true_positives_21: 115.0000 - true_negatives_21: 85.0000 - false_positives_21: 95.0000 - false_negatives_21: 65.0000 - val_loss: 11.9040 - val_accuracy: 0.6727 - val_true_positives_21: 35.0000 - val_true_negatives_21: 2.0000 - val_false_positives_21: 7.0000 - val_false_negatives_21: 11.0000\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.9222 - accuracy: 0.5667 - true_positives_21: 119.0000 - true_negatives_21: 85.0000 - false_positives_21: 95.0000 - false_negatives_21: 61.0000 - val_loss: 11.5893 - val_accuracy: 0.3273 - val_true_positives_21: 11.0000 - val_true_negatives_21: 7.0000 - val_false_positives_21: 2.0000 - val_false_negatives_21: 35.0000\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 5.2762 - accuracy: 0.6028 - true_positives_21: 111.0000 - true_negatives_21: 106.0000 - false_positives_21: 74.0000 - false_negatives_21: 69.0000 - val_loss: 12.4964 - val_accuracy: 0.4909 - val_true_positives_21: 22.0000 - val_true_negatives_21: 5.0000 - val_false_positives_21: 4.0000 - val_false_negatives_21: 24.0000\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 3.3662 - accuracy: 0.5833 - true_positives_21: 96.0000 - true_negatives_21: 114.0000 - false_positives_21: 66.0000 - false_negatives_21: 84.0000 - val_loss: 9.0555 - val_accuracy: 0.5273 - val_true_positives_21: 25.0000 - val_true_negatives_21: 4.0000 - val_false_positives_21: 5.0000 - val_false_negatives_21: 21.0000\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 3.8797 - accuracy: 0.5722 - true_positives_21: 81.0000 - true_negatives_21: 125.0000 - false_positives_21: 55.0000 - false_negatives_21: 99.0000 - val_loss: 8.4624 - val_accuracy: 0.3636 - val_true_positives_21: 15.0000 - val_true_negatives_21: 5.0000 - val_false_positives_21: 4.0000 - val_false_negatives_21: 31.0000\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 3.0020 - accuracy: 0.5750 - true_positives_21: 83.0000 - true_negatives_21: 124.0000 - false_positives_21: 56.0000 - false_negatives_21: 97.0000 - val_loss: 6.3965 - val_accuracy: 0.4545 - val_true_positives_21: 21.0000 - val_true_negatives_21: 4.0000 - val_false_positives_21: 5.0000 - val_false_negatives_21: 25.0000\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 4.0195 - accuracy: 0.5528 - true_positives_21: 87.0000 - true_negatives_21: 112.0000 - false_positives_21: 68.0000 - false_negatives_21: 93.0000 - val_loss: 7.3961 - val_accuracy: 0.4000 - val_true_positives_21: 17.0000 - val_true_negatives_21: 5.0000 - val_false_positives_21: 4.0000 - val_false_negatives_21: 29.0000\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 3.8459 - accuracy: 0.5750 - true_positives_21: 78.0000 - true_negatives_21: 129.0000 - false_positives_21: 51.0000 - false_negatives_21: 102.0000 - val_loss: 6.1280 - val_accuracy: 0.3636 - val_true_positives_21: 15.0000 - val_true_negatives_21: 5.0000 - val_false_positives_21: 4.0000 - val_false_negatives_21: 31.0000\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.9699 - accuracy: 0.6167 - true_positives_21: 86.0000 - true_negatives_21: 136.0000 - false_positives_21: 44.0000 - false_negatives_21: 94.0000 - val_loss: 6.6724 - val_accuracy: 0.4545 - val_true_positives_21: 21.0000 - val_true_negatives_21: 4.0000 - val_false_positives_21: 5.0000 - val_false_negatives_21: 25.0000\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 3.2716 - accuracy: 0.5750 - true_positives_21: 84.0000 - true_negatives_21: 123.0000 - false_positives_21: 57.0000 - false_negatives_21: 96.0000 - val_loss: 7.8440 - val_accuracy: 0.5273 - val_true_positives_21: 25.0000 - val_true_negatives_21: 4.0000 - val_false_positives_21: 5.0000 - val_false_negatives_21: 21.0000\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.2992 - accuracy: 0.6278 - true_positives_21: 85.0000 - true_negatives_21: 141.0000 - false_positives_21: 39.0000 - false_negatives_21: 95.0000 - val_loss: 9.6200 - val_accuracy: 0.3091 - val_true_positives_21: 11.0000 - val_true_negatives_21: 6.0000 - val_false_positives_21: 3.0000 - val_false_negatives_21: 35.0000\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 3.8241 - accuracy: 0.5861 - true_positives_21: 87.0000 - true_negatives_21: 124.0000 - false_positives_21: 56.0000 - false_negatives_21: 93.0000 - val_loss: 7.9061 - val_accuracy: 0.3818 - val_true_positives_21: 16.0000 - val_true_negatives_21: 5.0000 - val_false_positives_21: 4.0000 - val_false_negatives_21: 30.0000\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 3.6483 - accuracy: 0.5833 - true_positives_21: 72.0000 - true_negatives_21: 138.0000 - false_positives_21: 42.0000 - false_negatives_21: 108.0000 - val_loss: 4.9637 - val_accuracy: 0.4182 - val_true_positives_21: 19.0000 - val_true_negatives_21: 4.0000 - val_false_positives_21: 5.0000 - val_false_negatives_21: 27.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.6725 - accuracy: 0.5500 - true_positives_21: 79.0000 - true_negatives_21: 119.0000 - false_positives_21: 61.0000 - false_negatives_21: 101.0000 - val_loss: 5.7842 - val_accuracy: 0.5091 - val_true_positives_21: 24.0000 - val_true_negatives_21: 4.0000 - val_false_positives_21: 5.0000 - val_false_negatives_21: 22.0000\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.7939 - accuracy: 0.5778 - true_positives_21: 80.0000 - true_negatives_21: 128.0000 - false_positives_21: 52.0000 - false_negatives_21: 100.0000 - val_loss: 4.6187 - val_accuracy: 0.4727 - val_true_positives_21: 22.0000 - val_true_negatives_21: 4.0000 - val_false_positives_21: 5.0000 - val_false_negatives_21: 24.0000\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 3.0345 - accuracy: 0.5583 - true_positives_21: 87.0000 - true_negatives_21: 114.0000 - false_positives_21: 66.0000 - false_negatives_21: 93.0000 - val_loss: 5.5346 - val_accuracy: 0.4545 - val_true_positives_21: 20.0000 - val_true_negatives_21: 5.0000 - val_false_positives_21: 4.0000 - val_false_negatives_21: 26.0000\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.7412 - accuracy: 0.5778 - true_positives_21: 69.0000 - true_negatives_21: 139.0000 - false_positives_21: 41.0000 - false_negatives_21: 111.0000 - val_loss: 7.0201 - val_accuracy: 0.5455 - val_true_positives_21: 26.0000 - val_true_negatives_21: 4.0000 - val_false_positives_21: 5.0000 - val_false_negatives_21: 20.0000\n",
      "Epoch 23/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.4853 - accuracy: 0.5917 - true_positives_21: 79.0000 - true_negatives_21: 134.0000 - false_positives_21: 46.0000 - false_negatives_21: 101.0000 - val_loss: 5.2943 - val_accuracy: 0.4545 - val_true_positives_21: 19.0000 - val_true_negatives_21: 6.0000 - val_false_positives_21: 3.0000 - val_false_negatives_21: 27.0000\n",
      "Epoch 24/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 1.5695 - accuracy: 0.6056 - true_positives_21: 80.0000 - true_negatives_21: 138.0000 - false_positives_21: 42.0000 - false_negatives_21: 100.0000 - val_loss: 2.6869 - val_accuracy: 0.4545 - val_true_positives_21: 20.0000 - val_true_negatives_21: 5.0000 - val_false_positives_21: 4.0000 - val_false_negatives_21: 26.0000\n",
      "Epoch 25/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.3380 - accuracy: 0.5944 - true_positives_21: 81.0000 - true_negatives_21: 133.0000 - false_positives_21: 47.0000 - false_negatives_21: 99.0000 - val_loss: 5.5505 - val_accuracy: 0.4909 - val_true_positives_21: 22.0000 - val_true_negatives_21: 5.0000 - val_false_positives_21: 4.0000 - val_false_negatives_21: 24.0000\n",
      "Epoch 26/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.1161 - accuracy: 0.6056 - true_positives_21: 78.0000 - true_negatives_21: 140.0000 - false_positives_21: 40.0000 - false_negatives_21: 102.0000 - val_loss: 6.9067 - val_accuracy: 0.4000 - val_true_positives_21: 13.0000 - val_true_negatives_21: 9.0000 - val_false_positives_21: 0.0000e+00 - val_false_negatives_21: 33.0000\n",
      "Epoch 27/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.3148 - accuracy: 0.5917 - true_positives_21: 77.0000 - true_negatives_21: 136.0000 - false_positives_21: 44.0000 - false_negatives_21: 103.0000 - val_loss: 3.5850 - val_accuracy: 0.2364 - val_true_positives_21: 8.0000 - val_true_negatives_21: 5.0000 - val_false_positives_21: 4.0000 - val_false_negatives_21: 38.0000\n",
      "Epoch 28/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 1.7785 - accuracy: 0.5917 - true_positives_21: 80.0000 - true_negatives_21: 133.0000 - false_positives_21: 47.0000 - false_negatives_21: 100.0000 - val_loss: 8.1302 - val_accuracy: 0.4000 - val_true_positives_21: 17.0000 - val_true_negatives_21: 5.0000 - val_false_positives_21: 4.0000 - val_false_negatives_21: 29.0000\n",
      "Epoch 29/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.6711 - accuracy: 0.5972 - true_positives_21: 63.0000 - true_negatives_21: 152.0000 - false_positives_21: 28.0000 - false_negatives_21: 117.0000 - val_loss: 2.7224 - val_accuracy: 0.4000 - val_true_positives_21: 14.0000 - val_true_negatives_21: 8.0000 - val_false_positives_21: 1.0000 - val_false_negatives_21: 32.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: -0.01103311953251251.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 1s 8ms/step - loss: 153.9737 - accuracy: 0.5000 - true_positives_22: 0.0000e+00 - true_negatives_22: 180.0000 - false_positives_22: 0.0000e+00 - false_negatives_22: 180.0000 - val_loss: 135.4830 - val_accuracy: 0.1818 - val_true_positives_22: 0.0000e+00 - val_true_negatives_22: 10.0000 - val_false_positives_22: 0.0000e+00 - val_false_negatives_22: 45.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 45.8307 - accuracy: 0.5000 - true_positives_22: 0.0000e+00 - true_negatives_22: 180.0000 - false_positives_22: 0.0000e+00 - false_negatives_22: 180.0000 - val_loss: 33.8613 - val_accuracy: 0.1818 - val_true_positives_22: 0.0000e+00 - val_true_negatives_22: 10.0000 - val_false_positives_22: 0.0000e+00 - val_false_negatives_22: 45.0000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.1501 - accuracy: 0.5083 - true_positives_22: 16.0000 - true_negatives_22: 167.0000 - false_positives_22: 13.0000 - false_negatives_22: 164.0000 - val_loss: 5.2372 - val_accuracy: 0.3091 - val_true_positives_22: 10.0000 - val_true_negatives_22: 7.0000 - val_false_positives_22: 3.0000 - val_false_negatives_22: 35.0000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 3.1821 - accuracy: 0.4917 - true_positives_22: 63.0000 - true_negatives_22: 114.0000 - false_positives_22: 66.0000 - false_negatives_22: 117.0000 - val_loss: 2.5496 - val_accuracy: 0.4545 - val_true_positives_22: 19.0000 - val_true_negatives_22: 6.0000 - val_false_positives_22: 4.0000 - val_false_negatives_22: 26.0000\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 1.7518 - accuracy: 0.5000 - true_positives_22: 103.0000 - true_negatives_22: 77.0000 - false_positives_22: 103.0000 - false_negatives_22: 77.0000 - val_loss: 2.4854 - val_accuracy: 0.4909 - val_true_positives_22: 23.0000 - val_true_negatives_22: 4.0000 - val_false_positives_22: 6.0000 - val_false_negatives_22: 22.0000\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 1.4241 - accuracy: 0.4833 - true_positives_22: 119.0000 - true_negatives_22: 55.0000 - false_positives_22: 125.0000 - false_negatives_22: 61.0000 - val_loss: 1.8543 - val_accuracy: 0.5273 - val_true_positives_22: 26.0000 - val_true_negatives_22: 3.0000 - val_false_positives_22: 7.0000 - val_false_negatives_22: 19.0000\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 1.2558 - accuracy: 0.4778 - true_positives_22: 130.0000 - true_negatives_22: 42.0000 - false_positives_22: 138.0000 - false_negatives_22: 50.0000 - val_loss: 0.9002 - val_accuracy: 0.6545 - val_true_positives_22: 32.0000 - val_true_negatives_22: 4.0000 - val_false_positives_22: 6.0000 - val_false_negatives_22: 13.0000\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.9489 - accuracy: 0.5222 - true_positives_22: 140.0000 - true_negatives_22: 48.0000 - false_positives_22: 132.0000 - false_negatives_22: 40.0000 - val_loss: 0.7306 - val_accuracy: 0.6909 - val_true_positives_22: 34.0000 - val_true_negatives_22: 4.0000 - val_false_positives_22: 6.0000 - val_false_negatives_22: 11.0000\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.8935 - accuracy: 0.4889 - true_positives_22: 150.0000 - true_negatives_22: 26.0000 - false_positives_22: 154.0000 - false_negatives_22: 30.0000 - val_loss: 0.7706 - val_accuracy: 0.6545 - val_true_positives_22: 33.0000 - val_true_negatives_22: 3.0000 - val_false_positives_22: 7.0000 - val_false_negatives_22: 12.0000\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 2ms/step - loss: 0.8365 - accuracy: 0.4750 - true_positives_22: 149.0000 - true_negatives_22: 22.0000 - false_positives_22: 158.0000 - false_negatives_22: 31.0000 - val_loss: 0.7062 - val_accuracy: 0.7455 - val_true_positives_22: 39.0000 - val_true_negatives_22: 2.0000 - val_false_positives_22: 8.0000 - val_false_negatives_22: 6.0000\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7582 - accuracy: 0.4639 - true_positives_22: 151.0000 - true_negatives_22: 16.0000 - false_positives_22: 164.0000 - false_negatives_22: 29.0000 - val_loss: 0.6880 - val_accuracy: 0.6909 - val_true_positives_22: 37.0000 - val_true_negatives_22: 1.0000 - val_false_positives_22: 9.0000 - val_false_negatives_22: 8.0000\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7337 - accuracy: 0.4889 - true_positives_22: 162.0000 - true_negatives_22: 14.0000 - false_positives_22: 166.0000 - false_negatives_22: 18.0000 - val_loss: 0.6593 - val_accuracy: 0.7636 - val_true_positives_22: 41.0000 - val_true_negatives_22: 1.0000 - val_false_positives_22: 9.0000 - val_false_negatives_22: 4.0000\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7008 - accuracy: 0.4833 - true_positives_22: 163.0000 - true_negatives_22: 11.0000 - false_positives_22: 169.0000 - false_negatives_22: 17.0000 - val_loss: 0.6647 - val_accuracy: 0.7636 - val_true_positives_22: 41.0000 - val_true_negatives_22: 1.0000 - val_false_positives_22: 9.0000 - val_false_negatives_22: 4.0000\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7054 - accuracy: 0.4889 - true_positives_22: 164.0000 - true_negatives_22: 12.0000 - false_positives_22: 168.0000 - false_negatives_22: 16.0000 - val_loss: 0.6606 - val_accuracy: 0.7636 - val_true_positives_22: 41.0000 - val_true_negatives_22: 1.0000 - val_false_positives_22: 9.0000 - val_false_negatives_22: 4.0000\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.4944 - true_positives_22: 167.0000 - true_negatives_22: 11.0000 - false_positives_22: 169.0000 - false_negatives_22: 13.0000 - val_loss: 0.6562 - val_accuracy: 0.8000 - val_true_positives_22: 43.0000 - val_true_negatives_22: 1.0000 - val_false_positives_22: 9.0000 - val_false_negatives_22: 2.0000\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5028 - true_positives_22: 171.0000 - true_negatives_22: 10.0000 - false_positives_22: 170.0000 - false_negatives_22: 9.0000 - val_loss: 0.6550 - val_accuracy: 0.8000 - val_true_positives_22: 43.0000 - val_true_negatives_22: 1.0000 - val_false_positives_22: 9.0000 - val_false_negatives_22: 2.0000\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4972 - true_positives_22: 171.0000 - true_negatives_22: 8.0000 - false_positives_22: 172.0000 - false_negatives_22: 9.0000 - val_loss: 0.6560 - val_accuracy: 0.7818 - val_true_positives_22: 42.0000 - val_true_negatives_22: 1.0000 - val_false_positives_22: 9.0000 - val_false_negatives_22: 3.0000\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5056 - true_positives_22: 174.0000 - true_negatives_22: 8.0000 - false_positives_22: 172.0000 - false_negatives_22: 6.0000 - val_loss: 0.6514 - val_accuracy: 0.8000 - val_true_positives_22: 43.0000 - val_true_negatives_22: 1.0000 - val_false_positives_22: 9.0000 - val_false_negatives_22: 2.0000\n",
      "Epoch 19/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7053 - accuracy: 0.5111 - true_positives_22: 174.0000 - true_negatives_22: 10.0000 - false_positives_22: 170.0000 - false_negatives_22: 6.0000 - val_loss: 0.7124 - val_accuracy: 0.7636 - val_true_positives_22: 41.0000 - val_true_negatives_22: 1.0000 - val_false_positives_22: 9.0000 - val_false_negatives_22: 4.0000\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7119 - accuracy: 0.5028 - true_positives_22: 170.0000 - true_negatives_22: 11.0000 - false_positives_22: 169.0000 - false_negatives_22: 10.0000 - val_loss: 0.6488 - val_accuracy: 0.8182 - val_true_positives_22: 44.0000 - val_true_negatives_22: 1.0000 - val_false_positives_22: 9.0000 - val_false_negatives_22: 1.0000\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5056 - true_positives_22: 175.0000 - true_negatives_22: 7.0000 - false_positives_22: 173.0000 - false_negatives_22: 5.0000 - val_loss: 0.6660 - val_accuracy: 0.7818 - val_true_positives_22: 43.0000 - val_true_negatives_22: 0.0000e+00 - val_false_positives_22: 10.0000 - val_false_negatives_22: 2.0000\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5083 - true_positives_22: 176.0000 - true_negatives_22: 7.0000 - false_positives_22: 173.0000 - false_negatives_22: 4.0000 - val_loss: 0.6589 - val_accuracy: 0.8000 - val_true_positives_22: 43.0000 - val_true_negatives_22: 1.0000 - val_false_positives_22: 9.0000 - val_false_negatives_22: 2.0000\n",
      "Epoch 23/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.5083 - true_positives_22: 177.0000 - true_negatives_22: 6.0000 - false_positives_22: 174.0000 - false_negatives_22: 3.0000 - val_loss: 0.6686 - val_accuracy: 0.7818 - val_true_positives_22: 43.0000 - val_true_negatives_22: 0.0000e+00 - val_false_positives_22: 10.0000 - val_false_negatives_22: 2.0000\n",
      "Epoch 24/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5083 - true_positives_22: 176.0000 - true_negatives_22: 7.0000 - false_positives_22: 173.0000 - false_negatives_22: 4.0000 - val_loss: 0.6608 - val_accuracy: 0.8000 - val_true_positives_22: 43.0000 - val_true_negatives_22: 1.0000 - val_false_positives_22: 9.0000 - val_false_negatives_22: 2.0000\n",
      "Epoch 25/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5000 - true_positives_22: 174.0000 - true_negatives_22: 6.0000 - false_positives_22: 174.0000 - false_negatives_22: 6.0000 - val_loss: 0.6715 - val_accuracy: 0.7818 - val_true_positives_22: 43.0000 - val_true_negatives_22: 0.0000e+00 - val_false_positives_22: 10.0000 - val_false_negatives_22: 2.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 1s 7ms/step - loss: 1.1780 - accuracy: 0.4797 - true_positives_23: 169.0000 - true_negatives_23: 8.0000 - false_positives_23: 181.0000 - false_negatives_23: 11.0000 - val_loss: 0.6900 - val_accuracy: 0.8364 - val_true_positives_23: 46.0000 - val_true_negatives_23: 0.0000e+00 - val_false_positives_23: 9.0000 - val_false_negatives_23: 0.0000e+00\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4688 - true_positives_23: 100.0000 - true_negatives_23: 73.0000 - false_positives_23: 116.0000 - false_negatives_23: 80.0000 - val_loss: 0.6936 - val_accuracy: 0.1636 - val_true_positives_23: 0.0000e+00 - val_true_negatives_23: 9.0000 - val_false_positives_23: 0.0000e+00 - val_false_negatives_23: 46.0000\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5122 - true_positives_23: 0.0000e+00 - true_negatives_23: 189.0000 - false_positives_23: 0.0000e+00 - false_negatives_23: 180.0000 - val_loss: 0.6945 - val_accuracy: 0.1636 - val_true_positives_23: 0.0000e+00 - val_true_negatives_23: 9.0000 - val_false_positives_23: 0.0000e+00 - val_false_negatives_23: 46.0000\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5122 - true_positives_23: 0.0000e+00 - true_negatives_23: 189.0000 - false_positives_23: 0.0000e+00 - false_negatives_23: 180.0000 - val_loss: 0.6947 - val_accuracy: 0.1636 - val_true_positives_23: 0.0000e+00 - val_true_negatives_23: 9.0000 - val_false_positives_23: 0.0000e+00 - val_false_negatives_23: 46.0000\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5122 - true_positives_23: 0.0000e+00 - true_negatives_23: 189.0000 - false_positives_23: 0.0000e+00 - false_negatives_23: 180.0000 - val_loss: 0.6961 - val_accuracy: 0.1636 - val_true_positives_23: 0.0000e+00 - val_true_negatives_23: 9.0000 - val_false_positives_23: 0.0000e+00 - val_false_negatives_23: 46.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5122 - true_positives_23: 0.0000e+00 - true_negatives_23: 189.0000 - false_positives_23: 0.0000e+00 - false_negatives_23: 180.0000 - val_loss: 0.6963 - val_accuracy: 0.1636 - val_true_positives_23: 0.0000e+00 - val_true_negatives_23: 9.0000 - val_false_positives_23: 0.0000e+00 - val_false_negatives_23: 46.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 1s 7ms/step - loss: 284.8911 - accuracy: 0.5161 - true_positives_24: 0.0000e+00 - true_negatives_24: 192.0000 - false_positives_24: 0.0000e+00 - false_negatives_24: 180.0000 - val_loss: 245.5353 - val_accuracy: 0.1636 - val_true_positives_24: 0.0000e+00 - val_true_negatives_24: 9.0000 - val_false_positives_24: 0.0000e+00 - val_false_negatives_24: 46.0000\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 64.1657 - accuracy: 0.5108 - true_positives_24: 5.0000 - true_negatives_24: 185.0000 - false_positives_24: 7.0000 - false_negatives_24: 175.0000 - val_loss: 9.2148 - val_accuracy: 0.3455 - val_true_positives_24: 10.0000 - val_true_negatives_24: 9.0000 - val_false_positives_24: 0.0000e+00 - val_false_negatives_24: 36.0000\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.8326 - accuracy: 0.4946 - true_positives_24: 63.0000 - true_negatives_24: 121.0000 - false_positives_24: 71.0000 - false_negatives_24: 117.0000 - val_loss: 6.3851 - val_accuracy: 0.4364 - val_true_positives_24: 19.0000 - val_true_negatives_24: 5.0000 - val_false_positives_24: 4.0000 - val_false_negatives_24: 27.0000\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.5068 - accuracy: 0.4704 - true_positives_24: 105.0000 - true_negatives_24: 70.0000 - false_positives_24: 122.0000 - false_negatives_24: 75.0000 - val_loss: 1.8703 - val_accuracy: 0.6182 - val_true_positives_24: 33.0000 - val_true_negatives_24: 1.0000 - val_false_positives_24: 8.0000 - val_false_negatives_24: 13.0000\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.8592 - accuracy: 0.4435 - true_positives_24: 135.0000 - true_negatives_24: 30.0000 - false_positives_24: 162.0000 - false_negatives_24: 45.0000 - val_loss: 0.9982 - val_accuracy: 0.7273 - val_true_positives_24: 37.0000 - val_true_negatives_24: 3.0000 - val_false_positives_24: 6.0000 - val_false_negatives_24: 9.0000\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.7785 - accuracy: 0.4409 - true_positives_24: 137.0000 - true_negatives_24: 27.0000 - false_positives_24: 165.0000 - false_negatives_24: 43.0000 - val_loss: 0.8376 - val_accuracy: 0.7091 - val_true_positives_24: 37.0000 - val_true_negatives_24: 2.0000 - val_false_positives_24: 7.0000 - val_false_negatives_24: 9.0000\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.7184 - accuracy: 0.4570 - true_positives_24: 149.0000 - true_negatives_24: 21.0000 - false_positives_24: 171.0000 - false_negatives_24: 31.0000 - val_loss: 0.7474 - val_accuracy: 0.7455 - val_true_positives_24: 39.0000 - val_true_negatives_24: 2.0000 - val_false_positives_24: 7.0000 - val_false_negatives_24: 7.0000\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.7054 - accuracy: 0.4677 - true_positives_24: 154.0000 - true_negatives_24: 20.0000 - false_positives_24: 172.0000 - false_negatives_24: 26.0000 - val_loss: 0.7128 - val_accuracy: 0.7818 - val_true_positives_24: 41.0000 - val_true_negatives_24: 2.0000 - val_false_positives_24: 7.0000 - val_false_negatives_24: 5.0000\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.7009 - accuracy: 0.4651 - true_positives_24: 158.0000 - true_negatives_24: 15.0000 - false_positives_24: 177.0000 - false_negatives_24: 22.0000 - val_loss: 0.6916 - val_accuracy: 0.7818 - val_true_positives_24: 41.0000 - val_true_negatives_24: 2.0000 - val_false_positives_24: 7.0000 - val_false_negatives_24: 5.0000\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.4812 - true_positives_24: 164.0000 - true_negatives_24: 15.0000 - false_positives_24: 177.0000 - false_negatives_24: 16.0000 - val_loss: 0.6784 - val_accuracy: 0.7455 - val_true_positives_24: 41.0000 - val_true_negatives_24: 0.0000e+00 - val_false_positives_24: 9.0000 - val_false_negatives_24: 5.0000\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.4812 - true_positives_24: 167.0000 - true_negatives_24: 12.0000 - false_positives_24: 180.0000 - false_negatives_24: 13.0000 - val_loss: 0.6708 - val_accuracy: 0.7636 - val_true_positives_24: 42.0000 - val_true_negatives_24: 0.0000e+00 - val_false_positives_24: 9.0000 - val_false_negatives_24: 4.0000\n",
      "Epoch 12/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.4839 - true_positives_24: 175.0000 - true_negatives_24: 5.0000 - false_positives_24: 187.0000 - false_negatives_24: 5.0000 - val_loss: 0.6774 - val_accuracy: 0.7636 - val_true_positives_24: 42.0000 - val_true_negatives_24: 0.0000e+00 - val_false_positives_24: 9.0000 - val_false_negatives_24: 4.0000\n",
      "Epoch 13/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.4785 - true_positives_24: 168.0000 - true_negatives_24: 10.0000 - false_positives_24: 182.0000 - false_negatives_24: 12.0000 - val_loss: 0.6778 - val_accuracy: 0.7636 - val_true_positives_24: 42.0000 - val_true_negatives_24: 0.0000e+00 - val_false_positives_24: 9.0000 - val_false_negatives_24: 4.0000\n",
      "Epoch 14/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.4892 - true_positives_24: 174.0000 - true_negatives_24: 8.0000 - false_positives_24: 184.0000 - false_negatives_24: 6.0000 - val_loss: 0.6694 - val_accuracy: 0.8000 - val_true_positives_24: 44.0000 - val_true_negatives_24: 0.0000e+00 - val_false_positives_24: 9.0000 - val_false_negatives_24: 2.0000\n",
      "Epoch 15/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.4866 - true_positives_24: 171.0000 - true_negatives_24: 10.0000 - false_positives_24: 182.0000 - false_negatives_24: 9.0000 - val_loss: 0.6809 - val_accuracy: 0.7636 - val_true_positives_24: 42.0000 - val_true_negatives_24: 0.0000e+00 - val_false_positives_24: 9.0000 - val_false_negatives_24: 4.0000\n",
      "Epoch 16/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.4919 - true_positives_24: 173.0000 - true_negatives_24: 10.0000 - false_positives_24: 182.0000 - false_negatives_24: 7.0000 - val_loss: 0.6804 - val_accuracy: 0.7636 - val_true_positives_24: 42.0000 - val_true_negatives_24: 0.0000e+00 - val_false_positives_24: 9.0000 - val_false_negatives_24: 4.0000\n",
      "Epoch 17/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.4839 - true_positives_24: 175.0000 - true_negatives_24: 5.0000 - false_positives_24: 187.0000 - false_negatives_24: 5.0000 - val_loss: 0.6863 - val_accuracy: 0.7636 - val_true_positives_24: 42.0000 - val_true_negatives_24: 0.0000e+00 - val_false_positives_24: 9.0000 - val_false_negatives_24: 4.0000\n",
      "Epoch 18/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.4812 - true_positives_24: 169.0000 - true_negatives_24: 10.0000 - false_positives_24: 182.0000 - false_negatives_24: 11.0000 - val_loss: 0.6869 - val_accuracy: 0.7636 - val_true_positives_24: 42.0000 - val_true_negatives_24: 0.0000e+00 - val_false_positives_24: 9.0000 - val_false_negatives_24: 4.0000\n",
      "Epoch 19/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4892 - true_positives_24: 171.0000 - true_negatives_24: 11.0000 - false_positives_24: 181.0000 - false_negatives_24: 9.0000 - val_loss: 0.6898 - val_accuracy: 0.7636 - val_true_positives_24: 42.0000 - val_true_negatives_24: 0.0000e+00 - val_false_positives_24: 9.0000 - val_false_negatives_24: 4.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 9ms/step - loss: 12.1309 - accuracy: 0.4720 - true_positives_25: 110.0000 - true_negatives_25: 67.0000 - false_positives_25: 128.0000 - false_negatives_25: 70.0000 - val_loss: 0.6714 - val_accuracy: 0.8545 - val_true_positives_25: 46.0000 - val_true_negatives_25: 1.0000 - val_false_positives_25: 8.0000 - val_false_negatives_25: 0.0000e+00\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.4800 - true_positives_25: 179.0000 - true_negatives_25: 1.0000 - false_positives_25: 194.0000 - false_negatives_25: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.8364 - val_true_positives_25: 46.0000 - val_true_negatives_25: 0.0000e+00 - val_false_positives_25: 9.0000 - val_false_negatives_25: 0.0000e+00\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4800 - true_positives_25: 180.0000 - true_negatives_25: 0.0000e+00 - false_positives_25: 195.0000 - false_negatives_25: 0.0000e+00 - val_loss: 0.6871 - val_accuracy: 0.8364 - val_true_positives_25: 46.0000 - val_true_negatives_25: 0.0000e+00 - val_false_positives_25: 9.0000 - val_false_negatives_25: 0.0000e+00\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4800 - true_positives_25: 180.0000 - true_negatives_25: 0.0000e+00 - false_positives_25: 195.0000 - false_negatives_25: 0.0000e+00 - val_loss: 0.6891 - val_accuracy: 0.8364 - val_true_positives_25: 46.0000 - val_true_negatives_25: 0.0000e+00 - val_false_positives_25: 9.0000 - val_false_negatives_25: 0.0000e+00\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4800 - true_positives_25: 180.0000 - true_negatives_25: 0.0000e+00 - false_positives_25: 195.0000 - false_negatives_25: 0.0000e+00 - val_loss: 0.6901 - val_accuracy: 0.8364 - val_true_positives_25: 46.0000 - val_true_negatives_25: 0.0000e+00 - val_false_positives_25: 9.0000 - val_false_negatives_25: 0.0000e+00\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4667 - true_positives_25: 158.0000 - true_negatives_25: 17.0000 - false_positives_25: 178.0000 - false_negatives_25: 22.0000 - val_loss: 0.6933 - val_accuracy: 0.1636 - val_true_positives_25: 0.0000e+00 - val_true_negatives_25: 9.0000 - val_false_positives_25: 0.0000e+00 - val_false_negatives_25: 46.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Epoch 1/30\n",
      "46/46 [==============================] - 2s 13ms/step - loss: 29.6959 - accuracy: 0.4656 - true_positives_26: 56.0000 - true_negatives_26: 113.0000 - false_positives_26: 70.0000 - false_negatives_26: 124.0000 - val_loss: 1.6302 - val_accuracy: 0.8182 - val_true_positives_26: 44.0000 - val_true_negatives_26: 1.0000 - val_false_positives_26: 8.0000 - val_false_negatives_26: 2.0000\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8065 - accuracy: 0.5014 - true_positives_26: 175.0000 - true_negatives_26: 7.0000 - false_positives_26: 176.0000 - false_negatives_26: 5.0000 - val_loss: 0.7970 - val_accuracy: 0.8182 - val_true_positives_26: 45.0000 - val_true_negatives_26: 0.0000e+00 - val_false_positives_26: 9.0000 - val_false_negatives_26: 1.0000\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.7076 - accuracy: 0.4931 - true_positives_26: 178.0000 - true_negatives_26: 1.0000 - false_positives_26: 182.0000 - false_negatives_26: 2.0000 - val_loss: 0.6899 - val_accuracy: 0.8182 - val_true_positives_26: 45.0000 - val_true_negatives_26: 0.0000e+00 - val_false_positives_26: 9.0000 - val_false_negatives_26: 1.0000\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4959 - true_positives_26: 179.0000 - true_negatives_26: 1.0000 - false_positives_26: 182.0000 - false_negatives_26: 1.0000 - val_loss: 0.6826 - val_accuracy: 0.8364 - val_true_positives_26: 46.0000 - val_true_negatives_26: 0.0000e+00 - val_false_positives_26: 9.0000 - val_false_negatives_26: 0.0000e+00\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4986 - true_positives_26: 180.0000 - true_negatives_26: 1.0000 - false_positives_26: 182.0000 - false_negatives_26: 0.0000e+00 - val_loss: 0.6831 - val_accuracy: 0.8364 - val_true_positives_26: 46.0000 - val_true_negatives_26: 0.0000e+00 - val_false_positives_26: 9.0000 - val_false_negatives_26: 0.0000e+00\n",
      "Epoch 6/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.4986 - true_positives_26: 180.0000 - true_negatives_26: 1.0000 - false_positives_26: 182.0000 - false_negatives_26: 0.0000e+00 - val_loss: 0.6955 - val_accuracy: 0.8182 - val_true_positives_26: 45.0000 - val_true_negatives_26: 0.0000e+00 - val_false_positives_26: 9.0000 - val_false_negatives_26: 1.0000\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4986 - true_positives_26: 179.0000 - true_negatives_26: 2.0000 - false_positives_26: 181.0000 - false_negatives_26: 1.0000 - val_loss: 0.6852 - val_accuracy: 0.8364 - val_true_positives_26: 46.0000 - val_true_negatives_26: 0.0000e+00 - val_false_positives_26: 9.0000 - val_false_negatives_26: 0.0000e+00\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.4986 - true_positives_26: 180.0000 - true_negatives_26: 1.0000 - false_positives_26: 182.0000 - false_negatives_26: 0.0000e+00 - val_loss: 0.6855 - val_accuracy: 0.8364 - val_true_positives_26: 46.0000 - val_true_negatives_26: 0.0000e+00 - val_false_positives_26: 9.0000 - val_false_negatives_26: 0.0000e+00\n",
      "Epoch 9/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5014 - true_positives_26: 180.0000 - true_negatives_26: 2.0000 - false_positives_26: 181.0000 - false_negatives_26: 0.0000e+00 - val_loss: 0.7099 - val_accuracy: 0.8182 - val_true_positives_26: 45.0000 - val_true_negatives_26: 0.0000e+00 - val_false_positives_26: 9.0000 - val_false_negatives_26: 1.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Epoch 1/30\n",
      "46/46 [==============================] - 2s 9ms/step - loss: 17.1806 - accuracy: 0.4959 - true_positives_27: 106.0000 - true_negatives_27: 74.0000 - false_positives_27: 109.0000 - false_negatives_27: 74.0000 - val_loss: 0.6177 - val_accuracy: 0.8364 - val_true_positives_27: 46.0000 - val_true_negatives_27: 0.0000e+00 - val_false_positives_27: 9.0000 - val_false_negatives_27: 0.0000e+00\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.7268 - accuracy: 0.4904 - true_positives_27: 109.0000 - true_negatives_27: 69.0000 - false_positives_27: 114.0000 - false_negatives_27: 71.0000 - val_loss: 0.7102 - val_accuracy: 0.2000 - val_true_positives_27: 3.0000 - val_true_negatives_27: 8.0000 - val_false_positives_27: 1.0000 - val_false_negatives_27: 43.0000\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.7067 - accuracy: 0.4876 - true_positives_27: 109.0000 - true_negatives_27: 68.0000 - false_positives_27: 115.0000 - false_negatives_27: 71.0000 - val_loss: 0.5729 - val_accuracy: 0.8364 - val_true_positives_27: 46.0000 - val_true_negatives_27: 0.0000e+00 - val_false_positives_27: 9.0000 - val_false_negatives_27: 0.0000e+00\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6983 - accuracy: 0.4848 - true_positives_27: 120.0000 - true_negatives_27: 56.0000 - false_positives_27: 127.0000 - false_negatives_27: 60.0000 - val_loss: 0.5689 - val_accuracy: 0.8364 - val_true_positives_27: 46.0000 - val_true_negatives_27: 0.0000e+00 - val_false_positives_27: 9.0000 - val_false_negatives_27: 0.0000e+00\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6998 - accuracy: 0.5041 - true_positives_27: 126.0000 - true_negatives_27: 57.0000 - false_positives_27: 126.0000 - false_negatives_27: 54.0000 - val_loss: 0.6875 - val_accuracy: 0.6727 - val_true_positives_27: 36.0000 - val_true_negatives_27: 1.0000 - val_false_positives_27: 8.0000 - val_false_negatives_27: 10.0000\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6986 - accuracy: 0.5014 - true_positives_27: 114.0000 - true_negatives_27: 68.0000 - false_positives_27: 115.0000 - false_negatives_27: 66.0000 - val_loss: 0.5979 - val_accuracy: 0.7273 - val_true_positives_27: 39.0000 - val_true_negatives_27: 1.0000 - val_false_positives_27: 8.0000 - val_false_negatives_27: 7.0000\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.7043 - accuracy: 0.5014 - true_positives_27: 122.0000 - true_negatives_27: 60.0000 - false_positives_27: 123.0000 - false_negatives_27: 58.0000 - val_loss: 0.6473 - val_accuracy: 0.6545 - val_true_positives_27: 35.0000 - val_true_negatives_27: 1.0000 - val_false_positives_27: 8.0000 - val_false_negatives_27: 11.0000\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4931 - true_positives_27: 87.0000 - true_negatives_27: 92.0000 - false_positives_27: 91.0000 - false_negatives_27: 93.0000 - val_loss: 0.6159 - val_accuracy: 0.6545 - val_true_positives_27: 35.0000 - val_true_negatives_27: 1.0000 - val_false_positives_27: 8.0000 - val_false_negatives_27: 11.0000\n",
      "Epoch 9/30\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.6942 - accuracy: 0.4904 - true_positives_27: 124.0000 - true_negatives_27: 54.0000 - false_positives_27: 129.0000 - false_negatives_27: 56.0000 - val_loss: 0.6940 - val_accuracy: 0.3636 - val_true_positives_27: 16.0000 - val_true_negatives_27: 4.0000 - val_false_positives_27: 5.0000 - val_false_negatives_27: 30.0000\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Epoch 1/30\n",
      "46/46 [==============================] - 2s 8ms/step - loss: 22.7182 - accuracy: 0.4738 - true_positives_28: 100.0000 - true_negatives_28: 72.0000 - false_positives_28: 111.0000 - false_negatives_28: 80.0000 - val_loss: 6.7291 - val_accuracy: 0.4545 - val_true_positives_28: 21.0000 - val_true_negatives_28: 4.0000 - val_false_positives_28: 5.0000 - val_false_negatives_28: 25.0000\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8201 - accuracy: 0.4821 - true_positives_28: 64.0000 - true_negatives_28: 111.0000 - false_positives_28: 72.0000 - false_negatives_28: 116.0000 - val_loss: 1.0305 - val_accuracy: 0.2727 - val_true_positives_28: 10.0000 - val_true_negatives_28: 5.0000 - val_false_positives_28: 4.0000 - val_false_negatives_28: 36.0000\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.7548 - accuracy: 0.5262 - true_positives_28: 33.0000 - true_negatives_28: 158.0000 - false_positives_28: 25.0000 - false_negatives_28: 147.0000 - val_loss: 0.8351 - val_accuracy: 0.2364 - val_true_positives_28: 6.0000 - val_true_negatives_28: 7.0000 - val_false_positives_28: 2.0000 - val_false_negatives_28: 40.0000\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.5207 - true_positives_28: 24.0000 - true_negatives_28: 165.0000 - false_positives_28: 18.0000 - false_negatives_28: 156.0000 - val_loss: 0.7615 - val_accuracy: 0.2182 - val_true_positives_28: 5.0000 - val_true_negatives_28: 7.0000 - val_false_positives_28: 2.0000 - val_false_negatives_28: 41.0000\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5289 - true_positives_28: 24.0000 - true_negatives_28: 168.0000 - false_positives_28: 15.0000 - false_negatives_28: 156.0000 - val_loss: 0.7449 - val_accuracy: 0.2182 - val_true_positives_28: 5.0000 - val_true_negatives_28: 7.0000 - val_false_positives_28: 2.0000 - val_false_negatives_28: 41.0000\n",
      "Epoch 6/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6753 - accuracy: 0.5207 - true_positives_28: 19.0000 - true_negatives_28: 170.0000 - false_positives_28: 13.0000 - false_negatives_28: 161.0000 - val_loss: 0.7173 - val_accuracy: 0.2182 - val_true_positives_28: 5.0000 - val_true_negatives_28: 7.0000 - val_false_positives_28: 2.0000 - val_false_negatives_28: 41.0000\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.5234 - true_positives_28: 17.0000 - true_negatives_28: 173.0000 - false_positives_28: 10.0000 - false_negatives_28: 163.0000 - val_loss: 0.7034 - val_accuracy: 0.2000 - val_true_positives_28: 4.0000 - val_true_negatives_28: 7.0000 - val_false_positives_28: 2.0000 - val_false_negatives_28: 42.0000\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.5317 - true_positives_28: 16.0000 - true_negatives_28: 177.0000 - false_positives_28: 6.0000 - false_negatives_28: 164.0000 - val_loss: 0.6956 - val_accuracy: 0.2000 - val_true_positives_28: 5.0000 - val_true_negatives_28: 6.0000 - val_false_positives_28: 3.0000 - val_false_negatives_28: 41.0000\n",
      "Epoch 9/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.5344 - true_positives_28: 16.0000 - true_negatives_28: 178.0000 - false_positives_28: 5.0000 - false_negatives_28: 164.0000 - val_loss: 0.6966 - val_accuracy: 0.2000 - val_true_positives_28: 5.0000 - val_true_negatives_28: 6.0000 - val_false_positives_28: 3.0000 - val_false_negatives_28: 41.0000\n",
      "Epoch 10/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.5372 - true_positives_28: 16.0000 - true_negatives_28: 179.0000 - false_positives_28: 4.0000 - false_negatives_28: 164.0000 - val_loss: 0.7075 - val_accuracy: 0.1818 - val_true_positives_28: 4.0000 - val_true_negatives_28: 6.0000 - val_false_positives_28: 3.0000 - val_false_negatives_28: 42.0000\n",
      "Epoch 11/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.5289 - true_positives_28: 17.0000 - true_negatives_28: 175.0000 - false_positives_28: 8.0000 - false_negatives_28: 163.0000 - val_loss: 0.6973 - val_accuracy: 0.2000 - val_true_positives_28: 4.0000 - val_true_negatives_28: 7.0000 - val_false_positives_28: 2.0000 - val_false_negatives_28: 42.0000\n",
      "Epoch 12/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.5399 - true_positives_28: 16.0000 - true_negatives_28: 180.0000 - false_positives_28: 3.0000 - false_negatives_28: 164.0000 - val_loss: 0.6864 - val_accuracy: 0.2000 - val_true_positives_28: 4.0000 - val_true_negatives_28: 7.0000 - val_false_positives_28: 2.0000 - val_false_negatives_28: 42.0000\n",
      "Epoch 13/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.5344 - true_positives_28: 16.0000 - true_negatives_28: 178.0000 - false_positives_28: 5.0000 - false_negatives_28: 164.0000 - val_loss: 0.6869 - val_accuracy: 0.2182 - val_true_positives_28: 5.0000 - val_true_negatives_28: 7.0000 - val_false_positives_28: 2.0000 - val_false_negatives_28: 41.0000\n",
      "Epoch 14/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.5317 - true_positives_28: 16.0000 - true_negatives_28: 177.0000 - false_positives_28: 6.0000 - false_negatives_28: 164.0000 - val_loss: 0.6984 - val_accuracy: 0.2182 - val_true_positives_28: 5.0000 - val_true_negatives_28: 7.0000 - val_false_positives_28: 2.0000 - val_false_negatives_28: 41.0000\n",
      "Epoch 15/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5207 - true_positives_28: 14.0000 - true_negatives_28: 175.0000 - false_positives_28: 8.0000 - false_negatives_28: 166.0000 - val_loss: 0.6834 - val_accuracy: 0.2182 - val_true_positives_28: 5.0000 - val_true_negatives_28: 7.0000 - val_false_positives_28: 2.0000 - val_false_negatives_28: 41.0000\n",
      "Epoch 16/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.5344 - true_positives_28: 15.0000 - true_negatives_28: 179.0000 - false_positives_28: 4.0000 - false_negatives_28: 165.0000 - val_loss: 0.6866 - val_accuracy: 0.2182 - val_true_positives_28: 5.0000 - val_true_negatives_28: 7.0000 - val_false_positives_28: 2.0000 - val_false_negatives_28: 41.0000\n",
      "Epoch 17/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.5344 - true_positives_28: 15.0000 - true_negatives_28: 179.0000 - false_positives_28: 4.0000 - false_negatives_28: 165.0000 - val_loss: 0.7287 - val_accuracy: 0.2000 - val_true_positives_28: 4.0000 - val_true_negatives_28: 7.0000 - val_false_positives_28: 2.0000 - val_false_negatives_28: 42.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.5207 - true_positives_28: 13.0000 - true_negatives_28: 176.0000 - false_positives_28: 7.0000 - false_negatives_28: 167.0000 - val_loss: 0.7399 - val_accuracy: 0.1818 - val_true_positives_28: 3.0000 - val_true_negatives_28: 7.0000 - val_false_positives_28: 2.0000 - val_false_negatives_28: 43.0000\n",
      "Epoch 19/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.5207 - true_positives_28: 12.0000 - true_negatives_28: 177.0000 - false_positives_28: 6.0000 - false_negatives_28: 168.0000 - val_loss: 0.7475 - val_accuracy: 0.1818 - val_true_positives_28: 3.0000 - val_true_negatives_28: 7.0000 - val_false_positives_28: 2.0000 - val_false_negatives_28: 43.0000\n",
      "Epoch 20/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.5234 - true_positives_28: 10.0000 - true_negatives_28: 180.0000 - false_positives_28: 3.0000 - false_negatives_28: 170.0000 - val_loss: 0.7549 - val_accuracy: 0.2000 - val_true_positives_28: 4.0000 - val_true_negatives_28: 7.0000 - val_false_positives_28: 2.0000 - val_false_negatives_28: 42.0000\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 1s 8ms/step - loss: 46.7604 - accuracy: 0.4444 - true_positives_29: 68.0000 - true_negatives_29: 92.0000 - false_positives_29: 88.0000 - false_negatives_29: 112.0000 - val_loss: 20.1810 - val_accuracy: 0.3818 - val_true_positives_29: 16.0000 - val_true_negatives_29: 5.0000 - val_false_positives_29: 4.0000 - val_false_negatives_29: 30.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 11.5604 - accuracy: 0.4778 - true_positives_29: 87.0000 - true_negatives_29: 85.0000 - false_positives_29: 95.0000 - false_negatives_29: 93.0000 - val_loss: 5.5974 - val_accuracy: 0.5273 - val_true_positives_29: 26.0000 - val_true_negatives_29: 3.0000 - val_false_positives_29: 6.0000 - val_false_negatives_29: 20.0000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 4.0149 - accuracy: 0.5528 - true_positives_29: 100.0000 - true_negatives_29: 99.0000 - false_positives_29: 81.0000 - false_negatives_29: 80.0000 - val_loss: 4.1879 - val_accuracy: 0.5455 - val_true_positives_29: 26.0000 - val_true_negatives_29: 4.0000 - val_false_positives_29: 5.0000 - val_false_negatives_29: 20.0000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.8120 - accuracy: 0.5806 - true_positives_29: 115.0000 - true_negatives_29: 94.0000 - false_positives_29: 86.0000 - false_negatives_29: 65.0000 - val_loss: 13.4474 - val_accuracy: 0.2909 - val_true_positives_29: 8.0000 - val_true_negatives_29: 8.0000 - val_false_positives_29: 1.0000 - val_false_negatives_29: 38.0000\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 4.1622 - accuracy: 0.5944 - true_positives_29: 102.0000 - true_negatives_29: 112.0000 - false_positives_29: 68.0000 - false_negatives_29: 78.0000 - val_loss: 3.7555 - val_accuracy: 0.5273 - val_true_positives_29: 26.0000 - val_true_negatives_29: 3.0000 - val_false_positives_29: 6.0000 - val_false_negatives_29: 20.0000\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 3.0477 - accuracy: 0.6500 - true_positives_29: 122.0000 - true_negatives_29: 112.0000 - false_positives_29: 68.0000 - false_negatives_29: 58.0000 - val_loss: 14.2808 - val_accuracy: 0.2727 - val_true_positives_29: 7.0000 - val_true_negatives_29: 8.0000 - val_false_positives_29: 1.0000 - val_false_negatives_29: 39.0000\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 3.0658 - accuracy: 0.5778 - true_positives_29: 106.0000 - true_negatives_29: 102.0000 - false_positives_29: 78.0000 - false_negatives_29: 74.0000 - val_loss: 4.1601 - val_accuracy: 0.4545 - val_true_positives_29: 20.0000 - val_true_negatives_29: 5.0000 - val_false_positives_29: 4.0000 - val_false_negatives_29: 26.0000\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 3.4282 - accuracy: 0.6194 - true_positives_29: 110.0000 - true_negatives_29: 113.0000 - false_positives_29: 67.0000 - false_negatives_29: 70.0000 - val_loss: 5.5930 - val_accuracy: 0.4909 - val_true_positives_29: 22.0000 - val_true_negatives_29: 5.0000 - val_false_positives_29: 4.0000 - val_false_negatives_29: 24.0000\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 3.0038 - accuracy: 0.6139 - true_positives_29: 115.0000 - true_negatives_29: 106.0000 - false_positives_29: 74.0000 - false_negatives_29: 65.0000 - val_loss: 2.6118 - val_accuracy: 0.6545 - val_true_positives_29: 35.0000 - val_true_negatives_29: 1.0000 - val_false_positives_29: 8.0000 - val_false_negatives_29: 11.0000\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.6476 - accuracy: 0.6139 - true_positives_29: 122.0000 - true_negatives_29: 99.0000 - false_positives_29: 81.0000 - false_negatives_29: 58.0000 - val_loss: 9.6451 - val_accuracy: 0.2909 - val_true_positives_29: 8.0000 - val_true_negatives_29: 8.0000 - val_false_positives_29: 1.0000 - val_false_negatives_29: 38.0000\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.9774 - accuracy: 0.6167 - true_positives_29: 113.0000 - true_negatives_29: 109.0000 - false_positives_29: 71.0000 - false_negatives_29: 67.0000 - val_loss: 4.0164 - val_accuracy: 0.4545 - val_true_positives_29: 21.0000 - val_true_negatives_29: 4.0000 - val_false_positives_29: 5.0000 - val_false_negatives_29: 25.0000\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 4.0684 - accuracy: 0.6056 - true_positives_29: 109.0000 - true_negatives_29: 109.0000 - false_positives_29: 71.0000 - false_negatives_29: 71.0000 - val_loss: 1.9975 - val_accuracy: 0.6909 - val_true_positives_29: 36.0000 - val_true_negatives_29: 2.0000 - val_false_positives_29: 7.0000 - val_false_negatives_29: 10.0000\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 5.4121 - accuracy: 0.6083 - true_positives_29: 121.0000 - true_negatives_29: 98.0000 - false_positives_29: 82.0000 - false_negatives_29: 59.0000 - val_loss: 4.5651 - val_accuracy: 0.7273 - val_true_positives_29: 39.0000 - val_true_negatives_29: 1.0000 - val_false_positives_29: 8.0000 - val_false_negatives_29: 7.0000\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 5.4148 - accuracy: 0.5694 - true_positives_29: 95.0000 - true_negatives_29: 110.0000 - false_positives_29: 70.0000 - false_negatives_29: 85.0000 - val_loss: 2.7441 - val_accuracy: 0.8000 - val_true_positives_29: 44.0000 - val_true_negatives_29: 0.0000e+00 - val_false_positives_29: 9.0000 - val_false_negatives_29: 2.0000\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 4.5445 - accuracy: 0.5694 - true_positives_29: 110.0000 - true_negatives_29: 95.0000 - false_positives_29: 85.0000 - false_negatives_29: 70.0000 - val_loss: 2.6687 - val_accuracy: 0.5818 - val_true_positives_29: 30.0000 - val_true_negatives_29: 2.0000 - val_false_positives_29: 7.0000 - val_false_negatives_29: 16.0000\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.9841 - accuracy: 0.6556 - true_positives_29: 120.0000 - true_negatives_29: 116.0000 - false_positives_29: 64.0000 - false_negatives_29: 60.0000 - val_loss: 5.2942 - val_accuracy: 0.3818 - val_true_positives_29: 13.0000 - val_true_negatives_29: 8.0000 - val_false_positives_29: 1.0000 - val_false_negatives_29: 33.0000\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.4802 - accuracy: 0.6194 - true_positives_29: 118.0000 - true_negatives_29: 105.0000 - false_positives_29: 75.0000 - false_negatives_29: 62.0000 - val_loss: 2.5265 - val_accuracy: 0.5455 - val_true_positives_29: 27.0000 - val_true_negatives_29: 3.0000 - val_false_positives_29: 6.0000 - val_false_negatives_29: 19.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 10ms/step - loss: 3.6384 - accuracy: 0.4972 - true_positives_30: 166.0000 - true_negatives_30: 14.0000 - false_positives_30: 168.0000 - false_negatives_30: 14.0000 - val_loss: 0.6923 - val_accuracy: 0.8364 - val_true_positives_30: 46.0000 - val_true_negatives_30: 0.0000e+00 - val_false_positives_30: 9.0000 - val_false_negatives_30: 0.0000e+00\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.9383 - accuracy: 0.4420 - true_positives_30: 145.0000 - true_negatives_30: 15.0000 - false_positives_30: 167.0000 - false_negatives_30: 35.0000 - val_loss: 0.6927 - val_accuracy: 0.8364 - val_true_positives_30: 46.0000 - val_true_negatives_30: 0.0000e+00 - val_false_positives_30: 9.0000 - val_false_negatives_30: 0.0000e+00\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4972 - true_positives_30: 180.0000 - true_negatives_30: 0.0000e+00 - false_positives_30: 182.0000 - false_negatives_30: 0.0000e+00 - val_loss: 0.6921 - val_accuracy: 0.8364 - val_true_positives_30: 46.0000 - val_true_negatives_30: 0.0000e+00 - val_false_positives_30: 9.0000 - val_false_negatives_30: 0.0000e+00\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4972 - true_positives_30: 180.0000 - true_negatives_30: 0.0000e+00 - false_positives_30: 182.0000 - false_negatives_30: 0.0000e+00 - val_loss: 0.6930 - val_accuracy: 0.8364 - val_true_positives_30: 46.0000 - val_true_negatives_30: 0.0000e+00 - val_false_positives_30: 9.0000 - val_false_negatives_30: 0.0000e+00\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4972 - true_positives_30: 11.0000 - true_negatives_30: 169.0000 - false_positives_30: 13.0000 - false_negatives_30: 169.0000 - val_loss: 0.6936 - val_accuracy: 0.1636 - val_true_positives_30: 0.0000e+00 - val_true_negatives_30: 9.0000 - val_false_positives_30: 0.0000e+00 - val_false_negatives_30: 46.0000\n",
      "Epoch 6/30\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4751 - true_positives_30: 3.0000 - true_negatives_30: 169.0000 - false_positives_30: 13.0000 - false_negatives_30: 177.0000 - val_loss: 0.6934 - val_accuracy: 0.1636 - val_true_positives_30: 0.0000e+00 - val_true_negatives_30: 9.0000 - val_false_positives_30: 0.0000e+00 - val_false_negatives_30: 46.0000\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5028 - true_positives_30: 0.0000e+00 - true_negatives_30: 182.0000 - false_positives_30: 0.0000e+00 - false_negatives_30: 180.0000 - val_loss: 0.6952 - val_accuracy: 0.1636 - val_true_positives_30: 0.0000e+00 - val_true_negatives_30: 9.0000 - val_false_positives_30: 0.0000e+00 - val_false_negatives_30: 46.0000\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5028 - true_positives_30: 0.0000e+00 - true_negatives_30: 182.0000 - false_positives_30: 0.0000e+00 - false_negatives_30: 180.0000 - val_loss: 0.6956 - val_accuracy: 0.1636 - val_true_positives_30: 0.0000e+00 - val_true_negatives_30: 9.0000 - val_false_positives_30: 0.0000e+00 - val_false_negatives_30: 46.0000\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Epoch 1/30\n",
      "46/46 [==============================] - 1s 9ms/step - loss: 81.3200 - accuracy: 0.4904 - true_positives_31: 148.0000 - true_negatives_31: 31.0000 - false_positives_31: 154.0000 - false_negatives_31: 32.0000 - val_loss: 0.8679 - val_accuracy: 0.2182 - val_true_positives_31: 4.0000 - val_true_negatives_31: 8.0000 - val_false_positives_31: 1.0000 - val_false_negatives_31: 42.0000\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8814 - accuracy: 0.4849 - true_positives_31: 6.0000 - true_negatives_31: 171.0000 - false_positives_31: 14.0000 - false_negatives_31: 174.0000 - val_loss: 0.7642 - val_accuracy: 0.1455 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 8.0000 - val_false_positives_31: 1.0000 - val_false_negatives_31: 46.0000\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5041 - true_positives_31: 4.0000 - true_negatives_31: 180.0000 - false_positives_31: 5.0000 - false_negatives_31: 176.0000 - val_loss: 0.7101 - val_accuracy: 0.1455 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 8.0000 - val_false_positives_31: 1.0000 - val_false_negatives_31: 46.0000\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5041 - true_positives_31: 3.0000 - true_negatives_31: 181.0000 - false_positives_31: 4.0000 - false_negatives_31: 177.0000 - val_loss: 0.7098 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5041 - true_positives_31: 3.0000 - true_negatives_31: 181.0000 - false_positives_31: 4.0000 - false_negatives_31: 177.0000 - val_loss: 0.7295 - val_accuracy: 0.1455 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 8.0000 - val_false_positives_31: 1.0000 - val_false_negatives_31: 46.0000\n",
      "Epoch 6/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.5068 - true_positives_31: 4.0000 - true_negatives_31: 181.0000 - false_positives_31: 4.0000 - false_negatives_31: 176.0000 - val_loss: 0.7252 - val_accuracy: 0.1455 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 8.0000 - val_false_positives_31: 1.0000 - val_false_negatives_31: 46.0000\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.5068 - true_positives_31: 4.0000 - true_negatives_31: 181.0000 - false_positives_31: 4.0000 - false_negatives_31: 176.0000 - val_loss: 0.7294 - val_accuracy: 0.1455 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 8.0000 - val_false_positives_31: 1.0000 - val_false_negatives_31: 46.0000\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5041 - true_positives_31: 3.0000 - true_negatives_31: 181.0000 - false_positives_31: 4.0000 - false_negatives_31: 177.0000 - val_loss: 0.7090 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 9/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4959 - true_positives_31: 0.0000e+00 - true_negatives_31: 181.0000 - false_positives_31: 4.0000 - false_negatives_31: 180.0000 - val_loss: 0.7096 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 10/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7090 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 11/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7084 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 12/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7087 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7075 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 14/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7077 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 15/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7071 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 16/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7074 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 17/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7069 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 18/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7063 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 19/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7062 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 20/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7065 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 21/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7053 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 22/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7062 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 23/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7054 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 24/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7046 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 25/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7050 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 26/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7050 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 27/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7049 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 28/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7054 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 29/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7046 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "Epoch 30/30\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5068 - true_positives_31: 0.0000e+00 - true_negatives_31: 185.0000 - false_positives_31: 0.0000e+00 - false_negatives_31: 180.0000 - val_loss: 0.7052 - val_accuracy: 0.1636 - val_true_positives_31: 0.0000e+00 - val_true_negatives_31: 9.0000 - val_false_positives_31: 0.0000e+00 - val_false_negatives_31: 46.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: -0.033967511958754595.\n",
      "\n",
      "Starting parameters 3...\n",
      "Starting fold 1...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 2s 9ms/step - loss: 0.7305 - accuracy: 0.4917 - true_positives_32: 6.0000 - true_negatives_32: 171.0000 - false_positives_32: 9.0000 - false_negatives_32: 174.0000 - val_loss: 0.7477 - val_accuracy: 0.1636 - val_true_positives_32: 0.0000e+00 - val_true_negatives_32: 9.0000 - val_false_positives_32: 1.0000 - val_false_negatives_32: 45.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5028 - true_positives_32: 1.0000 - true_negatives_32: 180.0000 - false_positives_32: 0.0000e+00 - false_negatives_32: 179.0000 - val_loss: 0.7609 - val_accuracy: 0.1636 - val_true_positives_32: 0.0000e+00 - val_true_negatives_32: 9.0000 - val_false_positives_32: 1.0000 - val_false_negatives_32: 45.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5028 - true_positives_32: 1.0000 - true_negatives_32: 180.0000 - false_positives_32: 0.0000e+00 - false_negatives_32: 179.0000 - val_loss: 0.7698 - val_accuracy: 0.1636 - val_true_positives_32: 0.0000e+00 - val_true_negatives_32: 9.0000 - val_false_positives_32: 1.0000 - val_false_negatives_32: 45.0000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6913 - accuracy: 0.5028 - true_positives_32: 1.0000 - true_negatives_32: 180.0000 - false_positives_32: 0.0000e+00 - false_negatives_32: 179.0000 - val_loss: 0.7791 - val_accuracy: 0.1636 - val_true_positives_32: 0.0000e+00 - val_true_negatives_32: 9.0000 - val_false_positives_32: 1.0000 - val_false_negatives_32: 45.0000\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5028 - true_positives_32: 1.0000 - true_negatives_32: 180.0000 - false_positives_32: 0.0000e+00 - false_negatives_32: 179.0000 - val_loss: 0.7846 - val_accuracy: 0.1636 - val_true_positives_32: 0.0000e+00 - val_true_negatives_32: 9.0000 - val_false_positives_32: 1.0000 - val_false_negatives_32: 45.0000\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5028 - true_positives_32: 1.0000 - true_negatives_32: 180.0000 - false_positives_32: 0.0000e+00 - false_negatives_32: 179.0000 - val_loss: 0.7886 - val_accuracy: 0.1636 - val_true_positives_32: 0.0000e+00 - val_true_negatives_32: 9.0000 - val_false_positives_32: 1.0000 - val_false_negatives_32: 45.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 1s 8ms/step - loss: 194.6879 - accuracy: 0.5000 - true_positives_33: 0.0000e+00 - true_negatives_33: 180.0000 - false_positives_33: 0.0000e+00 - false_negatives_33: 180.0000 - val_loss: 212.1457 - val_accuracy: 0.1636 - val_true_positives_33: 0.0000e+00 - val_true_negatives_33: 9.0000 - val_false_positives_33: 0.0000e+00 - val_false_negatives_33: 46.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 64.8347 - accuracy: 0.4972 - true_positives_33: 0.0000e+00 - true_negatives_33: 179.0000 - false_positives_33: 1.0000 - false_negatives_33: 180.0000 - val_loss: 65.3914 - val_accuracy: 0.2182 - val_true_positives_33: 3.0000 - val_true_negatives_33: 9.0000 - val_false_positives_33: 0.0000e+00 - val_false_negatives_33: 43.0000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 17.9887 - accuracy: 0.5333 - true_positives_33: 37.0000 - true_negatives_33: 155.0000 - false_positives_33: 25.0000 - false_negatives_33: 143.0000 - val_loss: 13.7664 - val_accuracy: 0.4727 - val_true_positives_33: 21.0000 - val_true_negatives_33: 5.0000 - val_false_positives_33: 4.0000 - val_false_negatives_33: 25.0000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 3.0220 - accuracy: 0.5611 - true_positives_33: 100.0000 - true_negatives_33: 102.0000 - false_positives_33: 78.0000 - false_negatives_33: 80.0000 - val_loss: 2.0574 - val_accuracy: 0.7273 - val_true_positives_33: 38.0000 - val_true_negatives_33: 2.0000 - val_false_positives_33: 7.0000 - val_false_negatives_33: 8.0000\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7629 - accuracy: 0.5750 - true_positives_33: 170.0000 - true_negatives_33: 37.0000 - false_positives_33: 143.0000 - false_negatives_33: 10.0000 - val_loss: 0.9399 - val_accuracy: 0.8364 - val_true_positives_33: 45.0000 - val_true_negatives_33: 1.0000 - val_false_positives_33: 8.0000 - val_false_negatives_33: 1.0000\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7174 - accuracy: 0.5417 - true_positives_33: 174.0000 - true_negatives_33: 21.0000 - false_positives_33: 159.0000 - false_negatives_33: 6.0000 - val_loss: 0.6462 - val_accuracy: 0.8364 - val_true_positives_33: 46.0000 - val_true_negatives_33: 0.0000e+00 - val_false_positives_33: 9.0000 - val_false_negatives_33: 0.0000e+00\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7031 - accuracy: 0.5444 - true_positives_33: 174.0000 - true_negatives_33: 22.0000 - false_positives_33: 158.0000 - false_negatives_33: 6.0000 - val_loss: 0.6468 - val_accuracy: 0.8364 - val_true_positives_33: 46.0000 - val_true_negatives_33: 0.0000e+00 - val_false_positives_33: 9.0000 - val_false_negatives_33: 0.0000e+00\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6983 - accuracy: 0.5417 - true_positives_33: 174.0000 - true_negatives_33: 21.0000 - false_positives_33: 159.0000 - false_negatives_33: 6.0000 - val_loss: 0.6469 - val_accuracy: 0.8364 - val_true_positives_33: 46.0000 - val_true_negatives_33: 0.0000e+00 - val_false_positives_33: 9.0000 - val_false_negatives_33: 0.0000e+00\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.5528 - true_positives_33: 176.0000 - true_negatives_33: 23.0000 - false_positives_33: 157.0000 - false_negatives_33: 4.0000 - val_loss: 0.6556 - val_accuracy: 0.8182 - val_true_positives_33: 45.0000 - val_true_negatives_33: 0.0000e+00 - val_false_positives_33: 9.0000 - val_false_negatives_33: 1.0000\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.5667 - true_positives_33: 172.0000 - true_negatives_33: 32.0000 - false_positives_33: 148.0000 - false_negatives_33: 8.0000 - val_loss: 0.7892 - val_accuracy: 0.8000 - val_true_positives_33: 43.0000 - val_true_negatives_33: 1.0000 - val_false_positives_33: 8.0000 - val_false_negatives_33: 3.0000\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.5389 - true_positives_33: 165.0000 - true_negatives_33: 29.0000 - false_positives_33: 151.0000 - false_negatives_33: 15.0000 - val_loss: 0.6469 - val_accuracy: 0.8364 - val_true_positives_33: 46.0000 - val_true_negatives_33: 0.0000e+00 - val_false_positives_33: 9.0000 - val_false_negatives_33: 0.0000e+00\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 2s 9ms/step - loss: 2.8633 - accuracy: 0.5167 - true_positives_34: 149.0000 - true_negatives_34: 37.0000 - false_positives_34: 143.0000 - false_negatives_34: 31.0000 - val_loss: 1.1122 - val_accuracy: 0.7091 - val_true_positives_34: 39.0000 - val_true_negatives_34: 0.0000e+00 - val_false_positives_34: 9.0000 - val_false_negatives_34: 7.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.8292 - accuracy: 0.5083 - true_positives_34: 170.0000 - true_negatives_34: 13.0000 - false_positives_34: 167.0000 - false_negatives_34: 10.0000 - val_loss: 0.7118 - val_accuracy: 0.8000 - val_true_positives_34: 44.0000 - val_true_negatives_34: 0.0000e+00 - val_false_positives_34: 9.0000 - val_false_negatives_34: 2.0000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7329 - accuracy: 0.5056 - true_positives_34: 173.0000 - true_negatives_34: 9.0000 - false_positives_34: 171.0000 - false_negatives_34: 7.0000 - val_loss: 0.6687 - val_accuracy: 0.8000 - val_true_positives_34: 44.0000 - val_true_negatives_34: 0.0000e+00 - val_false_positives_34: 9.0000 - val_false_negatives_34: 2.0000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7061 - accuracy: 0.5194 - true_positives_34: 174.0000 - true_negatives_34: 13.0000 - false_positives_34: 167.0000 - false_negatives_34: 6.0000 - val_loss: 0.6268 - val_accuracy: 0.8182 - val_true_positives_34: 45.0000 - val_true_negatives_34: 0.0000e+00 - val_false_positives_34: 9.0000 - val_false_negatives_34: 1.0000\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6975 - accuracy: 0.5167 - true_positives_34: 174.0000 - true_negatives_34: 12.0000 - false_positives_34: 168.0000 - false_negatives_34: 6.0000 - val_loss: 0.6514 - val_accuracy: 0.8182 - val_true_positives_34: 45.0000 - val_true_negatives_34: 0.0000e+00 - val_false_positives_34: 9.0000 - val_false_negatives_34: 1.0000\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.5083 - true_positives_34: 174.0000 - true_negatives_34: 9.0000 - false_positives_34: 171.0000 - false_negatives_34: 6.0000 - val_loss: 0.6311 - val_accuracy: 0.8182 - val_true_positives_34: 45.0000 - val_true_negatives_34: 0.0000e+00 - val_false_positives_34: 9.0000 - val_false_negatives_34: 1.0000\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.5083 - true_positives_34: 174.0000 - true_negatives_34: 9.0000 - false_positives_34: 171.0000 - false_negatives_34: 6.0000 - val_loss: 0.6174 - val_accuracy: 0.8182 - val_true_positives_34: 45.0000 - val_true_negatives_34: 0.0000e+00 - val_false_positives_34: 9.0000 - val_false_negatives_34: 1.0000\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.5167 - true_positives_34: 177.0000 - true_negatives_34: 9.0000 - false_positives_34: 171.0000 - false_negatives_34: 3.0000 - val_loss: 0.6261 - val_accuracy: 0.8364 - val_true_positives_34: 46.0000 - val_true_negatives_34: 0.0000e+00 - val_false_positives_34: 9.0000 - val_false_negatives_34: 0.0000e+00\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.5278 - true_positives_34: 179.0000 - true_negatives_34: 11.0000 - false_positives_34: 169.0000 - false_negatives_34: 1.0000 - val_loss: 0.6262 - val_accuracy: 0.8364 - val_true_positives_34: 46.0000 - val_true_negatives_34: 0.0000e+00 - val_false_positives_34: 9.0000 - val_false_negatives_34: 0.0000e+00\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.5167 - true_positives_34: 179.0000 - true_negatives_34: 7.0000 - false_positives_34: 173.0000 - false_negatives_34: 1.0000 - val_loss: 0.6139 - val_accuracy: 0.8364 - val_true_positives_34: 46.0000 - val_true_negatives_34: 0.0000e+00 - val_false_positives_34: 9.0000 - val_false_negatives_34: 0.0000e+00\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.5000 - true_positives_34: 179.0000 - true_negatives_34: 1.0000 - false_positives_34: 179.0000 - false_negatives_34: 1.0000 - val_loss: 0.6064 - val_accuracy: 0.8364 - val_true_positives_34: 46.0000 - val_true_negatives_34: 0.0000e+00 - val_false_positives_34: 9.0000 - val_false_negatives_34: 0.0000e+00\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.5000 - true_positives_34: 180.0000 - true_negatives_34: 0.0000e+00 - false_positives_34: 180.0000 - false_negatives_34: 0.0000e+00 - val_loss: 0.6072 - val_accuracy: 0.8364 - val_true_positives_34: 46.0000 - val_true_negatives_34: 0.0000e+00 - val_false_positives_34: 9.0000 - val_false_negatives_34: 0.0000e+00\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.5000 - true_positives_34: 180.0000 - true_negatives_34: 0.0000e+00 - false_positives_34: 180.0000 - false_negatives_34: 0.0000e+00 - val_loss: 0.6082 - val_accuracy: 0.8364 - val_true_positives_34: 46.0000 - val_true_negatives_34: 0.0000e+00 - val_false_positives_34: 9.0000 - val_false_negatives_34: 0.0000e+00\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6778 - accuracy: 0.5000 - true_positives_34: 180.0000 - true_negatives_34: 0.0000e+00 - false_positives_34: 180.0000 - false_negatives_34: 0.0000e+00 - val_loss: 0.6082 - val_accuracy: 0.8364 - val_true_positives_34: 46.0000 - val_true_negatives_34: 0.0000e+00 - val_false_positives_34: 9.0000 - val_false_negatives_34: 0.0000e+00\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6778 - accuracy: 0.5056 - true_positives_34: 44.0000 - true_negatives_34: 138.0000 - false_positives_34: 42.0000 - false_negatives_34: 136.0000 - val_loss: 0.6103 - val_accuracy: 0.2909 - val_true_positives_34: 7.0000 - val_true_negatives_34: 9.0000 - val_false_positives_34: 0.0000e+00 - val_false_negatives_34: 39.0000\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.5222 - true_positives_34: 8.0000 - true_negatives_34: 180.0000 - false_positives_34: 0.0000e+00 - false_negatives_34: 172.0000 - val_loss: 0.6102 - val_accuracy: 0.2909 - val_true_positives_34: 7.0000 - val_true_negatives_34: 9.0000 - val_false_positives_34: 0.0000e+00 - val_false_negatives_34: 39.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 2s 9ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_35: 0.0000e+00 - true_negatives_35: 180.0000 - false_positives_35: 0.0000e+00 - false_negatives_35: 180.0000 - val_loss: 0.6952 - val_accuracy: 0.1636 - val_true_positives_35: 0.0000e+00 - val_true_negatives_35: 9.0000 - val_false_positives_35: 0.0000e+00 - val_false_negatives_35: 46.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4611 - true_positives_35: 45.0000 - true_negatives_35: 121.0000 - false_positives_35: 59.0000 - false_negatives_35: 135.0000 - val_loss: 0.6934 - val_accuracy: 0.1636 - val_true_positives_35: 0.0000e+00 - val_true_negatives_35: 9.0000 - val_false_positives_35: 0.0000e+00 - val_false_negatives_35: 46.0000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4667 - true_positives_35: 118.0000 - true_negatives_35: 50.0000 - false_positives_35: 130.0000 - false_negatives_35: 62.0000 - val_loss: 0.6929 - val_accuracy: 0.8364 - val_true_positives_35: 46.0000 - val_true_negatives_35: 0.0000e+00 - val_false_positives_35: 9.0000 - val_false_negatives_35: 0.0000e+00\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5111 - true_positives_35: 18.0000 - true_negatives_35: 166.0000 - false_positives_35: 14.0000 - false_negatives_35: 162.0000 - val_loss: 0.6937 - val_accuracy: 0.1636 - val_true_positives_35: 0.0000e+00 - val_true_negatives_35: 9.0000 - val_false_positives_35: 0.0000e+00 - val_false_negatives_35: 46.0000\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_35: 0.0000e+00 - true_negatives_35: 180.0000 - false_positives_35: 0.0000e+00 - false_negatives_35: 180.0000 - val_loss: 0.6942 - val_accuracy: 0.1636 - val_true_positives_35: 0.0000e+00 - val_true_negatives_35: 9.0000 - val_false_positives_35: 0.0000e+00 - val_false_negatives_35: 46.0000\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4667 - true_positives_35: 46.0000 - true_negatives_35: 122.0000 - false_positives_35: 58.0000 - false_negatives_35: 134.0000 - val_loss: 0.6935 - val_accuracy: 0.1636 - val_true_positives_35: 0.0000e+00 - val_true_negatives_35: 9.0000 - val_false_positives_35: 0.0000e+00 - val_false_negatives_35: 46.0000\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_35: 0.0000e+00 - true_negatives_35: 180.0000 - false_positives_35: 0.0000e+00 - false_negatives_35: 180.0000 - val_loss: 0.6939 - val_accuracy: 0.1636 - val_true_positives_35: 0.0000e+00 - val_true_negatives_35: 9.0000 - val_false_positives_35: 0.0000e+00 - val_false_negatives_35: 46.0000\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4611 - true_positives_35: 113.0000 - true_negatives_35: 53.0000 - false_positives_35: 127.0000 - false_negatives_35: 67.0000 - val_loss: 0.6928 - val_accuracy: 0.8364 - val_true_positives_35: 46.0000 - val_true_negatives_35: 0.0000e+00 - val_false_positives_35: 9.0000 - val_false_negatives_35: 0.0000e+00\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4833 - true_positives_35: 5.0000 - true_negatives_35: 169.0000 - false_positives_35: 11.0000 - false_negatives_35: 175.0000 - val_loss: 0.6951 - val_accuracy: 0.1636 - val_true_positives_35: 0.0000e+00 - val_true_negatives_35: 9.0000 - val_false_positives_35: 0.0000e+00 - val_false_negatives_35: 46.0000\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4611 - true_positives_35: 121.0000 - true_negatives_35: 45.0000 - false_positives_35: 135.0000 - false_negatives_35: 59.0000 - val_loss: 0.6931 - val_accuracy: 0.8364 - val_true_positives_35: 46.0000 - val_true_negatives_35: 0.0000e+00 - val_false_positives_35: 9.0000 - val_false_negatives_35: 0.0000e+00\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4611 - true_positives_35: 13.0000 - true_negatives_35: 153.0000 - false_positives_35: 27.0000 - false_negatives_35: 167.0000 - val_loss: 0.6937 - val_accuracy: 0.1636 - val_true_positives_35: 0.0000e+00 - val_true_negatives_35: 9.0000 - val_false_positives_35: 0.0000e+00 - val_false_negatives_35: 46.0000\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_35: 0.0000e+00 - true_negatives_35: 180.0000 - false_positives_35: 0.0000e+00 - false_negatives_35: 180.0000 - val_loss: 0.6940 - val_accuracy: 0.1636 - val_true_positives_35: 0.0000e+00 - val_true_negatives_35: 9.0000 - val_false_positives_35: 0.0000e+00 - val_false_negatives_35: 46.0000\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4556 - true_positives_35: 76.0000 - true_negatives_35: 88.0000 - false_positives_35: 92.0000 - false_negatives_35: 104.0000 - val_loss: 0.6932 - val_accuracy: 0.1636 - val_true_positives_35: 0.0000e+00 - val_true_negatives_35: 9.0000 - val_false_positives_35: 0.0000e+00 - val_false_negatives_35: 46.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 1s 8ms/step - loss: 2.4445 - accuracy: 0.5000 - true_positives_36: 28.0000 - true_negatives_36: 152.0000 - false_positives_36: 28.0000 - false_negatives_36: 152.0000 - val_loss: 0.6994 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6999 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6990 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6986 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6994 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6980 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6982 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6979 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6968 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6964 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6970 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6964 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6963 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6959 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6961 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6955 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6959 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6951 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 19/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6952 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6941 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6947 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6941 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 23/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6944 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 24/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6947 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 25/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6953 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 26/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6948 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "Epoch 27/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_36: 0.0000e+00 - true_negatives_36: 180.0000 - false_positives_36: 0.0000e+00 - false_negatives_36: 180.0000 - val_loss: 0.6945 - val_accuracy: 0.1636 - val_true_positives_36: 0.0000e+00 - val_true_negatives_36: 9.0000 - val_false_positives_36: 0.0000e+00 - val_false_negatives_36: 46.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 1s 8ms/step - loss: 24.0197 - accuracy: 0.5889 - true_positives_37: 73.0000 - true_negatives_37: 139.0000 - false_positives_37: 41.0000 - false_negatives_37: 107.0000 - val_loss: 6.7749 - val_accuracy: 0.7636 - val_true_positives_37: 40.0000 - val_true_negatives_37: 2.0000 - val_false_positives_37: 7.0000 - val_false_negatives_37: 6.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 1.3974 - accuracy: 0.5389 - true_positives_37: 164.0000 - true_negatives_37: 30.0000 - false_positives_37: 150.0000 - false_negatives_37: 16.0000 - val_loss: 1.0588 - val_accuracy: 0.8182 - val_true_positives_37: 45.0000 - val_true_negatives_37: 0.0000e+00 - val_false_positives_37: 9.0000 - val_false_negatives_37: 1.0000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7249 - accuracy: 0.5139 - true_positives_37: 175.0000 - true_negatives_37: 10.0000 - false_positives_37: 170.0000 - false_negatives_37: 5.0000 - val_loss: 0.7193 - val_accuracy: 0.8182 - val_true_positives_37: 45.0000 - val_true_negatives_37: 0.0000e+00 - val_false_positives_37: 9.0000 - val_false_negatives_37: 1.0000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7070 - accuracy: 0.5000 - true_positives_37: 179.0000 - true_negatives_37: 1.0000 - false_positives_37: 179.0000 - false_negatives_37: 1.0000 - val_loss: 0.6773 - val_accuracy: 0.8364 - val_true_positives_37: 46.0000 - val_true_negatives_37: 0.0000e+00 - val_false_positives_37: 9.0000 - val_false_negatives_37: 0.0000e+00\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6997 - accuracy: 0.4972 - true_positives_37: 178.0000 - true_negatives_37: 1.0000 - false_positives_37: 179.0000 - false_negatives_37: 2.0000 - val_loss: 0.6777 - val_accuracy: 0.8364 - val_true_positives_37: 46.0000 - val_true_negatives_37: 0.0000e+00 - val_false_positives_37: 9.0000 - val_false_negatives_37: 0.0000e+00\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5000 - true_positives_37: 180.0000 - true_negatives_37: 0.0000e+00 - false_positives_37: 180.0000 - false_negatives_37: 0.0000e+00 - val_loss: 0.6784 - val_accuracy: 0.8364 - val_true_positives_37: 46.0000 - val_true_negatives_37: 0.0000e+00 - val_false_positives_37: 9.0000 - val_false_negatives_37: 0.0000e+00\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5000 - true_positives_37: 180.0000 - true_negatives_37: 0.0000e+00 - false_positives_37: 180.0000 - false_negatives_37: 0.0000e+00 - val_loss: 0.6788 - val_accuracy: 0.8364 - val_true_positives_37: 46.0000 - val_true_negatives_37: 0.0000e+00 - val_false_positives_37: 9.0000 - val_false_negatives_37: 0.0000e+00\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5000 - true_positives_37: 180.0000 - true_negatives_37: 0.0000e+00 - false_positives_37: 180.0000 - false_negatives_37: 0.0000e+00 - val_loss: 0.6798 - val_accuracy: 0.8364 - val_true_positives_37: 46.0000 - val_true_negatives_37: 0.0000e+00 - val_false_positives_37: 9.0000 - val_false_negatives_37: 0.0000e+00\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5000 - true_positives_37: 180.0000 - true_negatives_37: 0.0000e+00 - false_positives_37: 180.0000 - false_negatives_37: 0.0000e+00 - val_loss: 0.6813 - val_accuracy: 0.8364 - val_true_positives_37: 46.0000 - val_true_negatives_37: 0.0000e+00 - val_false_positives_37: 9.0000 - val_false_negatives_37: 0.0000e+00\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "45/45 [==============================] - 2s 8ms/step - loss: 34.2189 - accuracy: 0.5306 - true_positives_38: 105.0000 - true_negatives_38: 86.0000 - false_positives_38: 94.0000 - false_negatives_38: 75.0000 - val_loss: 0.6652 - val_accuracy: 0.2182 - val_true_positives_38: 3.0000 - val_true_negatives_38: 9.0000 - val_false_positives_38: 0.0000e+00 - val_false_negatives_38: 43.0000\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_38: 0.0000e+00 - true_negatives_38: 180.0000 - false_positives_38: 0.0000e+00 - false_negatives_38: 180.0000 - val_loss: 0.7046 - val_accuracy: 0.1636 - val_true_positives_38: 0.0000e+00 - val_true_negatives_38: 9.0000 - val_false_positives_38: 0.0000e+00 - val_false_negatives_38: 46.0000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_38: 0.0000e+00 - true_negatives_38: 180.0000 - false_positives_38: 0.0000e+00 - false_negatives_38: 180.0000 - val_loss: 0.7046 - val_accuracy: 0.1636 - val_true_positives_38: 0.0000e+00 - val_true_negatives_38: 9.0000 - val_false_positives_38: 0.0000e+00 - val_false_negatives_38: 46.0000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_38: 0.0000e+00 - true_negatives_38: 180.0000 - false_positives_38: 0.0000e+00 - false_negatives_38: 180.0000 - val_loss: 0.7038 - val_accuracy: 0.1636 - val_true_positives_38: 0.0000e+00 - val_true_negatives_38: 9.0000 - val_false_positives_38: 0.0000e+00 - val_false_negatives_38: 46.0000\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_38: 0.0000e+00 - true_negatives_38: 180.0000 - false_positives_38: 0.0000e+00 - false_negatives_38: 180.0000 - val_loss: 0.7038 - val_accuracy: 0.1636 - val_true_positives_38: 0.0000e+00 - val_true_negatives_38: 9.0000 - val_false_positives_38: 0.0000e+00 - val_false_negatives_38: 46.0000\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_38: 0.0000e+00 - true_negatives_38: 180.0000 - false_positives_38: 0.0000e+00 - false_negatives_38: 180.0000 - val_loss: 0.7027 - val_accuracy: 0.1636 - val_true_positives_38: 0.0000e+00 - val_true_negatives_38: 9.0000 - val_false_positives_38: 0.0000e+00 - val_false_negatives_38: 46.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 1s 8ms/step - loss: 0.9880 - accuracy: 0.5000 - true_positives_39: 171.0000 - true_negatives_39: 9.0000 - false_positives_39: 171.0000 - false_negatives_39: 9.0000 - val_loss: 0.6916 - val_accuracy: 0.8364 - val_true_positives_39: 46.0000 - val_true_negatives_39: 0.0000e+00 - val_false_positives_39: 9.0000 - val_false_negatives_39: 0.0000e+00\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_39: 180.0000 - true_negatives_39: 0.0000e+00 - false_positives_39: 180.0000 - false_negatives_39: 0.0000e+00 - val_loss: 0.6909 - val_accuracy: 0.8364 - val_true_positives_39: 46.0000 - val_true_negatives_39: 0.0000e+00 - val_false_positives_39: 9.0000 - val_false_negatives_39: 0.0000e+00\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_39: 180.0000 - true_negatives_39: 0.0000e+00 - false_positives_39: 180.0000 - false_negatives_39: 0.0000e+00 - val_loss: 0.6918 - val_accuracy: 0.8364 - val_true_positives_39: 46.0000 - val_true_negatives_39: 0.0000e+00 - val_false_positives_39: 9.0000 - val_false_negatives_39: 0.0000e+00\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_39: 180.0000 - true_negatives_39: 0.0000e+00 - false_positives_39: 180.0000 - false_negatives_39: 0.0000e+00 - val_loss: 0.6911 - val_accuracy: 0.8364 - val_true_positives_39: 46.0000 - val_true_negatives_39: 0.0000e+00 - val_false_positives_39: 9.0000 - val_false_negatives_39: 0.0000e+00\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4722 - true_positives_39: 167.0000 - true_negatives_39: 3.0000 - false_positives_39: 177.0000 - false_negatives_39: 13.0000 - val_loss: 0.6920 - val_accuracy: 0.8364 - val_true_positives_39: 46.0000 - val_true_negatives_39: 0.0000e+00 - val_false_positives_39: 9.0000 - val_false_negatives_39: 0.0000e+00\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_39: 180.0000 - true_negatives_39: 0.0000e+00 - false_positives_39: 180.0000 - false_negatives_39: 0.0000e+00 - val_loss: 0.6921 - val_accuracy: 0.8364 - val_true_positives_39: 46.0000 - val_true_negatives_39: 0.0000e+00 - val_false_positives_39: 9.0000 - val_false_negatives_39: 0.0000e+00\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000 - true_positives_39: 180.0000 - true_negatives_39: 0.0000e+00 - false_positives_39: 180.0000 - false_negatives_39: 0.0000e+00 - val_loss: 0.6917 - val_accuracy: 0.8364 - val_true_positives_39: 46.0000 - val_true_negatives_39: 0.0000e+00 - val_false_positives_39: 9.0000 - val_false_negatives_39: 0.0000e+00\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 1s 8ms/step - loss: 28.2959 - accuracy: 0.5750 - true_positives_40: 72.0000 - true_negatives_40: 135.0000 - false_positives_40: 45.0000 - false_negatives_40: 108.0000 - val_loss: 0.6813 - val_accuracy: 0.8364 - val_true_positives_40: 46.0000 - val_true_negatives_40: 0.0000e+00 - val_false_positives_40: 9.0000 - val_false_negatives_40: 0.0000e+00\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.8533 - accuracy: 0.5417 - true_positives_40: 178.0000 - true_negatives_40: 17.0000 - false_positives_40: 163.0000 - false_negatives_40: 2.0000 - val_loss: 0.6791 - val_accuracy: 0.8364 - val_true_positives_40: 46.0000 - val_true_negatives_40: 0.0000e+00 - val_false_positives_40: 9.0000 - val_false_negatives_40: 0.0000e+00\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7802 - accuracy: 0.5389 - true_positives_40: 179.0000 - true_negatives_40: 15.0000 - false_positives_40: 165.0000 - false_negatives_40: 1.0000 - val_loss: 0.6793 - val_accuracy: 0.8364 - val_true_positives_40: 46.0000 - val_true_negatives_40: 0.0000e+00 - val_false_positives_40: 9.0000 - val_false_negatives_40: 0.0000e+00\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7686 - accuracy: 0.5333 - true_positives_40: 179.0000 - true_negatives_40: 13.0000 - false_positives_40: 167.0000 - false_negatives_40: 1.0000 - val_loss: 0.6775 - val_accuracy: 0.8364 - val_true_positives_40: 46.0000 - val_true_negatives_40: 0.0000e+00 - val_false_positives_40: 9.0000 - val_false_negatives_40: 0.0000e+00\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7598 - accuracy: 0.5278 - true_positives_40: 179.0000 - true_negatives_40: 11.0000 - false_positives_40: 169.0000 - false_negatives_40: 1.0000 - val_loss: 0.6780 - val_accuracy: 0.8364 - val_true_positives_40: 46.0000 - val_true_negatives_40: 0.0000e+00 - val_false_positives_40: 9.0000 - val_false_negatives_40: 0.0000e+00\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7452 - accuracy: 0.5250 - true_positives_40: 179.0000 - true_negatives_40: 10.0000 - false_positives_40: 170.0000 - false_negatives_40: 1.0000 - val_loss: 0.6781 - val_accuracy: 0.8364 - val_true_positives_40: 46.0000 - val_true_negatives_40: 0.0000e+00 - val_false_positives_40: 9.0000 - val_false_negatives_40: 0.0000e+00\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7250 - accuracy: 0.5194 - true_positives_40: 179.0000 - true_negatives_40: 8.0000 - false_positives_40: 172.0000 - false_negatives_40: 1.0000 - val_loss: 0.6770 - val_accuracy: 0.8364 - val_true_positives_40: 46.0000 - val_true_negatives_40: 0.0000e+00 - val_false_positives_40: 9.0000 - val_false_negatives_40: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.5167 - true_positives_40: 179.0000 - true_negatives_40: 7.0000 - false_positives_40: 173.0000 - false_negatives_40: 1.0000 - val_loss: 0.6771 - val_accuracy: 0.8364 - val_true_positives_40: 46.0000 - val_true_negatives_40: 0.0000e+00 - val_false_positives_40: 9.0000 - val_false_negatives_40: 0.0000e+00\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.7067 - accuracy: 0.5028 - true_positives_40: 179.0000 - true_negatives_40: 2.0000 - false_positives_40: 178.0000 - false_negatives_40: 1.0000 - val_loss: 0.6779 - val_accuracy: 0.8364 - val_true_positives_40: 46.0000 - val_true_negatives_40: 0.0000e+00 - val_false_positives_40: 9.0000 - val_false_negatives_40: 0.0000e+00\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5000 - true_positives_40: 180.0000 - true_negatives_40: 0.0000e+00 - false_positives_40: 180.0000 - false_negatives_40: 0.0000e+00 - val_loss: 0.6787 - val_accuracy: 0.8364 - val_true_positives_40: 46.0000 - val_true_negatives_40: 0.0000e+00 - val_false_positives_40: 9.0000 - val_false_negatives_40: 0.0000e+00\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5000 - true_positives_40: 180.0000 - true_negatives_40: 0.0000e+00 - false_positives_40: 180.0000 - false_negatives_40: 0.0000e+00 - val_loss: 0.6801 - val_accuracy: 0.8364 - val_true_positives_40: 46.0000 - val_true_negatives_40: 0.0000e+00 - val_false_positives_40: 9.0000 - val_false_negatives_40: 0.0000e+00\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5000 - true_positives_40: 180.0000 - true_negatives_40: 0.0000e+00 - false_positives_40: 180.0000 - false_negatives_40: 0.0000e+00 - val_loss: 0.6807 - val_accuracy: 0.8364 - val_true_positives_40: 46.0000 - val_true_negatives_40: 0.0000e+00 - val_false_positives_40: 9.0000 - val_false_negatives_40: 0.0000e+00\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 1s 8ms/step - loss: 0.6932 - accuracy: 0.4889 - true_positives_41: 158.0000 - true_negatives_41: 18.0000 - false_positives_41: 162.0000 - false_negatives_41: 22.0000 - val_loss: 0.6797 - val_accuracy: 0.8364 - val_true_positives_41: 46.0000 - val_true_negatives_41: 0.0000e+00 - val_false_positives_41: 9.0000 - val_false_negatives_41: 0.0000e+00\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4778 - true_positives_41: 48.0000 - true_negatives_41: 124.0000 - false_positives_41: 56.0000 - false_negatives_41: 132.0000 - val_loss: 0.6805 - val_accuracy: 0.8364 - val_true_positives_41: 46.0000 - val_true_negatives_41: 0.0000e+00 - val_false_positives_41: 9.0000 - val_false_negatives_41: 0.0000e+00\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4778 - true_positives_41: 16.0000 - true_negatives_41: 156.0000 - false_positives_41: 24.0000 - false_negatives_41: 164.0000 - val_loss: 0.6808 - val_accuracy: 0.1818 - val_true_positives_41: 1.0000 - val_true_negatives_41: 9.0000 - val_false_positives_41: 0.0000e+00 - val_false_negatives_41: 45.0000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4833 - true_positives_41: 165.0000 - true_negatives_41: 9.0000 - false_positives_41: 171.0000 - false_negatives_41: 15.0000 - val_loss: 0.6799 - val_accuracy: 0.8364 - val_true_positives_41: 46.0000 - val_true_negatives_41: 0.0000e+00 - val_false_positives_41: 9.0000 - val_false_negatives_41: 0.0000e+00\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4833 - true_positives_41: 25.0000 - true_negatives_41: 149.0000 - false_positives_41: 31.0000 - false_negatives_41: 155.0000 - val_loss: 0.6810 - val_accuracy: 0.1818 - val_true_positives_41: 1.0000 - val_true_negatives_41: 9.0000 - val_false_positives_41: 0.0000e+00 - val_false_negatives_41: 45.0000\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5000 - true_positives_41: 0.0000e+00 - true_negatives_41: 180.0000 - false_positives_41: 0.0000e+00 - false_negatives_41: 180.0000 - val_loss: 0.6806 - val_accuracy: 0.1818 - val_true_positives_41: 1.0000 - val_true_negatives_41: 9.0000 - val_false_positives_41: 0.0000e+00 - val_false_negatives_41: 45.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 3: -0.001622608585266673.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'features': ['CHILD_SEX',\n",
       "  'IDD_SCORE',\n",
       "  'AGE',\n",
       "  'HHID_count',\n",
       "  'HH_AGE',\n",
       "  'FOOD_EXPENSE_WEEKLY',\n",
       "  'NON-FOOD_EXPENSE_WEEKLY',\n",
       "  'HDD_SCORE',\n",
       "  'FOOD_INSECURITY',\n",
       "  'YoungBoys',\n",
       "  'YoungGirls',\n",
       "  'AverageMonthlyIncome',\n",
       "  'BEN_4PS',\n",
       "  'AREA_TYPE',\n",
       "  'FOOD_EXPENSE_WEEKLY_pc',\n",
       "  'NON-FOOD_EXPENSE_WEEKLY_pc',\n",
       "  'AverageMonthlyIncome_pc'],\n",
       " 'layers': [16, 7, 2],\n",
       " 'oversample': 'none'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lower learning rate\n",
    "param_grid = {\n",
    "    'oversample': ['none', 'smote', 'adasyn', 'borderline'],\n",
    "    'features': [train_df.drop([TASK_TO_RUN], axis=1).columns.tolist()],\n",
    "    'layers': [[16, 7, 2]]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_dnn, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "097e9a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "31/31 [==============================] - 1s 10ms/step - loss: 51.9733 - accuracy: 0.1736 - true_positives_42: 0.0000e+00 - true_negatives_42: 42.0000 - false_positives_42: 0.0000e+00 - false_negatives_42: 200.0000 - val_loss: 20.0974 - val_accuracy: 0.1639 - val_true_positives_42: 0.0000e+00 - val_true_negatives_42: 10.0000 - val_false_positives_42: 0.0000e+00 - val_false_negatives_42: 51.0000\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.2723 - accuracy: 0.2397 - true_positives_42: 22.0000 - true_negatives_42: 36.0000 - false_positives_42: 6.0000 - false_negatives_42: 178.0000 - val_loss: 5.7631 - val_accuracy: 0.3115 - val_true_positives_42: 14.0000 - val_true_negatives_42: 5.0000 - val_false_positives_42: 5.0000 - val_false_negatives_42: 37.0000\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.1191 - accuracy: 0.5372 - true_positives_42: 116.0000 - true_negatives_42: 14.0000 - false_positives_42: 28.0000 - false_negatives_42: 84.0000 - val_loss: 2.0889 - val_accuracy: 0.5082 - val_true_positives_42: 28.0000 - val_true_negatives_42: 3.0000 - val_false_positives_42: 7.0000 - val_false_negatives_42: 23.0000\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0602 - accuracy: 0.6983 - true_positives_42: 158.0000 - true_negatives_42: 11.0000 - false_positives_42: 31.0000 - false_negatives_42: 42.0000 - val_loss: 0.9544 - val_accuracy: 0.6393 - val_true_positives_42: 37.0000 - val_true_negatives_42: 2.0000 - val_false_positives_42: 8.0000 - val_false_negatives_42: 14.0000\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.7485 - accuracy: 0.7769 - true_positives_42: 180.0000 - true_negatives_42: 8.0000 - false_positives_42: 34.0000 - false_negatives_42: 20.0000 - val_loss: 0.7069 - val_accuracy: 0.7541 - val_true_positives_42: 45.0000 - val_true_negatives_42: 1.0000 - val_false_positives_42: 9.0000 - val_false_negatives_42: 6.0000\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.7934 - true_positives_42: 187.0000 - true_negatives_42: 5.0000 - false_positives_42: 37.0000 - false_negatives_42: 13.0000 - val_loss: 0.6538 - val_accuracy: 0.8033 - val_true_positives_42: 49.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 2.0000\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.8182 - true_positives_42: 195.0000 - true_negatives_42: 3.0000 - false_positives_42: 39.0000 - false_negatives_42: 5.0000 - val_loss: 0.6464 - val_accuracy: 0.8197 - val_true_positives_42: 50.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 1.0000\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.8182 - true_positives_42: 195.0000 - true_negatives_42: 3.0000 - false_positives_42: 39.0000 - false_negatives_42: 5.0000 - val_loss: 0.6408 - val_accuracy: 0.8197 - val_true_positives_42: 50.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 1.0000\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.8223 - true_positives_42: 196.0000 - true_negatives_42: 3.0000 - false_positives_42: 39.0000 - false_negatives_42: 4.0000 - val_loss: 0.6351 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.8223 - true_positives_42: 196.0000 - true_negatives_42: 3.0000 - false_positives_42: 39.0000 - false_negatives_42: 4.0000 - val_loss: 0.6299 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.8223 - true_positives_42: 196.0000 - true_negatives_42: 3.0000 - false_positives_42: 39.0000 - false_negatives_42: 4.0000 - val_loss: 0.6243 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.8223 - true_positives_42: 196.0000 - true_negatives_42: 3.0000 - false_positives_42: 39.0000 - false_negatives_42: 4.0000 - val_loss: 0.6189 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.8264 - true_positives_42: 197.0000 - true_negatives_42: 3.0000 - false_positives_42: 39.0000 - false_negatives_42: 3.0000 - val_loss: 0.6135 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.8264 - true_positives_42: 197.0000 - true_negatives_42: 3.0000 - false_positives_42: 39.0000 - false_negatives_42: 3.0000 - val_loss: 0.6079 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.8264 - true_positives_42: 197.0000 - true_negatives_42: 3.0000 - false_positives_42: 39.0000 - false_negatives_42: 3.0000 - val_loss: 0.6027 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.8264 - true_positives_42: 197.0000 - true_negatives_42: 3.0000 - false_positives_42: 39.0000 - false_negatives_42: 3.0000 - val_loss: 0.5978 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.8306 - true_positives_42: 198.0000 - true_negatives_42: 3.0000 - false_positives_42: 39.0000 - false_negatives_42: 2.0000 - val_loss: 0.5925 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.8347 - true_positives_42: 199.0000 - true_negatives_42: 3.0000 - false_positives_42: 39.0000 - false_negatives_42: 1.0000 - val_loss: 0.5877 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5879 - accuracy: 0.8306 - true_positives_42: 199.0000 - true_negatives_42: 2.0000 - false_positives_42: 40.0000 - false_negatives_42: 1.0000 - val_loss: 0.5829 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.8306 - true_positives_42: 199.0000 - true_negatives_42: 2.0000 - false_positives_42: 40.0000 - false_negatives_42: 1.0000 - val_loss: 0.5786 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.8306 - true_positives_42: 199.0000 - true_negatives_42: 2.0000 - false_positives_42: 40.0000 - false_negatives_42: 1.0000 - val_loss: 0.5741 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.8306 - true_positives_42: 199.0000 - true_negatives_42: 2.0000 - false_positives_42: 40.0000 - false_negatives_42: 1.0000 - val_loss: 0.5697 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.8306 - true_positives_42: 199.0000 - true_negatives_42: 2.0000 - false_positives_42: 40.0000 - false_negatives_42: 1.0000 - val_loss: 0.5653 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.8306 - true_positives_42: 199.0000 - true_negatives_42: 2.0000 - false_positives_42: 40.0000 - false_negatives_42: 1.0000 - val_loss: 0.5609 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.8306 - true_positives_42: 199.0000 - true_negatives_42: 2.0000 - false_positives_42: 40.0000 - false_negatives_42: 1.0000 - val_loss: 0.5567 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.8306 - true_positives_42: 199.0000 - true_negatives_42: 2.0000 - false_positives_42: 40.0000 - false_negatives_42: 1.0000 - val_loss: 0.5523 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.8264 - true_positives_42: 199.0000 - true_negatives_42: 1.0000 - false_positives_42: 41.0000 - false_negatives_42: 1.0000 - val_loss: 0.5488 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.8264 - true_positives_42: 199.0000 - true_negatives_42: 1.0000 - false_positives_42: 41.0000 - false_negatives_42: 1.0000 - val_loss: 0.5449 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.8306 - true_positives_42: 199.0000 - true_negatives_42: 2.0000 - false_positives_42: 40.0000 - false_negatives_42: 1.0000 - val_loss: 0.5413 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.8306 - true_positives_42: 199.0000 - true_negatives_42: 2.0000 - false_positives_42: 40.0000 - false_negatives_42: 1.0000 - val_loss: 0.5378 - val_accuracy: 0.8361 - val_true_positives_42: 51.0000 - val_true_negatives_42: 0.0000e+00 - val_false_positives_42: 10.0000 - val_false_negatives_42: 0.0000e+00\n",
      "38/38 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8250825082508251, 1.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'oversample': 'none',\n",
    "    'features': train_df.drop([TASK_TO_RUN], axis=1).columns.tolist(),\n",
    "    'layers': [16, 7, 2]\n",
    "}\n",
    "\n",
    "predicted = train_dnn(train_df, test_df, TASK_TO_RUN, **params)\n",
    "accuracy, sensitivity, specificity, kappa = get_metrics(predicted, convert_labels(test_df[TASK_TO_RUN]))\n",
    "accuracy, sensitivity, specificity, kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294a6075",
   "metadata": {},
   "source": [
    "## NNRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "981bcccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnrf import ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64280863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module nnrf.ml.loss in nnrf.ml:\n",
      "\n",
      "NAME\n",
      "    nnrf.ml.loss\n",
      "\n",
      "CLASSES\n",
      "    abc.ABC(builtins.object)\n",
      "        LossFunction(nnrf.utils._base.Base, abc.ABC)\n",
      "            CrossEntropy\n",
      "            Hinge\n",
      "            Huber\n",
      "            MAE\n",
      "            MSE\n",
      "    nnrf.utils._base.Base(builtins.object)\n",
      "        LossFunction(nnrf.utils._base.Base, abc.ABC)\n",
      "            CrossEntropy\n",
      "            Hinge\n",
      "            Huber\n",
      "            MAE\n",
      "            MSE\n",
      "    \n",
      "    class CrossEntropy(LossFunction)\n",
      "     |  Cross Entropy Loss.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CrossEntropy\n",
      "     |      LossFunction\n",
      "     |      nnrf.utils._base.Base\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  gradient(self, Y_hat, Y, axis=1)\n",
      "     |      Derivative of loss/error between labels `Y_hat` and targets `Y`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Y_hat : array-like, shape=(n_samples, n_classes)\n",
      "     |              Prediction labels.\n",
      "     |      \n",
      "     |      Y : array-like, shape=(n_samples, n_classes)\n",
      "     |              Ground truth labels.\n",
      "     |      \n",
      "     |      axis : int, default=1\n",
      "     |              Axis to compute loss.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dY : array-like, shape=(n_samples, n_classes)\n",
      "     |              The derivative of the error of each sample for each class.\n",
      "     |  \n",
      "     |  loss(self, Y_hat, Y, axis=1)\n",
      "     |      Loss/error between labels `Y_hat` and targets `Y`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Y_hat : array-like, shape=(n_samples, n_classes)\n",
      "     |              Prediction labels.\n",
      "     |      \n",
      "     |      Y : array-like, shape=(n_samples, n_classes)\n",
      "     |              Ground truth labels.\n",
      "     |      \n",
      "     |      axis : int, default=1\n",
      "     |              Axis to compute loss.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loss : array-like, shape=(n_samples, n_classes)\n",
      "     |              The error of each sample for each class.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nnrf.utils._base.Base:\n",
      "     |  \n",
      "     |  get_params(self)\n",
      "     |      Get all parameters of the object, recursively.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |              Dictionary of object parameters.\n",
      "     |  \n",
      "     |  set_params(self, params)\n",
      "     |      Set the attributes of the object with the given\n",
      "     |      parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |              Dictionary of object parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : Base\n",
      "     |              Itself, with parameters set.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nnrf.utils._base.Base:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Hinge(LossFunction)\n",
      "     |  Hinge Loss.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Hinge\n",
      "     |      LossFunction\n",
      "     |      nnrf.utils._base.Base\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  gradient(self, Y_hat, Y, axis=1)\n",
      "     |      Derivative of loss/error between labels `Y_hat` and targets `Y`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Y_hat : array-like, shape=(n_samples, n_classes)\n",
      "     |              Prediction labels.\n",
      "     |      \n",
      "     |      Y : array-like, shape=(n_samples, n_classes)\n",
      "     |              Ground truth labels.\n",
      "     |      \n",
      "     |      axis : int, default=1\n",
      "     |              Axis to compute loss.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dY : array-like, shape=(n_samples, n_classes)\n",
      "     |              The derivative of the error of each sample for each class.\n",
      "     |  \n",
      "     |  loss(self, Y_hat, Y, axis=1)\n",
      "     |      Loss/error between labels `Y_hat` and targets `Y`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Y_hat : array-like, shape=(n_samples, n_classes)\n",
      "     |              Prediction labels.\n",
      "     |      \n",
      "     |      Y : array-like, shape=(n_samples, n_classes)\n",
      "     |              Ground truth labels.\n",
      "     |      \n",
      "     |      axis : int, default=1\n",
      "     |              Axis to compute loss.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loss : array-like, shape=(n_samples, n_classes)\n",
      "     |              The error of each sample for each class.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nnrf.utils._base.Base:\n",
      "     |  \n",
      "     |  get_params(self)\n",
      "     |      Get all parameters of the object, recursively.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |              Dictionary of object parameters.\n",
      "     |  \n",
      "     |  set_params(self, params)\n",
      "     |      Set the attributes of the object with the given\n",
      "     |      parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |              Dictionary of object parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : Base\n",
      "     |              Itself, with parameters set.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nnrf.utils._base.Base:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Huber(LossFunction)\n",
      "     |  Huber(delta=1)\n",
      "     |  \n",
      "     |  Huber Loss.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  delta : float, default=1\n",
      "     |          Determines relationship between MSE and MAE\n",
      "     |          character. Higher values approach MSE loss\n",
      "     |          while lower values towards 0 approach MAE loss.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Huber\n",
      "     |      LossFunction\n",
      "     |      nnrf.utils._base.Base\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, delta=1)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  gradient(self, Y_hat, Y, axis=1)\n",
      "     |      Derivative of loss/error between labels `Y_hat` and targets `Y`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Y_hat : array-like, shape=(n_samples, n_classes)\n",
      "     |              Prediction labels.\n",
      "     |      \n",
      "     |      Y : array-like, shape=(n_samples, n_classes)\n",
      "     |              Ground truth labels.\n",
      "     |      \n",
      "     |      axis : int, default=1\n",
      "     |              Axis to compute loss.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dY : array-like, shape=(n_samples, n_classes)\n",
      "     |              The derivative of the error of each sample for each class.\n",
      "     |  \n",
      "     |  loss(self, Y_hat, Y, axis=1)\n",
      "     |      Loss/error between labels `Y_hat` and targets `Y`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Y_hat : array-like, shape=(n_samples, n_classes)\n",
      "     |              Prediction labels.\n",
      "     |      \n",
      "     |      Y : array-like, shape=(n_samples, n_classes)\n",
      "     |              Ground truth labels.\n",
      "     |      \n",
      "     |      axis : int, default=1\n",
      "     |              Axis to compute loss.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loss : array-like, shape=(n_samples, n_classes)\n",
      "     |              The error of each sample for each class.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nnrf.utils._base.Base:\n",
      "     |  \n",
      "     |  get_params(self)\n",
      "     |      Get all parameters of the object, recursively.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |              Dictionary of object parameters.\n",
      "     |  \n",
      "     |  set_params(self, params)\n",
      "     |      Set the attributes of the object with the given\n",
      "     |      parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |              Dictionary of object parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : Base\n",
      "     |              Itself, with parameters set.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nnrf.utils._base.Base:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class LossFunction(nnrf.utils._base.Base, abc.ABC)\n",
      "     |  LossFunction(*args, **kwargs)\n",
      "     |  \n",
      "     |  Base Loss Function.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  scale : tuple or None\n",
      "     |          Acceptable range of loss function for gradient.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LossFunction\n",
      "     |      nnrf.utils._base.Base\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  gradient(self, Y_hat, Y, *args, axis=1, **kwargs)\n",
      "     |      Derivative of loss/error between labels `Y_hat` and targets `Y`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Y_hat : array-like, shape=(n_samples, n_classes)\n",
      "     |              Prediction labels.\n",
      "     |      \n",
      "     |      Y : array-like, shape=(n_samples, n_classes)\n",
      "     |              Ground truth labels.\n",
      "     |      \n",
      "     |      axis : int, default=1\n",
      "     |              Axis to compute loss.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dY : array-like, shape=(n_samples, n_classes)\n",
      "     |              The derivative of the error of each sample for each class.\n",
      "     |  \n",
      "     |  loss(self, Y_hat, Y, *args, axis=1, **kwargs)\n",
      "     |      Loss/error between labels `Y_hat` and targets `Y`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Y_hat : array-like, shape=(n_samples, n_classes)\n",
      "     |              Prediction labels.\n",
      "     |      \n",
      "     |      Y : array-like, shape=(n_samples, n_classes)\n",
      "     |              Ground truth labels.\n",
      "     |      \n",
      "     |      axis : int, default=1\n",
      "     |              Axis to compute loss.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loss : array-like, shape=(n_samples, n_classes)\n",
      "     |              The error of each sample for each class.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'gradient', 'loss'})\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nnrf.utils._base.Base:\n",
      "     |  \n",
      "     |  get_params(self)\n",
      "     |      Get all parameters of the object, recursively.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |              Dictionary of object parameters.\n",
      "     |  \n",
      "     |  set_params(self, params)\n",
      "     |      Set the attributes of the object with the given\n",
      "     |      parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |              Dictionary of object parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : Base\n",
      "     |              Itself, with parameters set.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nnrf.utils._base.Base:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MAE(LossFunction)\n",
      "     |  Mean Absolute Error.\n",
      "     |  Note that this implementation is really\n",
      "     |  just an absolute error and not a mean.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MAE\n",
      "     |      LossFunction\n",
      "     |      nnrf.utils._base.Base\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  gradient(self, Y_hat, Y, axis=1)\n",
      "     |      Derivative of loss/error between labels `Y_hat` and targets `Y`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Y_hat : array-like, shape=(n_samples, n_classes)\n",
      "     |              Prediction labels.\n",
      "     |      \n",
      "     |      Y : array-like, shape=(n_samples, n_classes)\n",
      "     |              Ground truth labels.\n",
      "     |      \n",
      "     |      axis : int, default=1\n",
      "     |              Axis to compute loss.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dY : array-like, shape=(n_samples, n_classes)\n",
      "     |              The derivative of the error of each sample for each class.\n",
      "     |  \n",
      "     |  loss(self, Y_hat, Y, axis=1)\n",
      "     |      Loss/error between labels `Y_hat` and targets `Y`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Y_hat : array-like, shape=(n_samples, n_classes)\n",
      "     |              Prediction labels.\n",
      "     |      \n",
      "     |      Y : array-like, shape=(n_samples, n_classes)\n",
      "     |              Ground truth labels.\n",
      "     |      \n",
      "     |      axis : int, default=1\n",
      "     |              Axis to compute loss.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loss : array-like, shape=(n_samples, n_classes)\n",
      "     |              The error of each sample for each class.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nnrf.utils._base.Base:\n",
      "     |  \n",
      "     |  get_params(self)\n",
      "     |      Get all parameters of the object, recursively.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |              Dictionary of object parameters.\n",
      "     |  \n",
      "     |  set_params(self, params)\n",
      "     |      Set the attributes of the object with the given\n",
      "     |      parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |              Dictionary of object parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : Base\n",
      "     |              Itself, with parameters set.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nnrf.utils._base.Base:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MSE(LossFunction)\n",
      "     |  Mean Squared Error.\n",
      "     |  Note that this implementation is really\n",
      "     |  just a squared error and not a mean.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MSE\n",
      "     |      LossFunction\n",
      "     |      nnrf.utils._base.Base\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  gradient(self, Y_hat, Y, axis=1)\n",
      "     |      Derivative of loss/error between labels `Y_hat` and targets `Y`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Y_hat : array-like, shape=(n_samples, n_classes)\n",
      "     |              Prediction labels.\n",
      "     |      \n",
      "     |      Y : array-like, shape=(n_samples, n_classes)\n",
      "     |              Ground truth labels.\n",
      "     |      \n",
      "     |      axis : int, default=1\n",
      "     |              Axis to compute loss.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dY : array-like, shape=(n_samples, n_classes)\n",
      "     |              The derivative of the error of each sample for each class.\n",
      "     |  \n",
      "     |  loss(self, Y_hat, Y, axis=1)\n",
      "     |      Loss/error between labels `Y_hat` and targets `Y`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Y_hat : array-like, shape=(n_samples, n_classes)\n",
      "     |              Prediction labels.\n",
      "     |      \n",
      "     |      Y : array-like, shape=(n_samples, n_classes)\n",
      "     |              Ground truth labels.\n",
      "     |      \n",
      "     |      axis : int, default=1\n",
      "     |              Axis to compute loss.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loss : array-like, shape=(n_samples, n_classes)\n",
      "     |              The error of each sample for each class.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nnrf.utils._base.Base:\n",
      "     |  \n",
      "     |  get_params(self)\n",
      "     |      Get all parameters of the object, recursively.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |              Dictionary of object parameters.\n",
      "     |  \n",
      "     |  set_params(self, params)\n",
      "     |      Set the attributes of the object with the given\n",
      "     |      parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |              Dictionary of object parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : Base\n",
      "     |              Itself, with parameters set.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nnrf.utils._base.Base:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    get_loss(name)\n",
      "        Lookup table of default loss functions.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        name : LossFunction, None, str\n",
      "                LossFunction to look up. Must be one of:\n",
      "                 - 'mse' : Mean Squared Error.\n",
      "                 - 'mae' : Mean Absolute Error.\n",
      "                 - 'huber' : Huber Loss.\n",
      "                 - 'hinge' : Hinge Loss.\n",
      "                 - 'cross-entropy' : Crossentropy Loss.\n",
      "                 - LossFunction : A custom implementation.\n",
      "                 - None : Return None.\n",
      "                Custom LossFunctions must implement `loss`, `gradient`\n",
      "                functions and contain `scale` attribute.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : LossFunction or None\n",
      "                The loss function.\n",
      "\n",
      "FILE\n",
      "    d:\\admu\\predicting-undernutrition\\thesispu\\lib\\site-packages\\nnrf\\ml\\loss.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ml.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b27b2310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.0.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.0.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# tune\u001b[39;00m\n\u001b[0;32m      2\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moversample\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmote\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mborderline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madasyn\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto_normalize\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mTrue\u001b[39;00m]\n\u001b[0;32m      9\u001b[0m }\n\u001b[1;32m---> 11\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mtune_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTASK_TO_RUN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_FOLDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_nnrf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m best_params\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\src\\predunder\\hypertuning.py:29\u001b[0m, in \u001b[0;36mtune_model\u001b[1;34m(train, label, folds, train_func, param_grid)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, params \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mlist\u001b[39m(ParameterGrid(param_grid))):\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting parameters \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m train_kfold(train, label, folds, train_func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m     30\u001b[0m     score \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKAPPA\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMEAN\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m best_score \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m score:\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\src\\predunder\\training.py:229\u001b[0m, in \u001b[0;36mtrain_kfold\u001b[1;34m(train_set, label, num_fold, train_func, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m predicted \u001b[38;5;241m=\u001b[39m train_func(train, test, label, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    230\u001b[0m accuracy, sensitivity, specificity, kappa \u001b[38;5;241m=\u001b[39m get_metrics(predicted, convert_labels(test[label]))\n\u001b[0;32m    232\u001b[0m acc_per_fold\u001b[38;5;241m.\u001b[39mappend(accuracy)\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\src\\predunder\\training.py:116\u001b[0m, in \u001b[0;36mtrain_nnrf\u001b[1;34m(train, test, label, oversample, to_normalize, learning_rate, reg_factor, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m normalize(X_train)\n\u001b[0;32m    114\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m normalize(X_test)\n\u001b[1;32m--> 116\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m predicted \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\nnrf\\_nnrf.py:227\u001b[0m, in \u001b[0;36mNNRF.fit\u001b[1;34m(self, X, Y, weights)\u001b[0m\n\u001b[0;32m    225\u001b[0m \tX_, Y_, weights_ \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mnext()\n\u001b[0;32m    226\u001b[0m \tds\u001b[38;5;241m.\u001b[39mi \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 227\u001b[0m \t\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\u001b[43m[\u001b[49m\u001b[43me\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitted_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m : \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\nnrf\\utils\\_estimator.py:305\u001b[0m, in \u001b[0;36mBaseClassifier.fit\u001b[1;34m(self, X, Y, weights, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \tearly_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \t\u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 305\u001b[0m Y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mloss(Y_hat, Y_batch), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    307\u001b[0m metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore(Y_batch, Y_hat\u001b[38;5;241m=\u001b[39mY_hat, weights\u001b[38;5;241m=\u001b[39mweights)\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\nnrf\\_nndt.py:234\u001b[0m, in \u001b[0;36mNNDT._forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    232\u001b[0m i \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(X))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m), s)\n\u001b[0;32m    233\u001b[0m p[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m a\n\u001b[1;32m--> 234\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msweights_\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msbias_ \u001b[38;5;66;03m# NC\u001b[39;00m\n\u001b[0;32m    235\u001b[0m Y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax\u001b[38;5;241m.\u001b[39mactivation(z)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_z\u001b[38;5;241m.\u001b[39mappend(z)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mD:\\ADMU\\predicting-undernutrition\\thesisPU\\lib\\site-packages\\numpy\\core\\multiarray.py:740\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(a, b, out)\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;124;03m    result_type(*arrays_and_dtypes)\u001b[39;00m\n\u001b[0;32m    672\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    735\u001b[0m \n\u001b[0;32m    736\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arrays_and_dtypes\n\u001b[1;32m--> 740\u001b[0m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath\u001b[38;5;241m.\u001b[39mdot)\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdot\u001b[39m(a, b, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    742\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;124;03m    dot(a, b, out=None)\u001b[39;00m\n\u001b[0;32m    744\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    828\u001b[0m \n\u001b[0;32m    829\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    830\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, b, out)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tune\n",
    "param_grid = {\n",
    "    'oversample': ['none', 'smote', 'borderline', 'adasyn'],\n",
    "    'n': [5, 10, 20],\n",
    "    'd': [2],\n",
    "    'learning_rate': [0.1],\n",
    "    'reg_factor': [1],\n",
    "    'to_normalize': [True]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_nnrf, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f5d060f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.04243196116926238.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: -0.001798623855220144.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.0.\n",
      "\n",
      "Starting parameters 3...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 3: 0.0.\n",
      "\n",
      "Starting parameters 4...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 4: 0.0.\n",
      "\n",
      "Starting parameters 5...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 5: 0.0.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'d': 2,\n",
       " 'learning_rate': 0.1,\n",
       " 'n': 20,\n",
       " 'oversample': 'adasyn',\n",
       " 'reg_factor': 1e-05}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune\n",
    "param_grid = {\n",
    "    'oversample': ['adasyn'],\n",
    "    'n': [20],\n",
    "    'd': [2],\n",
    "    'learning_rate': [0.1],\n",
    "    'reg_factor': [1e-5, 1e-2, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_nnrf, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27b81863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.059913809083530487.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.020849499321348202.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.06735555818780344.\n",
      "\n",
      "Starting parameters 3...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 3: 0.07455233946298342.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'d': 2,\n",
       " 'learning_rate': 0.1,\n",
       " 'n': 20,\n",
       " 'oversample': 'adasyn',\n",
       " 'reg_factor': 0.001}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune\n",
    "param_grid = {\n",
    "    'oversample': ['adasyn'],\n",
    "    'n': [20],\n",
    "    'd': [2],\n",
    "    'learning_rate': [0.1],\n",
    "    'reg_factor': [1e-10, 1e-8, 1e-5, 1e-3]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_nnrf, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2efac561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.00030362880891083855.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.051477462785325015.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.03281216155672953.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'d': 2,\n",
       " 'learning_rate': 0.1,\n",
       " 'n': 20,\n",
       " 'oversample': 'adasyn',\n",
       " 'reg_factor': 0.001}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune\n",
    "param_grid = {\n",
    "    'oversample': ['adasyn'],\n",
    "    'n': [20],\n",
    "    'd': [2],\n",
    "    'learning_rate': [0.1],\n",
    "    'reg_factor': [5e-4, 1e-3, 3e-3]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_nnrf, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecc86428",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.03490711683728204.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.0725851499574243.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.08461610091003043.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'d': 2,\n",
       " 'learning_rate': 0.1,\n",
       " 'n': 100,\n",
       " 'oversample': 'adasyn',\n",
       " 'reg_factor': 0.001}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune\n",
    "param_grid = {\n",
    "    'oversample': ['adasyn'],\n",
    "    'n': [20, 50, 100],\n",
    "    'd': [2],\n",
    "    'learning_rate': [0.1],\n",
    "    'reg_factor': [1e-3]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_nnrf, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31a23d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.0631783749547793.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.04597710705811423.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.05300933136112214.\n",
      "\n",
      "Starting parameters 3...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 3: 0.0.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'d': 2,\n",
       " 'learning_rate': 0.1,\n",
       " 'n': 100,\n",
       " 'oversample': 'adasyn',\n",
       " 'reg_factor': 0.001}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune\n",
    "param_grid = {\n",
    "    'oversample': ['adasyn', 'smote', 'borderline', 'none'],\n",
    "    'n': [100],\n",
    "    'd': [2],\n",
    "    'learning_rate': [0.1],\n",
    "    'reg_factor': [1e-3]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_nnrf, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed61df20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: 0.014285714285714285.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: -0.007593069137073255.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.02277981345301558.\n",
      "\n",
      "Starting parameters 3...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 3: 0.06161727518166047.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'d': 2,\n",
       " 'learning_rate': 0.1,\n",
       " 'n': 100,\n",
       " 'oversample': 'adasyn',\n",
       " 'reg_factor': 0.001}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune\n",
    "param_grid = {\n",
    "    'oversample': ['adasyn'],\n",
    "    'n': [100],\n",
    "    'd': [2],\n",
    "    'learning_rate': [1e-3, 0.01, 0.03, 0.1],\n",
    "    'reg_factor': [1e-3]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_nnrf, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc11d16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters 0...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 0: -0.0022293239460631858.\n",
      "\n",
      "Starting parameters 1...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 1: 0.066754121340761.\n",
      "\n",
      "Starting parameters 2...\n",
      "Starting fold 1...\n",
      "Fold 1 completed.\n",
      "\n",
      "Starting fold 2...\n",
      "Fold 2 completed.\n",
      "\n",
      "Starting fold 3...\n",
      "Fold 3 completed.\n",
      "\n",
      "Starting fold 4...\n",
      "Fold 4 completed.\n",
      "\n",
      "Starting fold 5...\n",
      "Fold 5 completed.\n",
      "\n",
      "Starting fold 6...\n",
      "Fold 6 completed.\n",
      "\n",
      "Starting fold 7...\n",
      "Fold 7 completed.\n",
      "\n",
      "Starting fold 8...\n",
      "Fold 8 completed.\n",
      "\n",
      "Starting fold 9...\n",
      "Fold 9 completed.\n",
      "\n",
      "Starting fold 10...\n",
      "Fold 10 completed.\n",
      "\n",
      "Completed parameters 2: 0.012557993176660131.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'d': 2,\n",
       " 'learning_rate': 0.1,\n",
       " 'n': 100,\n",
       " 'oversample': 'adasyn',\n",
       " 'r': 5,\n",
       " 'reg_factor': 0.001}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune\n",
    "param_grid = {\n",
    "    'oversample': ['adasyn'],\n",
    "    'n': [100],\n",
    "    'd': [2],\n",
    "    'r': [2, 5, 10],\n",
    "    'learning_rate': [0.1],\n",
    "    'reg_factor': [1e-3]\n",
    "}\n",
    "\n",
    "best_params = tune_model(train_df, TASK_TO_RUN, NUM_FOLDS, train_nnrf, param_grid)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27f0f452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7227722772277227, 0.82, 0.2641509433962264, 0.08055776316740122)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'d': 2, 'n': 500, 'r': 5,  'oversample': 'adasyn', 'learning_rate': 0.01, 'reg_factor': 1e-3}\n",
    "\n",
    "predicted = train_nnrf(train_df, test_df, TASK_TO_RUN, **params)\n",
    "accuracy, sensitivity, specificity, kappa = get_metrics(predicted, convert_labels(test_df[TASK_TO_RUN]))\n",
    "accuracy, sensitivity, specificity, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a4690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
