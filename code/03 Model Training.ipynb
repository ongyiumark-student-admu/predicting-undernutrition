{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3804970",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64f01296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff06279b",
   "metadata": {},
   "source": [
    "### Testing Tensorflow GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8056044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453bca0c",
   "metadata": {},
   "source": [
    "# 2. Project Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63a200f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../train-test-data'\n",
    "NUM_FOLDS = 10\n",
    "TASKS_TO_RUN = ['2aii', '2aiii']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a9a438",
   "metadata": {},
   "source": [
    "# 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cb252b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, label, shuffle=True, batch_size=8):\n",
    "    dataframe = dataframe.copy()\n",
    "    dataframe['target'] = np.where(dataframe[label]=='INCREASED RISK', 1, 0)\n",
    "    dataframe = dataframe.drop(columns=label)\n",
    "    \n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop('target')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "        ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "325e1915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utitlity method to create an X and y np.array from a Pandas Dataframe\n",
    "def df_to_nparray(dataframe, label):\n",
    "    X = dataframe.drop(label, axis=1).to_numpy()\n",
    "    y = dataframe[label].to_numpy()\n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26d867fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to train with k-fold\n",
    "def train_kfold(num_fold, task, included_cols, train_func):\n",
    "    # Read train csv\n",
    "    train_df = pd.read_csv(os.path.join(DATA_DIR, f'{task}_train.csv'), index_col=0)\n",
    "\n",
    "    # Metric arrays\n",
    "    acc_per_fold = []\n",
    "    loss_per_fold = []\n",
    "    sens_per_fold = []\n",
    "    spec_per_fold = []\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=num_fold, shuffle=True, random_state=42)\n",
    "    fold_no = 1\n",
    "    for train_idx, val_idx in kfold.split(train_df.drop(task, axis=1), train_df[[task]]):\n",
    "        train = train_df.iloc[train_idx] \n",
    "        test = train_df.iloc[val_idx]\n",
    "\n",
    "        loss, accuracy, sensitivity, specificity = train_func(train,test, task)\n",
    "        \n",
    "        loss_per_fold.append(loss)\n",
    "        acc_per_fold.append(accuracy)\n",
    "        sens_per_fold.append(sensitivity)\n",
    "        spec_per_fold.append(specificity)\n",
    "        \n",
    "        fold_no += 1\n",
    "    \n",
    "    metrics = {\n",
    "        'ACCURACY': {\n",
    "            'ALL': acc_per_fold,\n",
    "            'MEAN': np.mean(acc_per_fold),\n",
    "            'STDEV': np.std(acc_per_fold)\n",
    "        },\n",
    "        'SENSITIVITY': {\n",
    "            'ALL': sens_per_fold,\n",
    "            'MEAN': np.mean(sens_per_fold),\n",
    "            'STDEV': np.std(sens_per_fold)\n",
    "        },\n",
    "        'SPECIFICITY': {\n",
    "            'ALL': spec_per_fold,\n",
    "            'MEAN': np.mean(spec_per_fold),\n",
    "            'STDEV': np.std(spec_per_fold)\n",
    "        }\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb5c5d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train neural network\n",
    "def train_nn(train, test, task):\n",
    "    # Generate feauture columns\n",
    "    feature_columns = []\n",
    "    for col in included_cols:\n",
    "        feature_columns.append(tf.feature_column.numeric_column(col))\n",
    "\n",
    "    # Generating a tensorflow dataset\n",
    "    train_ds = df_to_dataset(train, task)\n",
    "    test_ds = df_to_dataset(test, task)\n",
    "\n",
    "    # Building model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.DenseFeatures(feature_columns),\n",
    "        tf.keras.layers.Dense(14, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy',\n",
    "                           tf.keras.metrics.TruePositives(),\n",
    "                           tf.keras.metrics.TrueNegatives(),\n",
    "                           tf.keras.metrics.FalsePositives(),\n",
    "                           tf.keras.metrics.FalseNegatives()\n",
    "                          ])\n",
    "\n",
    "    # Fitting Model\n",
    "    history = model.fit(train_ds, epochs=10, verbose=1)\n",
    "\n",
    "    # Evaluate Model\n",
    "    scores = model.evaluate(test_ds, verbose=0)\n",
    "    loss, accuracy, tp, tn, fp, fn = scores\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    \n",
    "    return loss, accuracy, sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b9af82a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tabnet(train, test, task):\n",
    "    X_train, y_train = df_to_nparray(train, task)\n",
    "    X_test, y_test = df_to_nparray(test, task)\n",
    "\n",
    "    model = TabNetClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    tp, fp, tn, fn = [0,0,0,0]\n",
    "    for p,a in zip(preds, y_test):\n",
    "        if (p == 'INCREASED RISK' and a == 'INCREASED RISK'): tp += 1\n",
    "        elif (p == 'INCREASED RISK' and a == 'REDUCED RISK'): fp += 1\n",
    "        elif (p == 'REDUCED RISK' and a == 'INCREASED RISK'): fn += 1\n",
    "        else: tn += 1\n",
    "\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "\n",
    "    return -1, accuracy, sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc594e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6732673267326733"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5971e754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.2214  |  0:00:00s\n",
      "epoch 1  | loss: 0.91538 |  0:00:00s\n",
      "epoch 2  | loss: 0.71774 |  0:00:00s\n",
      "epoch 3  | loss: 0.60308 |  0:00:00s\n",
      "epoch 4  | loss: 0.53341 |  0:00:00s\n",
      "epoch 5  | loss: 0.47526 |  0:00:00s\n",
      "epoch 6  | loss: 0.4647  |  0:00:00s\n",
      "epoch 7  | loss: 0.45177 |  0:00:00s\n",
      "epoch 8  | loss: 0.44853 |  0:00:00s\n",
      "epoch 9  | loss: 0.45086 |  0:00:00s\n",
      "epoch 10 | loss: 0.4426  |  0:00:00s\n",
      "epoch 11 | loss: 0.44003 |  0:00:00s\n",
      "epoch 12 | loss: 0.44779 |  0:00:00s\n",
      "epoch 13 | loss: 0.44877 |  0:00:00s\n",
      "epoch 14 | loss: 0.45707 |  0:00:00s\n",
      "epoch 15 | loss: 0.43454 |  0:00:00s\n",
      "epoch 16 | loss: 0.42927 |  0:00:00s\n",
      "epoch 17 | loss: 0.41648 |  0:00:00s\n",
      "epoch 18 | loss: 0.43763 |  0:00:00s\n",
      "epoch 19 | loss: 0.41593 |  0:00:00s\n",
      "epoch 20 | loss: 0.41877 |  0:00:00s\n",
      "epoch 21 | loss: 0.39907 |  0:00:00s\n",
      "epoch 22 | loss: 0.39011 |  0:00:00s\n",
      "epoch 23 | loss: 0.3869  |  0:00:00s\n",
      "epoch 24 | loss: 0.36941 |  0:00:00s\n",
      "epoch 25 | loss: 0.37808 |  0:00:00s\n",
      "epoch 26 | loss: 0.41377 |  0:00:00s\n",
      "epoch 27 | loss: 0.38326 |  0:00:00s\n",
      "epoch 28 | loss: 0.38845 |  0:00:00s\n",
      "epoch 29 | loss: 0.37418 |  0:00:00s\n",
      "epoch 30 | loss: 0.37951 |  0:00:00s\n",
      "epoch 31 | loss: 0.35143 |  0:00:00s\n",
      "epoch 32 | loss: 0.336   |  0:00:00s\n",
      "epoch 33 | loss: 0.34414 |  0:00:00s\n",
      "epoch 34 | loss: 0.33269 |  0:00:00s\n",
      "epoch 35 | loss: 0.32576 |  0:00:00s\n",
      "epoch 36 | loss: 0.32517 |  0:00:00s\n",
      "epoch 37 | loss: 0.30793 |  0:00:00s\n",
      "epoch 38 | loss: 0.31372 |  0:00:00s\n",
      "epoch 39 | loss: 0.3095  |  0:00:01s\n",
      "epoch 40 | loss: 0.28204 |  0:00:01s\n",
      "epoch 41 | loss: 0.32736 |  0:00:01s\n",
      "epoch 42 | loss: 0.31172 |  0:00:01s\n",
      "epoch 43 | loss: 0.28461 |  0:00:01s\n",
      "epoch 44 | loss: 0.31025 |  0:00:01s\n",
      "epoch 45 | loss: 0.27113 |  0:00:01s\n",
      "epoch 46 | loss: 0.28973 |  0:00:01s\n",
      "epoch 47 | loss: 0.27163 |  0:00:01s\n",
      "epoch 48 | loss: 0.29661 |  0:00:01s\n",
      "epoch 49 | loss: 0.27154 |  0:00:01s\n",
      "epoch 50 | loss: 0.27105 |  0:00:01s\n",
      "epoch 51 | loss: 0.24864 |  0:00:01s\n",
      "epoch 52 | loss: 0.27651 |  0:00:01s\n",
      "epoch 53 | loss: 0.26665 |  0:00:01s\n",
      "epoch 54 | loss: 0.25082 |  0:00:01s\n",
      "epoch 55 | loss: 0.2771  |  0:00:01s\n",
      "epoch 56 | loss: 0.31408 |  0:00:01s\n",
      "epoch 57 | loss: 0.24346 |  0:00:01s\n",
      "epoch 58 | loss: 0.25392 |  0:00:01s\n",
      "epoch 59 | loss: 0.20324 |  0:00:01s\n",
      "epoch 60 | loss: 0.26184 |  0:00:01s\n",
      "epoch 61 | loss: 0.22013 |  0:00:01s\n",
      "epoch 62 | loss: 0.23366 |  0:00:01s\n",
      "epoch 63 | loss: 0.24465 |  0:00:01s\n",
      "epoch 64 | loss: 0.20639 |  0:00:01s\n",
      "epoch 65 | loss: 0.22999 |  0:00:01s\n",
      "epoch 66 | loss: 0.23922 |  0:00:01s\n",
      "epoch 67 | loss: 0.21738 |  0:00:01s\n",
      "epoch 68 | loss: 0.22109 |  0:00:01s\n",
      "epoch 69 | loss: 0.2037  |  0:00:01s\n",
      "epoch 70 | loss: 0.23143 |  0:00:01s\n",
      "epoch 71 | loss: 0.1796  |  0:00:01s\n",
      "epoch 72 | loss: 0.1979  |  0:00:01s\n",
      "epoch 73 | loss: 0.20642 |  0:00:01s\n",
      "epoch 74 | loss: 0.18249 |  0:00:01s\n",
      "epoch 75 | loss: 0.20083 |  0:00:01s\n",
      "epoch 76 | loss: 0.21091 |  0:00:01s\n",
      "epoch 77 | loss: 0.21514 |  0:00:01s\n",
      "epoch 78 | loss: 0.20927 |  0:00:02s\n",
      "epoch 79 | loss: 0.20924 |  0:00:02s\n",
      "epoch 80 | loss: 0.21588 |  0:00:02s\n",
      "epoch 81 | loss: 0.21119 |  0:00:02s\n",
      "epoch 82 | loss: 0.1641  |  0:00:02s\n",
      "epoch 83 | loss: 0.21862 |  0:00:02s\n",
      "epoch 84 | loss: 0.20364 |  0:00:02s\n",
      "epoch 85 | loss: 0.17874 |  0:00:02s\n",
      "epoch 86 | loss: 0.16181 |  0:00:02s\n",
      "epoch 87 | loss: 0.19619 |  0:00:02s\n",
      "epoch 88 | loss: 0.14642 |  0:00:02s\n",
      "epoch 89 | loss: 0.19319 |  0:00:02s\n",
      "epoch 90 | loss: 0.14233 |  0:00:02s\n",
      "epoch 91 | loss: 0.13782 |  0:00:02s\n",
      "epoch 92 | loss: 0.15507 |  0:00:02s\n",
      "epoch 93 | loss: 0.17678 |  0:00:02s\n",
      "epoch 94 | loss: 0.12989 |  0:00:02s\n",
      "epoch 95 | loss: 0.15856 |  0:00:02s\n",
      "epoch 96 | loss: 0.15827 |  0:00:02s\n",
      "epoch 97 | loss: 0.1458  |  0:00:02s\n",
      "epoch 98 | loss: 0.14719 |  0:00:02s\n",
      "epoch 99 | loss: 0.11415 |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.18691 |  0:00:00s\n",
      "epoch 1  | loss: 0.9051  |  0:00:00s\n",
      "epoch 2  | loss: 0.70404 |  0:00:00s\n",
      "epoch 3  | loss: 0.59752 |  0:00:00s\n",
      "epoch 4  | loss: 0.54059 |  0:00:00s\n",
      "epoch 5  | loss: 0.48578 |  0:00:00s\n",
      "epoch 6  | loss: 0.47439 |  0:00:00s\n",
      "epoch 7  | loss: 0.43789 |  0:00:00s\n",
      "epoch 8  | loss: 0.44012 |  0:00:00s\n",
      "epoch 9  | loss: 0.4263  |  0:00:00s\n",
      "epoch 10 | loss: 0.40854 |  0:00:00s\n",
      "epoch 11 | loss: 0.40643 |  0:00:00s\n",
      "epoch 12 | loss: 0.40747 |  0:00:00s\n",
      "epoch 13 | loss: 0.40929 |  0:00:00s\n",
      "epoch 14 | loss: 0.39351 |  0:00:00s\n",
      "epoch 15 | loss: 0.38903 |  0:00:00s\n",
      "epoch 16 | loss: 0.36528 |  0:00:00s\n",
      "epoch 17 | loss: 0.35653 |  0:00:00s\n",
      "epoch 18 | loss: 0.3585  |  0:00:00s\n",
      "epoch 19 | loss: 0.37283 |  0:00:00s\n",
      "epoch 20 | loss: 0.36225 |  0:00:00s\n",
      "epoch 21 | loss: 0.36166 |  0:00:00s\n",
      "epoch 22 | loss: 0.34032 |  0:00:00s\n",
      "epoch 23 | loss: 0.35312 |  0:00:00s\n",
      "epoch 24 | loss: 0.34489 |  0:00:00s\n",
      "epoch 25 | loss: 0.31407 |  0:00:00s\n",
      "epoch 26 | loss: 0.35634 |  0:00:00s\n",
      "epoch 27 | loss: 0.32023 |  0:00:00s\n",
      "epoch 28 | loss: 0.29531 |  0:00:00s\n",
      "epoch 29 | loss: 0.30767 |  0:00:00s\n",
      "epoch 30 | loss: 0.30335 |  0:00:00s\n",
      "epoch 31 | loss: 0.28125 |  0:00:00s\n",
      "epoch 32 | loss: 0.34238 |  0:00:00s\n",
      "epoch 33 | loss: 0.30214 |  0:00:00s\n",
      "epoch 34 | loss: 0.29406 |  0:00:00s\n",
      "epoch 35 | loss: 0.29849 |  0:00:00s\n",
      "epoch 36 | loss: 0.2967  |  0:00:00s\n",
      "epoch 37 | loss: 0.26598 |  0:00:01s\n",
      "epoch 38 | loss: 0.32252 |  0:00:01s\n",
      "epoch 39 | loss: 0.27598 |  0:00:01s\n",
      "epoch 40 | loss: 0.2538  |  0:00:01s\n",
      "epoch 41 | loss: 0.27569 |  0:00:01s\n",
      "epoch 42 | loss: 0.28839 |  0:00:01s\n",
      "epoch 43 | loss: 0.25773 |  0:00:01s\n",
      "epoch 44 | loss: 0.30131 |  0:00:01s\n",
      "epoch 45 | loss: 0.28719 |  0:00:01s\n",
      "epoch 46 | loss: 0.26221 |  0:00:01s\n",
      "epoch 47 | loss: 0.27108 |  0:00:01s\n",
      "epoch 48 | loss: 0.24043 |  0:00:01s\n",
      "epoch 49 | loss: 0.30021 |  0:00:01s\n",
      "epoch 50 | loss: 0.25667 |  0:00:01s\n",
      "epoch 51 | loss: 0.28744 |  0:00:01s\n",
      "epoch 52 | loss: 0.24744 |  0:00:01s\n",
      "epoch 53 | loss: 0.24331 |  0:00:01s\n",
      "epoch 54 | loss: 0.22114 |  0:00:01s\n",
      "epoch 55 | loss: 0.22232 |  0:00:01s\n",
      "epoch 56 | loss: 0.25091 |  0:00:01s\n",
      "epoch 57 | loss: 0.22162 |  0:00:01s\n",
      "epoch 58 | loss: 0.25479 |  0:00:01s\n",
      "epoch 59 | loss: 0.23052 |  0:00:01s\n",
      "epoch 60 | loss: 0.23646 |  0:00:01s\n",
      "epoch 61 | loss: 0.2206  |  0:00:01s\n",
      "epoch 62 | loss: 0.27346 |  0:00:01s\n",
      "epoch 63 | loss: 0.23197 |  0:00:01s\n",
      "epoch 64 | loss: 0.23109 |  0:00:01s\n",
      "epoch 65 | loss: 0.25845 |  0:00:01s\n",
      "epoch 66 | loss: 0.25307 |  0:00:01s\n",
      "epoch 67 | loss: 0.2446  |  0:00:01s\n",
      "epoch 68 | loss: 0.23217 |  0:00:01s\n",
      "epoch 69 | loss: 0.23397 |  0:00:01s\n",
      "epoch 70 | loss: 0.21618 |  0:00:01s\n",
      "epoch 71 | loss: 0.22155 |  0:00:01s\n",
      "epoch 72 | loss: 0.21047 |  0:00:01s\n",
      "epoch 73 | loss: 0.23294 |  0:00:01s\n",
      "epoch 74 | loss: 0.2151  |  0:00:01s\n",
      "epoch 75 | loss: 0.21023 |  0:00:01s\n",
      "epoch 76 | loss: 0.27438 |  0:00:01s\n",
      "epoch 77 | loss: 0.19191 |  0:00:02s\n",
      "epoch 78 | loss: 0.20063 |  0:00:02s\n",
      "epoch 79 | loss: 0.19931 |  0:00:02s\n",
      "epoch 80 | loss: 0.26701 |  0:00:02s\n",
      "epoch 81 | loss: 0.25571 |  0:00:02s\n",
      "epoch 82 | loss: 0.18318 |  0:00:02s\n",
      "epoch 83 | loss: 0.17817 |  0:00:02s\n",
      "epoch 84 | loss: 0.18244 |  0:00:02s\n",
      "epoch 85 | loss: 0.1832  |  0:00:02s\n",
      "epoch 86 | loss: 0.19692 |  0:00:02s\n",
      "epoch 87 | loss: 0.19394 |  0:00:02s\n",
      "epoch 88 | loss: 0.17433 |  0:00:02s\n",
      "epoch 89 | loss: 0.18234 |  0:00:02s\n",
      "epoch 90 | loss: 0.18508 |  0:00:02s\n",
      "epoch 91 | loss: 0.18505 |  0:00:02s\n",
      "epoch 92 | loss: 0.16062 |  0:00:02s\n",
      "epoch 93 | loss: 0.16902 |  0:00:02s\n",
      "epoch 94 | loss: 0.19017 |  0:00:02s\n",
      "epoch 95 | loss: 0.17833 |  0:00:02s\n",
      "epoch 96 | loss: 0.17042 |  0:00:02s\n",
      "epoch 97 | loss: 0.16892 |  0:00:02s\n",
      "epoch 98 | loss: 0.1948  |  0:00:02s\n",
      "epoch 99 | loss: 0.1624  |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.19673 |  0:00:00s\n",
      "epoch 1  | loss: 0.87582 |  0:00:00s\n",
      "epoch 2  | loss: 0.71551 |  0:00:00s\n",
      "epoch 3  | loss: 0.60663 |  0:00:00s\n",
      "epoch 4  | loss: 0.52189 |  0:00:00s\n",
      "epoch 5  | loss: 0.50426 |  0:00:00s\n",
      "epoch 6  | loss: 0.45281 |  0:00:00s\n",
      "epoch 7  | loss: 0.44543 |  0:00:00s\n",
      "epoch 8  | loss: 0.45553 |  0:00:00s\n",
      "epoch 9  | loss: 0.42198 |  0:00:00s\n",
      "epoch 10 | loss: 0.43039 |  0:00:00s\n",
      "epoch 11 | loss: 0.42587 |  0:00:00s\n",
      "epoch 12 | loss: 0.43054 |  0:00:00s\n",
      "epoch 13 | loss: 0.41075 |  0:00:00s\n",
      "epoch 14 | loss: 0.39414 |  0:00:00s\n",
      "epoch 15 | loss: 0.39615 |  0:00:00s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 | loss: 0.37639 |  0:00:00s\n",
      "epoch 17 | loss: 0.38371 |  0:00:00s\n",
      "epoch 18 | loss: 0.36964 |  0:00:00s\n",
      "epoch 19 | loss: 0.36377 |  0:00:00s\n",
      "epoch 20 | loss: 0.35283 |  0:00:00s\n",
      "epoch 21 | loss: 0.36079 |  0:00:00s\n",
      "epoch 22 | loss: 0.34357 |  0:00:00s\n",
      "epoch 23 | loss: 0.36675 |  0:00:00s\n",
      "epoch 24 | loss: 0.3477  |  0:00:00s\n",
      "epoch 25 | loss: 0.33946 |  0:00:00s\n",
      "epoch 26 | loss: 0.35364 |  0:00:00s\n",
      "epoch 27 | loss: 0.34608 |  0:00:00s\n",
      "epoch 28 | loss: 0.32242 |  0:00:00s\n",
      "epoch 29 | loss: 0.33781 |  0:00:00s\n",
      "epoch 30 | loss: 0.31921 |  0:00:00s\n",
      "epoch 31 | loss: 0.3355  |  0:00:00s\n",
      "epoch 32 | loss: 0.3181  |  0:00:00s\n",
      "epoch 33 | loss: 0.3314  |  0:00:00s\n",
      "epoch 34 | loss: 0.32436 |  0:00:00s\n",
      "epoch 35 | loss: 0.29872 |  0:00:01s\n",
      "epoch 36 | loss: 0.33706 |  0:00:01s\n",
      "epoch 37 | loss: 0.30088 |  0:00:01s\n",
      "epoch 38 | loss: 0.31118 |  0:00:01s\n",
      "epoch 39 | loss: 0.31549 |  0:00:01s\n",
      "epoch 40 | loss: 0.31002 |  0:00:01s\n",
      "epoch 41 | loss: 0.29946 |  0:00:01s\n",
      "epoch 42 | loss: 0.30898 |  0:00:01s\n",
      "epoch 43 | loss: 0.30585 |  0:00:01s\n",
      "epoch 44 | loss: 0.28948 |  0:00:01s\n",
      "epoch 45 | loss: 0.27805 |  0:00:01s\n",
      "epoch 46 | loss: 0.31293 |  0:00:01s\n",
      "epoch 47 | loss: 0.26746 |  0:00:01s\n",
      "epoch 48 | loss: 0.267   |  0:00:01s\n",
      "epoch 49 | loss: 0.28701 |  0:00:01s\n",
      "epoch 50 | loss: 0.27204 |  0:00:01s\n",
      "epoch 51 | loss: 0.2607  |  0:00:01s\n",
      "epoch 52 | loss: 0.28544 |  0:00:01s\n",
      "epoch 53 | loss: 0.29581 |  0:00:01s\n",
      "epoch 54 | loss: 0.29774 |  0:00:01s\n",
      "epoch 55 | loss: 0.26637 |  0:00:01s\n",
      "epoch 56 | loss: 0.25601 |  0:00:01s\n",
      "epoch 57 | loss: 0.25118 |  0:00:01s\n",
      "epoch 58 | loss: 0.25739 |  0:00:01s\n",
      "epoch 59 | loss: 0.28255 |  0:00:01s\n",
      "epoch 60 | loss: 0.28538 |  0:00:01s\n",
      "epoch 61 | loss: 0.25015 |  0:00:01s\n",
      "epoch 62 | loss: 0.2896  |  0:00:01s\n",
      "epoch 63 | loss: 0.25776 |  0:00:01s\n",
      "epoch 64 | loss: 0.2345  |  0:00:01s\n",
      "epoch 65 | loss: 0.25421 |  0:00:01s\n",
      "epoch 66 | loss: 0.24379 |  0:00:01s\n",
      "epoch 67 | loss: 0.23876 |  0:00:01s\n",
      "epoch 68 | loss: 0.22611 |  0:00:01s\n",
      "epoch 69 | loss: 0.25375 |  0:00:01s\n",
      "epoch 70 | loss: 0.22279 |  0:00:01s\n",
      "epoch 71 | loss: 0.24372 |  0:00:01s\n",
      "epoch 72 | loss: 0.21666 |  0:00:01s\n",
      "epoch 73 | loss: 0.23859 |  0:00:02s\n",
      "epoch 74 | loss: 0.23108 |  0:00:02s\n",
      "epoch 75 | loss: 0.20466 |  0:00:02s\n",
      "epoch 76 | loss: 0.18054 |  0:00:02s\n",
      "epoch 77 | loss: 0.2116  |  0:00:02s\n",
      "epoch 78 | loss: 0.19946 |  0:00:02s\n",
      "epoch 79 | loss: 0.20392 |  0:00:02s\n",
      "epoch 80 | loss: 0.22461 |  0:00:02s\n",
      "epoch 81 | loss: 0.24423 |  0:00:02s\n",
      "epoch 82 | loss: 0.21537 |  0:00:02s\n",
      "epoch 83 | loss: 0.2372  |  0:00:02s\n",
      "epoch 84 | loss: 0.23069 |  0:00:02s\n",
      "epoch 85 | loss: 0.22772 |  0:00:02s\n",
      "epoch 86 | loss: 0.24674 |  0:00:02s\n",
      "epoch 87 | loss: 0.22739 |  0:00:02s\n",
      "epoch 88 | loss: 0.21491 |  0:00:02s\n",
      "epoch 89 | loss: 0.23822 |  0:00:02s\n",
      "epoch 90 | loss: 0.21938 |  0:00:02s\n",
      "epoch 91 | loss: 0.21064 |  0:00:02s\n",
      "epoch 92 | loss: 0.19289 |  0:00:02s\n",
      "epoch 93 | loss: 0.224   |  0:00:02s\n",
      "epoch 94 | loss: 0.23231 |  0:00:02s\n",
      "epoch 95 | loss: 0.20734 |  0:00:02s\n",
      "epoch 96 | loss: 0.22951 |  0:00:02s\n",
      "epoch 97 | loss: 0.19122 |  0:00:02s\n",
      "epoch 98 | loss: 0.18979 |  0:00:02s\n",
      "epoch 99 | loss: 0.19594 |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.15136 |  0:00:00s\n",
      "epoch 1  | loss: 0.88484 |  0:00:00s\n",
      "epoch 2  | loss: 0.7198  |  0:00:00s\n",
      "epoch 3  | loss: 0.61478 |  0:00:00s\n",
      "epoch 4  | loss: 0.55315 |  0:00:00s\n",
      "epoch 5  | loss: 0.56244 |  0:00:00s\n",
      "epoch 6  | loss: 0.52035 |  0:00:00s\n",
      "epoch 7  | loss: 0.51329 |  0:00:00s\n",
      "epoch 8  | loss: 0.47199 |  0:00:00s\n",
      "epoch 9  | loss: 0.4683  |  0:00:00s\n",
      "epoch 10 | loss: 0.48121 |  0:00:00s\n",
      "epoch 11 | loss: 0.47108 |  0:00:00s\n",
      "epoch 12 | loss: 0.45466 |  0:00:00s\n",
      "epoch 13 | loss: 0.43702 |  0:00:00s\n",
      "epoch 14 | loss: 0.44125 |  0:00:00s\n",
      "epoch 15 | loss: 0.42018 |  0:00:00s\n",
      "epoch 16 | loss: 0.40919 |  0:00:00s\n",
      "epoch 17 | loss: 0.3967  |  0:00:00s\n",
      "epoch 18 | loss: 0.39455 |  0:00:00s\n",
      "epoch 19 | loss: 0.39023 |  0:00:00s\n",
      "epoch 20 | loss: 0.40498 |  0:00:00s\n",
      "epoch 21 | loss: 0.38726 |  0:00:00s\n",
      "epoch 22 | loss: 0.38653 |  0:00:00s\n",
      "epoch 23 | loss: 0.38316 |  0:00:00s\n",
      "epoch 24 | loss: 0.37998 |  0:00:00s\n",
      "epoch 25 | loss: 0.38921 |  0:00:00s\n",
      "epoch 26 | loss: 0.38589 |  0:00:00s\n",
      "epoch 27 | loss: 0.35472 |  0:00:00s\n",
      "epoch 28 | loss: 0.35437 |  0:00:00s\n",
      "epoch 29 | loss: 0.35733 |  0:00:00s\n",
      "epoch 30 | loss: 0.35989 |  0:00:00s\n",
      "epoch 31 | loss: 0.3502  |  0:00:00s\n",
      "epoch 32 | loss: 0.35696 |  0:00:00s\n",
      "epoch 33 | loss: 0.33106 |  0:00:00s\n",
      "epoch 34 | loss: 0.34823 |  0:00:00s\n",
      "epoch 35 | loss: 0.35062 |  0:00:00s\n",
      "epoch 36 | loss: 0.35681 |  0:00:00s\n",
      "epoch 37 | loss: 0.32786 |  0:00:00s\n",
      "epoch 38 | loss: 0.31692 |  0:00:01s\n",
      "epoch 39 | loss: 0.32419 |  0:00:01s\n",
      "epoch 40 | loss: 0.30981 |  0:00:01s\n",
      "epoch 41 | loss: 0.29433 |  0:00:01s\n",
      "epoch 42 | loss: 0.29878 |  0:00:01s\n",
      "epoch 43 | loss: 0.31878 |  0:00:01s\n",
      "epoch 44 | loss: 0.29423 |  0:00:01s\n",
      "epoch 45 | loss: 0.29361 |  0:00:01s\n",
      "epoch 46 | loss: 0.27755 |  0:00:01s\n",
      "epoch 47 | loss: 0.29705 |  0:00:01s\n",
      "epoch 48 | loss: 0.27132 |  0:00:01s\n",
      "epoch 49 | loss: 0.26593 |  0:00:01s\n",
      "epoch 50 | loss: 0.26742 |  0:00:01s\n",
      "epoch 51 | loss: 0.25233 |  0:00:01s\n",
      "epoch 52 | loss: 0.25281 |  0:00:01s\n",
      "epoch 53 | loss: 0.24946 |  0:00:01s\n",
      "epoch 54 | loss: 0.24947 |  0:00:01s\n",
      "epoch 55 | loss: 0.21984 |  0:00:01s\n",
      "epoch 56 | loss: 0.25116 |  0:00:01s\n",
      "epoch 57 | loss: 0.2357  |  0:00:01s\n",
      "epoch 58 | loss: 0.20552 |  0:00:01s\n",
      "epoch 59 | loss: 0.22727 |  0:00:01s\n",
      "epoch 60 | loss: 0.21    |  0:00:01s\n",
      "epoch 61 | loss: 0.2233  |  0:00:01s\n",
      "epoch 62 | loss: 0.22801 |  0:00:01s\n",
      "epoch 63 | loss: 0.20848 |  0:00:01s\n",
      "epoch 64 | loss: 0.20593 |  0:00:01s\n",
      "epoch 65 | loss: 0.19213 |  0:00:01s\n",
      "epoch 66 | loss: 0.22536 |  0:00:01s\n",
      "epoch 67 | loss: 0.19993 |  0:00:01s\n",
      "epoch 68 | loss: 0.2194  |  0:00:01s\n",
      "epoch 69 | loss: 0.19957 |  0:00:01s\n",
      "epoch 70 | loss: 0.19249 |  0:00:01s\n",
      "epoch 71 | loss: 0.19717 |  0:00:01s\n",
      "epoch 72 | loss: 0.20678 |  0:00:01s\n",
      "epoch 73 | loss: 0.19268 |  0:00:01s\n",
      "epoch 74 | loss: 0.20253 |  0:00:01s\n",
      "epoch 75 | loss: 0.25782 |  0:00:01s\n",
      "epoch 76 | loss: 0.22586 |  0:00:01s\n",
      "epoch 77 | loss: 0.17752 |  0:00:02s\n",
      "epoch 78 | loss: 0.2124  |  0:00:02s\n",
      "epoch 79 | loss: 0.20967 |  0:00:02s\n",
      "epoch 80 | loss: 0.18379 |  0:00:02s\n",
      "epoch 81 | loss: 0.21133 |  0:00:02s\n",
      "epoch 82 | loss: 0.18734 |  0:00:02s\n",
      "epoch 83 | loss: 0.18965 |  0:00:02s\n",
      "epoch 84 | loss: 0.18675 |  0:00:02s\n",
      "epoch 85 | loss: 0.19735 |  0:00:02s\n",
      "epoch 86 | loss: 0.21696 |  0:00:02s\n",
      "epoch 87 | loss: 0.18847 |  0:00:02s\n",
      "epoch 88 | loss: 0.18051 |  0:00:02s\n",
      "epoch 89 | loss: 0.19601 |  0:00:02s\n",
      "epoch 90 | loss: 0.18709 |  0:00:02s\n",
      "epoch 91 | loss: 0.2041  |  0:00:02s\n",
      "epoch 92 | loss: 0.19014 |  0:00:02s\n",
      "epoch 93 | loss: 0.18325 |  0:00:02s\n",
      "epoch 94 | loss: 0.18111 |  0:00:02s\n",
      "epoch 95 | loss: 0.1836  |  0:00:02s\n",
      "epoch 96 | loss: 0.22079 |  0:00:02s\n",
      "epoch 97 | loss: 0.20001 |  0:00:02s\n",
      "epoch 98 | loss: 0.18316 |  0:00:02s\n",
      "epoch 99 | loss: 0.17413 |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.24859 |  0:00:00s\n",
      "epoch 1  | loss: 0.85414 |  0:00:00s\n",
      "epoch 2  | loss: 0.71846 |  0:00:00s\n",
      "epoch 3  | loss: 0.55613 |  0:00:00s\n",
      "epoch 4  | loss: 0.57343 |  0:00:00s\n",
      "epoch 5  | loss: 0.52077 |  0:00:00s\n",
      "epoch 6  | loss: 0.51687 |  0:00:00s\n",
      "epoch 7  | loss: 0.50682 |  0:00:00s\n",
      "epoch 8  | loss: 0.50375 |  0:00:00s\n",
      "epoch 9  | loss: 0.43806 |  0:00:00s\n",
      "epoch 10 | loss: 0.46291 |  0:00:00s\n",
      "epoch 11 | loss: 0.4453  |  0:00:00s\n",
      "epoch 12 | loss: 0.43936 |  0:00:00s\n",
      "epoch 13 | loss: 0.4044  |  0:00:00s\n",
      "epoch 14 | loss: 0.42453 |  0:00:00s\n",
      "epoch 15 | loss: 0.43197 |  0:00:00s\n",
      "epoch 16 | loss: 0.41966 |  0:00:00s\n",
      "epoch 17 | loss: 0.43662 |  0:00:00s\n",
      "epoch 18 | loss: 0.40666 |  0:00:00s\n",
      "epoch 19 | loss: 0.41011 |  0:00:00s\n",
      "epoch 20 | loss: 0.38056 |  0:00:00s\n",
      "epoch 21 | loss: 0.37218 |  0:00:00s\n",
      "epoch 22 | loss: 0.38915 |  0:00:00s\n",
      "epoch 23 | loss: 0.36647 |  0:00:00s\n",
      "epoch 24 | loss: 0.3785  |  0:00:00s\n",
      "epoch 25 | loss: 0.36746 |  0:00:00s\n",
      "epoch 26 | loss: 0.36373 |  0:00:00s\n",
      "epoch 27 | loss: 0.34783 |  0:00:00s\n",
      "epoch 28 | loss: 0.34199 |  0:00:00s\n",
      "epoch 29 | loss: 0.35597 |  0:00:00s\n",
      "epoch 30 | loss: 0.32382 |  0:00:00s\n",
      "epoch 31 | loss: 0.35712 |  0:00:00s\n",
      "epoch 32 | loss: 0.33639 |  0:00:00s\n",
      "epoch 33 | loss: 0.33754 |  0:00:00s\n",
      "epoch 34 | loss: 0.34122 |  0:00:00s\n",
      "epoch 35 | loss: 0.31655 |  0:00:00s\n",
      "epoch 36 | loss: 0.31021 |  0:00:00s\n",
      "epoch 37 | loss: 0.31026 |  0:00:00s\n",
      "epoch 38 | loss: 0.28346 |  0:00:01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39 | loss: 0.30398 |  0:00:01s\n",
      "epoch 40 | loss: 0.29411 |  0:00:01s\n",
      "epoch 41 | loss: 0.27785 |  0:00:01s\n",
      "epoch 42 | loss: 0.29185 |  0:00:01s\n",
      "epoch 43 | loss: 0.28506 |  0:00:01s\n",
      "epoch 44 | loss: 0.26175 |  0:00:01s\n",
      "epoch 45 | loss: 0.27887 |  0:00:01s\n",
      "epoch 46 | loss: 0.28162 |  0:00:01s\n",
      "epoch 47 | loss: 0.26422 |  0:00:01s\n",
      "epoch 48 | loss: 0.24708 |  0:00:01s\n",
      "epoch 49 | loss: 0.27185 |  0:00:01s\n",
      "epoch 50 | loss: 0.25664 |  0:00:01s\n",
      "epoch 51 | loss: 0.23555 |  0:00:01s\n",
      "epoch 52 | loss: 0.25139 |  0:00:01s\n",
      "epoch 53 | loss: 0.24663 |  0:00:01s\n",
      "epoch 54 | loss: 0.26331 |  0:00:01s\n",
      "epoch 55 | loss: 0.2371  |  0:00:01s\n",
      "epoch 56 | loss: 0.24497 |  0:00:01s\n",
      "epoch 57 | loss: 0.23982 |  0:00:01s\n",
      "epoch 58 | loss: 0.24118 |  0:00:01s\n",
      "epoch 59 | loss: 0.22603 |  0:00:01s\n",
      "epoch 60 | loss: 0.23033 |  0:00:01s\n",
      "epoch 61 | loss: 0.21811 |  0:00:01s\n",
      "epoch 62 | loss: 0.22226 |  0:00:01s\n",
      "epoch 63 | loss: 0.22423 |  0:00:01s\n",
      "epoch 64 | loss: 0.19946 |  0:00:01s\n",
      "epoch 65 | loss: 0.2236  |  0:00:01s\n",
      "epoch 66 | loss: 0.20268 |  0:00:01s\n",
      "epoch 67 | loss: 0.20711 |  0:00:01s\n",
      "epoch 68 | loss: 0.2139  |  0:00:01s\n",
      "epoch 69 | loss: 0.19378 |  0:00:01s\n",
      "epoch 70 | loss: 0.19155 |  0:00:01s\n",
      "epoch 71 | loss: 0.18494 |  0:00:01s\n",
      "epoch 72 | loss: 0.18585 |  0:00:01s\n",
      "epoch 73 | loss: 0.20732 |  0:00:01s\n",
      "epoch 74 | loss: 0.17869 |  0:00:01s\n",
      "epoch 75 | loss: 0.22054 |  0:00:01s\n",
      "epoch 76 | loss: 0.17727 |  0:00:01s\n",
      "epoch 77 | loss: 0.19981 |  0:00:01s\n",
      "epoch 78 | loss: 0.17419 |  0:00:02s\n",
      "epoch 79 | loss: 0.16577 |  0:00:02s\n",
      "epoch 80 | loss: 0.1621  |  0:00:02s\n",
      "epoch 81 | loss: 0.17069 |  0:00:02s\n",
      "epoch 82 | loss: 0.20325 |  0:00:02s\n",
      "epoch 83 | loss: 0.19143 |  0:00:02s\n",
      "epoch 84 | loss: 0.1599  |  0:00:02s\n",
      "epoch 85 | loss: 0.19767 |  0:00:02s\n",
      "epoch 86 | loss: 0.16616 |  0:00:02s\n",
      "epoch 87 | loss: 0.16108 |  0:00:02s\n",
      "epoch 88 | loss: 0.18966 |  0:00:02s\n",
      "epoch 89 | loss: 0.15105 |  0:00:02s\n",
      "epoch 90 | loss: 0.17455 |  0:00:02s\n",
      "epoch 91 | loss: 0.19359 |  0:00:02s\n",
      "epoch 92 | loss: 0.15094 |  0:00:02s\n",
      "epoch 93 | loss: 0.17789 |  0:00:02s\n",
      "epoch 94 | loss: 0.17769 |  0:00:02s\n",
      "epoch 95 | loss: 0.13548 |  0:00:02s\n",
      "epoch 96 | loss: 0.1482  |  0:00:02s\n",
      "epoch 97 | loss: 0.12225 |  0:00:02s\n",
      "epoch 98 | loss: 0.1226  |  0:00:02s\n",
      "epoch 99 | loss: 0.1431  |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.24344 |  0:00:00s\n",
      "epoch 1  | loss: 0.89117 |  0:00:00s\n",
      "epoch 2  | loss: 0.72457 |  0:00:00s\n",
      "epoch 3  | loss: 0.58981 |  0:00:00s\n",
      "epoch 4  | loss: 0.53919 |  0:00:00s\n",
      "epoch 5  | loss: 0.4938  |  0:00:00s\n",
      "epoch 6  | loss: 0.45624 |  0:00:00s\n",
      "epoch 7  | loss: 0.43238 |  0:00:00s\n",
      "epoch 8  | loss: 0.43179 |  0:00:00s\n",
      "epoch 9  | loss: 0.4342  |  0:00:00s\n",
      "epoch 10 | loss: 0.41139 |  0:00:00s\n",
      "epoch 11 | loss: 0.42149 |  0:00:00s\n",
      "epoch 12 | loss: 0.40259 |  0:00:00s\n",
      "epoch 13 | loss: 0.36856 |  0:00:00s\n",
      "epoch 14 | loss: 0.35337 |  0:00:00s\n",
      "epoch 15 | loss: 0.38283 |  0:00:00s\n",
      "epoch 16 | loss: 0.37462 |  0:00:00s\n",
      "epoch 17 | loss: 0.34821 |  0:00:00s\n",
      "epoch 18 | loss: 0.37412 |  0:00:00s\n",
      "epoch 19 | loss: 0.39186 |  0:00:00s\n",
      "epoch 20 | loss: 0.35581 |  0:00:00s\n",
      "epoch 21 | loss: 0.33334 |  0:00:00s\n",
      "epoch 22 | loss: 0.32012 |  0:00:00s\n",
      "epoch 23 | loss: 0.31519 |  0:00:00s\n",
      "epoch 24 | loss: 0.33892 |  0:00:00s\n",
      "epoch 25 | loss: 0.33413 |  0:00:00s\n",
      "epoch 26 | loss: 0.3369  |  0:00:00s\n",
      "epoch 27 | loss: 0.32512 |  0:00:00s\n",
      "epoch 28 | loss: 0.28811 |  0:00:00s\n",
      "epoch 29 | loss: 0.31187 |  0:00:00s\n",
      "epoch 30 | loss: 0.33791 |  0:00:00s\n",
      "epoch 31 | loss: 0.29514 |  0:00:00s\n",
      "epoch 32 | loss: 0.295   |  0:00:00s\n",
      "epoch 33 | loss: 0.30913 |  0:00:00s\n",
      "epoch 34 | loss: 0.31698 |  0:00:00s\n",
      "epoch 35 | loss: 0.2846  |  0:00:00s\n",
      "epoch 36 | loss: 0.26946 |  0:00:00s\n",
      "epoch 37 | loss: 0.26456 |  0:00:00s\n",
      "epoch 38 | loss: 0.28394 |  0:00:00s\n",
      "epoch 39 | loss: 0.26133 |  0:00:01s\n",
      "epoch 40 | loss: 0.26153 |  0:00:01s\n",
      "epoch 41 | loss: 0.251   |  0:00:01s\n",
      "epoch 42 | loss: 0.26789 |  0:00:01s\n",
      "epoch 43 | loss: 0.31046 |  0:00:01s\n",
      "epoch 44 | loss: 0.27011 |  0:00:01s\n",
      "epoch 45 | loss: 0.25215 |  0:00:01s\n",
      "epoch 46 | loss: 0.26341 |  0:00:01s\n",
      "epoch 47 | loss: 0.256   |  0:00:01s\n",
      "epoch 48 | loss: 0.23033 |  0:00:01s\n",
      "epoch 49 | loss: 0.24162 |  0:00:01s\n",
      "epoch 50 | loss: 0.21856 |  0:00:01s\n",
      "epoch 51 | loss: 0.23136 |  0:00:01s\n",
      "epoch 52 | loss: 0.23189 |  0:00:01s\n",
      "epoch 53 | loss: 0.23439 |  0:00:01s\n",
      "epoch 54 | loss: 0.21834 |  0:00:01s\n",
      "epoch 55 | loss: 0.226   |  0:00:01s\n",
      "epoch 56 | loss: 0.2363  |  0:00:01s\n",
      "epoch 57 | loss: 0.21895 |  0:00:01s\n",
      "epoch 58 | loss: 0.20902 |  0:00:01s\n",
      "epoch 59 | loss: 0.23486 |  0:00:01s\n",
      "epoch 60 | loss: 0.22194 |  0:00:01s\n",
      "epoch 61 | loss: 0.2179  |  0:00:01s\n",
      "epoch 62 | loss: 0.2062  |  0:00:01s\n",
      "epoch 63 | loss: 0.18671 |  0:00:01s\n",
      "epoch 64 | loss: 0.2107  |  0:00:01s\n",
      "epoch 65 | loss: 0.20156 |  0:00:01s\n",
      "epoch 66 | loss: 0.19541 |  0:00:01s\n",
      "epoch 67 | loss: 0.1917  |  0:00:01s\n",
      "epoch 68 | loss: 0.20187 |  0:00:01s\n",
      "epoch 69 | loss: 0.19899 |  0:00:01s\n",
      "epoch 70 | loss: 0.17756 |  0:00:01s\n",
      "epoch 71 | loss: 0.23335 |  0:00:01s\n",
      "epoch 72 | loss: 0.19927 |  0:00:01s\n",
      "epoch 73 | loss: 0.22773 |  0:00:01s\n",
      "epoch 74 | loss: 0.21888 |  0:00:01s\n",
      "epoch 75 | loss: 0.19181 |  0:00:01s\n",
      "epoch 76 | loss: 0.21077 |  0:00:01s\n",
      "epoch 77 | loss: 0.23192 |  0:00:02s\n",
      "epoch 78 | loss: 0.20941 |  0:00:02s\n",
      "epoch 79 | loss: 0.23874 |  0:00:02s\n",
      "epoch 80 | loss: 0.22498 |  0:00:02s\n",
      "epoch 81 | loss: 0.20566 |  0:00:02s\n",
      "epoch 82 | loss: 0.16966 |  0:00:02s\n",
      "epoch 83 | loss: 0.18889 |  0:00:02s\n",
      "epoch 84 | loss: 0.20847 |  0:00:02s\n",
      "epoch 85 | loss: 0.19353 |  0:00:02s\n",
      "epoch 86 | loss: 0.17715 |  0:00:02s\n",
      "epoch 87 | loss: 0.17    |  0:00:02s\n",
      "epoch 88 | loss: 0.19975 |  0:00:02s\n",
      "epoch 89 | loss: 0.15081 |  0:00:02s\n",
      "epoch 90 | loss: 0.18327 |  0:00:02s\n",
      "epoch 91 | loss: 0.1896  |  0:00:02s\n",
      "epoch 92 | loss: 0.16037 |  0:00:02s\n",
      "epoch 93 | loss: 0.14514 |  0:00:02s\n",
      "epoch 94 | loss: 0.16063 |  0:00:02s\n",
      "epoch 95 | loss: 0.14911 |  0:00:02s\n",
      "epoch 96 | loss: 0.12674 |  0:00:02s\n",
      "epoch 97 | loss: 0.15771 |  0:00:02s\n",
      "epoch 98 | loss: 0.16265 |  0:00:02s\n",
      "epoch 99 | loss: 0.12334 |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.14761 |  0:00:00s\n",
      "epoch 1  | loss: 0.89322 |  0:00:00s\n",
      "epoch 2  | loss: 0.76127 |  0:00:00s\n",
      "epoch 3  | loss: 0.63992 |  0:00:00s\n",
      "epoch 4  | loss: 0.60478 |  0:00:00s\n",
      "epoch 5  | loss: 0.54972 |  0:00:00s\n",
      "epoch 6  | loss: 0.53215 |  0:00:00s\n",
      "epoch 7  | loss: 0.48588 |  0:00:00s\n",
      "epoch 8  | loss: 0.47143 |  0:00:00s\n",
      "epoch 9  | loss: 0.45794 |  0:00:00s\n",
      "epoch 10 | loss: 0.42884 |  0:00:00s\n",
      "epoch 11 | loss: 0.46209 |  0:00:00s\n",
      "epoch 12 | loss: 0.4341  |  0:00:00s\n",
      "epoch 13 | loss: 0.41317 |  0:00:00s\n",
      "epoch 14 | loss: 0.3851  |  0:00:00s\n",
      "epoch 15 | loss: 0.37976 |  0:00:00s\n",
      "epoch 16 | loss: 0.38429 |  0:00:00s\n",
      "epoch 17 | loss: 0.38237 |  0:00:00s\n",
      "epoch 18 | loss: 0.38176 |  0:00:00s\n",
      "epoch 19 | loss: 0.37744 |  0:00:00s\n",
      "epoch 20 | loss: 0.35938 |  0:00:00s\n",
      "epoch 21 | loss: 0.37323 |  0:00:00s\n",
      "epoch 22 | loss: 0.3486  |  0:00:00s\n",
      "epoch 23 | loss: 0.34674 |  0:00:00s\n",
      "epoch 24 | loss: 0.36971 |  0:00:00s\n",
      "epoch 25 | loss: 0.34484 |  0:00:00s\n",
      "epoch 26 | loss: 0.31768 |  0:00:00s\n",
      "epoch 27 | loss: 0.33588 |  0:00:00s\n",
      "epoch 28 | loss: 0.35203 |  0:00:00s\n",
      "epoch 29 | loss: 0.31411 |  0:00:00s\n",
      "epoch 30 | loss: 0.32379 |  0:00:00s\n",
      "epoch 31 | loss: 0.32292 |  0:00:00s\n",
      "epoch 32 | loss: 0.27048 |  0:00:00s\n",
      "epoch 33 | loss: 0.33164 |  0:00:00s\n",
      "epoch 34 | loss: 0.31087 |  0:00:00s\n",
      "epoch 35 | loss: 0.27052 |  0:00:00s\n",
      "epoch 36 | loss: 0.26425 |  0:00:00s\n",
      "epoch 37 | loss: 0.32611 |  0:00:01s\n",
      "epoch 38 | loss: 0.2869  |  0:00:01s\n",
      "epoch 39 | loss: 0.29297 |  0:00:01s\n",
      "epoch 40 | loss: 0.28537 |  0:00:01s\n",
      "epoch 41 | loss: 0.30622 |  0:00:01s\n",
      "epoch 42 | loss: 0.28676 |  0:00:01s\n",
      "epoch 43 | loss: 0.25304 |  0:00:01s\n",
      "epoch 44 | loss: 0.24348 |  0:00:01s\n",
      "epoch 45 | loss: 0.27655 |  0:00:01s\n",
      "epoch 46 | loss: 0.29495 |  0:00:01s\n",
      "epoch 47 | loss: 0.26678 |  0:00:01s\n",
      "epoch 48 | loss: 0.24627 |  0:00:01s\n",
      "epoch 49 | loss: 0.25357 |  0:00:01s\n",
      "epoch 50 | loss: 0.24044 |  0:00:01s\n",
      "epoch 51 | loss: 0.23512 |  0:00:01s\n",
      "epoch 52 | loss: 0.23805 |  0:00:01s\n",
      "epoch 53 | loss: 0.23751 |  0:00:01s\n",
      "epoch 54 | loss: 0.25515 |  0:00:01s\n",
      "epoch 55 | loss: 0.23719 |  0:00:01s\n",
      "epoch 56 | loss: 0.22913 |  0:00:01s\n",
      "epoch 57 | loss: 0.21862 |  0:00:01s\n",
      "epoch 58 | loss: 0.22593 |  0:00:01s\n",
      "epoch 59 | loss: 0.25568 |  0:00:01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60 | loss: 0.20602 |  0:00:01s\n",
      "epoch 61 | loss: 0.22271 |  0:00:01s\n",
      "epoch 62 | loss: 0.25368 |  0:00:01s\n",
      "epoch 63 | loss: 0.20384 |  0:00:01s\n",
      "epoch 64 | loss: 0.21381 |  0:00:01s\n",
      "epoch 65 | loss: 0.21299 |  0:00:01s\n",
      "epoch 66 | loss: 0.22798 |  0:00:01s\n",
      "epoch 67 | loss: 0.20967 |  0:00:01s\n",
      "epoch 68 | loss: 0.22655 |  0:00:01s\n",
      "epoch 69 | loss: 0.1834  |  0:00:01s\n",
      "epoch 70 | loss: 0.20265 |  0:00:01s\n",
      "epoch 71 | loss: 0.17985 |  0:00:01s\n",
      "epoch 72 | loss: 0.20444 |  0:00:01s\n",
      "epoch 73 | loss: 0.17386 |  0:00:01s\n",
      "epoch 74 | loss: 0.19254 |  0:00:01s\n",
      "epoch 75 | loss: 0.1973  |  0:00:01s\n",
      "epoch 76 | loss: 0.18944 |  0:00:02s\n",
      "epoch 77 | loss: 0.14782 |  0:00:02s\n",
      "epoch 78 | loss: 0.14767 |  0:00:02s\n",
      "epoch 79 | loss: 0.15531 |  0:00:02s\n",
      "epoch 80 | loss: 0.19942 |  0:00:02s\n",
      "epoch 81 | loss: 0.23667 |  0:00:02s\n",
      "epoch 82 | loss: 0.11894 |  0:00:02s\n",
      "epoch 83 | loss: 0.15078 |  0:00:02s\n",
      "epoch 84 | loss: 0.12805 |  0:00:02s\n",
      "epoch 85 | loss: 0.13914 |  0:00:02s\n",
      "epoch 86 | loss: 0.12305 |  0:00:02s\n",
      "epoch 87 | loss: 0.11491 |  0:00:02s\n",
      "epoch 88 | loss: 0.14853 |  0:00:02s\n",
      "epoch 89 | loss: 0.13772 |  0:00:02s\n",
      "epoch 90 | loss: 0.13074 |  0:00:02s\n",
      "epoch 91 | loss: 0.12203 |  0:00:02s\n",
      "epoch 92 | loss: 0.12323 |  0:00:02s\n",
      "epoch 93 | loss: 0.11039 |  0:00:02s\n",
      "epoch 94 | loss: 0.12421 |  0:00:02s\n",
      "epoch 95 | loss: 0.11251 |  0:00:02s\n",
      "epoch 96 | loss: 0.11497 |  0:00:02s\n",
      "epoch 97 | loss: 0.12518 |  0:00:02s\n",
      "epoch 98 | loss: 0.08481 |  0:00:02s\n",
      "epoch 99 | loss: 0.11212 |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.17831 |  0:00:00s\n",
      "epoch 1  | loss: 0.89022 |  0:00:00s\n",
      "epoch 2  | loss: 0.76357 |  0:00:00s\n",
      "epoch 3  | loss: 0.59495 |  0:00:00s\n",
      "epoch 4  | loss: 0.54052 |  0:00:00s\n",
      "epoch 5  | loss: 0.55263 |  0:00:00s\n",
      "epoch 6  | loss: 0.52296 |  0:00:00s\n",
      "epoch 7  | loss: 0.49609 |  0:00:00s\n",
      "epoch 8  | loss: 0.47016 |  0:00:00s\n",
      "epoch 9  | loss: 0.46229 |  0:00:00s\n",
      "epoch 10 | loss: 0.42871 |  0:00:00s\n",
      "epoch 11 | loss: 0.42054 |  0:00:00s\n",
      "epoch 12 | loss: 0.41063 |  0:00:00s\n",
      "epoch 13 | loss: 0.41134 |  0:00:00s\n",
      "epoch 14 | loss: 0.39837 |  0:00:00s\n",
      "epoch 15 | loss: 0.41051 |  0:00:00s\n",
      "epoch 16 | loss: 0.41475 |  0:00:00s\n",
      "epoch 17 | loss: 0.42097 |  0:00:00s\n",
      "epoch 18 | loss: 0.3774  |  0:00:00s\n",
      "epoch 19 | loss: 0.40105 |  0:00:00s\n",
      "epoch 20 | loss: 0.36436 |  0:00:00s\n",
      "epoch 21 | loss: 0.38253 |  0:00:00s\n",
      "epoch 22 | loss: 0.37948 |  0:00:00s\n",
      "epoch 23 | loss: 0.38695 |  0:00:00s\n",
      "epoch 24 | loss: 0.37407 |  0:00:00s\n",
      "epoch 25 | loss: 0.36442 |  0:00:00s\n",
      "epoch 26 | loss: 0.35163 |  0:00:00s\n",
      "epoch 27 | loss: 0.34521 |  0:00:00s\n",
      "epoch 28 | loss: 0.33149 |  0:00:00s\n",
      "epoch 29 | loss: 0.34797 |  0:00:00s\n",
      "epoch 30 | loss: 0.3029  |  0:00:00s\n",
      "epoch 31 | loss: 0.307   |  0:00:00s\n",
      "epoch 32 | loss: 0.3038  |  0:00:00s\n",
      "epoch 33 | loss: 0.29555 |  0:00:00s\n",
      "epoch 34 | loss: 0.31201 |  0:00:00s\n",
      "epoch 35 | loss: 0.28158 |  0:00:00s\n",
      "epoch 36 | loss: 0.28323 |  0:00:00s\n",
      "epoch 37 | loss: 0.29227 |  0:00:01s\n",
      "epoch 38 | loss: 0.25942 |  0:00:01s\n",
      "epoch 39 | loss: 0.26355 |  0:00:01s\n",
      "epoch 40 | loss: 0.24226 |  0:00:01s\n",
      "epoch 41 | loss: 0.24844 |  0:00:01s\n",
      "epoch 42 | loss: 0.24786 |  0:00:01s\n",
      "epoch 43 | loss: 0.22956 |  0:00:01s\n",
      "epoch 44 | loss: 0.21237 |  0:00:01s\n",
      "epoch 45 | loss: 0.30551 |  0:00:01s\n",
      "epoch 46 | loss: 0.21617 |  0:00:01s\n",
      "epoch 47 | loss: 0.23214 |  0:00:01s\n",
      "epoch 48 | loss: 0.24122 |  0:00:01s\n",
      "epoch 49 | loss: 0.22539 |  0:00:01s\n",
      "epoch 50 | loss: 0.24059 |  0:00:01s\n",
      "epoch 51 | loss: 0.22761 |  0:00:01s\n",
      "epoch 52 | loss: 0.25295 |  0:00:01s\n",
      "epoch 53 | loss: 0.18809 |  0:00:01s\n",
      "epoch 54 | loss: 0.21284 |  0:00:01s\n",
      "epoch 55 | loss: 0.19036 |  0:00:01s\n",
      "epoch 56 | loss: 0.18146 |  0:00:01s\n",
      "epoch 57 | loss: 0.19907 |  0:00:01s\n",
      "epoch 58 | loss: 0.19147 |  0:00:01s\n",
      "epoch 59 | loss: 0.21054 |  0:00:01s\n",
      "epoch 60 | loss: 0.17736 |  0:00:01s\n",
      "epoch 61 | loss: 0.22635 |  0:00:01s\n",
      "epoch 62 | loss: 0.16983 |  0:00:01s\n",
      "epoch 63 | loss: 0.16904 |  0:00:01s\n",
      "epoch 64 | loss: 0.17096 |  0:00:01s\n",
      "epoch 65 | loss: 0.17047 |  0:00:01s\n",
      "epoch 66 | loss: 0.15306 |  0:00:01s\n",
      "epoch 67 | loss: 0.20731 |  0:00:01s\n",
      "epoch 68 | loss: 0.17547 |  0:00:01s\n",
      "epoch 69 | loss: 0.1692  |  0:00:01s\n",
      "epoch 70 | loss: 0.15676 |  0:00:01s\n",
      "epoch 71 | loss: 0.14134 |  0:00:01s\n",
      "epoch 72 | loss: 0.16224 |  0:00:01s\n",
      "epoch 73 | loss: 0.19763 |  0:00:01s\n",
      "epoch 74 | loss: 0.17056 |  0:00:01s\n",
      "epoch 75 | loss: 0.15307 |  0:00:02s\n",
      "epoch 76 | loss: 0.13361 |  0:00:02s\n",
      "epoch 77 | loss: 0.1712  |  0:00:02s\n",
      "epoch 78 | loss: 0.12423 |  0:00:02s\n",
      "epoch 79 | loss: 0.14139 |  0:00:02s\n",
      "epoch 80 | loss: 0.16611 |  0:00:02s\n",
      "epoch 81 | loss: 0.17082 |  0:00:02s\n",
      "epoch 82 | loss: 0.12387 |  0:00:02s\n",
      "epoch 83 | loss: 0.15426 |  0:00:02s\n",
      "epoch 84 | loss: 0.1677  |  0:00:02s\n",
      "epoch 85 | loss: 0.13337 |  0:00:02s\n",
      "epoch 86 | loss: 0.12917 |  0:00:02s\n",
      "epoch 87 | loss: 0.1446  |  0:00:02s\n",
      "epoch 88 | loss: 0.12839 |  0:00:02s\n",
      "epoch 89 | loss: 0.12951 |  0:00:02s\n",
      "epoch 90 | loss: 0.11134 |  0:00:02s\n",
      "epoch 91 | loss: 0.12986 |  0:00:02s\n",
      "epoch 92 | loss: 0.11386 |  0:00:02s\n",
      "epoch 93 | loss: 0.12303 |  0:00:02s\n",
      "epoch 94 | loss: 0.1215  |  0:00:02s\n",
      "epoch 95 | loss: 0.12251 |  0:00:02s\n",
      "epoch 96 | loss: 0.17705 |  0:00:02s\n",
      "epoch 97 | loss: 0.16713 |  0:00:02s\n",
      "epoch 98 | loss: 0.08757 |  0:00:02s\n",
      "epoch 99 | loss: 0.11396 |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.17707 |  0:00:00s\n",
      "epoch 1  | loss: 0.90382 |  0:00:00s\n",
      "epoch 2  | loss: 0.70657 |  0:00:00s\n",
      "epoch 3  | loss: 0.60507 |  0:00:00s\n",
      "epoch 4  | loss: 0.54215 |  0:00:00s\n",
      "epoch 5  | loss: 0.51065 |  0:00:00s\n",
      "epoch 6  | loss: 0.50865 |  0:00:00s\n",
      "epoch 7  | loss: 0.48706 |  0:00:00s\n",
      "epoch 8  | loss: 0.48659 |  0:00:00s\n",
      "epoch 9  | loss: 0.45071 |  0:00:00s\n",
      "epoch 10 | loss: 0.43043 |  0:00:00s\n",
      "epoch 11 | loss: 0.46712 |  0:00:00s\n",
      "epoch 12 | loss: 0.42398 |  0:00:00s\n",
      "epoch 13 | loss: 0.42323 |  0:00:00s\n",
      "epoch 14 | loss: 0.41191 |  0:00:00s\n",
      "epoch 15 | loss: 0.40982 |  0:00:00s\n",
      "epoch 16 | loss: 0.41478 |  0:00:00s\n",
      "epoch 17 | loss: 0.40442 |  0:00:00s\n",
      "epoch 18 | loss: 0.39171 |  0:00:00s\n",
      "epoch 19 | loss: 0.40922 |  0:00:00s\n",
      "epoch 20 | loss: 0.37585 |  0:00:00s\n",
      "epoch 21 | loss: 0.36931 |  0:00:00s\n",
      "epoch 22 | loss: 0.37731 |  0:00:00s\n",
      "epoch 23 | loss: 0.38608 |  0:00:00s\n",
      "epoch 24 | loss: 0.37252 |  0:00:00s\n",
      "epoch 25 | loss: 0.36048 |  0:00:00s\n",
      "epoch 26 | loss: 0.35106 |  0:00:00s\n",
      "epoch 27 | loss: 0.33792 |  0:00:00s\n",
      "epoch 28 | loss: 0.33387 |  0:00:00s\n",
      "epoch 29 | loss: 0.36071 |  0:00:00s\n",
      "epoch 30 | loss: 0.3338  |  0:00:00s\n",
      "epoch 31 | loss: 0.34915 |  0:00:00s\n",
      "epoch 32 | loss: 0.34691 |  0:00:00s\n",
      "epoch 33 | loss: 0.33305 |  0:00:00s\n",
      "epoch 34 | loss: 0.32229 |  0:00:00s\n",
      "epoch 35 | loss: 0.33046 |  0:00:00s\n",
      "epoch 36 | loss: 0.32802 |  0:00:00s\n",
      "epoch 37 | loss: 0.32538 |  0:00:01s\n",
      "epoch 38 | loss: 0.31805 |  0:00:01s\n",
      "epoch 39 | loss: 0.32651 |  0:00:01s\n",
      "epoch 40 | loss: 0.28374 |  0:00:01s\n",
      "epoch 41 | loss: 0.28038 |  0:00:01s\n",
      "epoch 42 | loss: 0.30679 |  0:00:01s\n",
      "epoch 43 | loss: 0.30419 |  0:00:01s\n",
      "epoch 44 | loss: 0.26828 |  0:00:01s\n",
      "epoch 45 | loss: 0.26009 |  0:00:01s\n",
      "epoch 46 | loss: 0.26489 |  0:00:01s\n",
      "epoch 47 | loss: 0.31683 |  0:00:01s\n",
      "epoch 48 | loss: 0.27333 |  0:00:01s\n",
      "epoch 49 | loss: 0.24038 |  0:00:01s\n",
      "epoch 50 | loss: 0.26188 |  0:00:01s\n",
      "epoch 51 | loss: 0.24001 |  0:00:01s\n",
      "epoch 52 | loss: 0.27919 |  0:00:01s\n",
      "epoch 53 | loss: 0.24954 |  0:00:01s\n",
      "epoch 54 | loss: 0.23429 |  0:00:01s\n",
      "epoch 55 | loss: 0.31249 |  0:00:01s\n",
      "epoch 56 | loss: 0.24877 |  0:00:01s\n",
      "epoch 57 | loss: 0.23808 |  0:00:01s\n",
      "epoch 58 | loss: 0.24591 |  0:00:01s\n",
      "epoch 59 | loss: 0.2532  |  0:00:01s\n",
      "epoch 60 | loss: 0.26099 |  0:00:01s\n",
      "epoch 61 | loss: 0.27182 |  0:00:01s\n",
      "epoch 62 | loss: 0.27856 |  0:00:01s\n",
      "epoch 63 | loss: 0.27535 |  0:00:01s\n",
      "epoch 64 | loss: 0.25248 |  0:00:01s\n",
      "epoch 65 | loss: 0.24451 |  0:00:01s\n",
      "epoch 66 | loss: 0.26319 |  0:00:01s\n",
      "epoch 67 | loss: 0.26544 |  0:00:01s\n",
      "epoch 68 | loss: 0.27695 |  0:00:01s\n",
      "epoch 69 | loss: 0.23181 |  0:00:01s\n",
      "epoch 70 | loss: 0.22185 |  0:00:01s\n",
      "epoch 71 | loss: 0.2315  |  0:00:01s\n",
      "epoch 72 | loss: 0.21934 |  0:00:01s\n",
      "epoch 73 | loss: 0.25108 |  0:00:01s\n",
      "epoch 74 | loss: 0.22618 |  0:00:01s\n",
      "epoch 75 | loss: 0.23308 |  0:00:01s\n",
      "epoch 76 | loss: 0.23823 |  0:00:01s\n",
      "epoch 77 | loss: 0.2273  |  0:00:02s\n",
      "epoch 78 | loss: 0.22313 |  0:00:02s\n",
      "epoch 79 | loss: 0.20911 |  0:00:02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80 | loss: 0.18002 |  0:00:02s\n",
      "epoch 81 | loss: 0.22192 |  0:00:02s\n",
      "epoch 82 | loss: 0.21854 |  0:00:02s\n",
      "epoch 83 | loss: 0.19191 |  0:00:02s\n",
      "epoch 84 | loss: 0.19543 |  0:00:02s\n",
      "epoch 85 | loss: 0.21135 |  0:00:02s\n",
      "epoch 86 | loss: 0.20053 |  0:00:02s\n",
      "epoch 87 | loss: 0.22186 |  0:00:02s\n",
      "epoch 88 | loss: 0.2156  |  0:00:02s\n",
      "epoch 89 | loss: 0.1954  |  0:00:02s\n",
      "epoch 90 | loss: 0.17922 |  0:00:02s\n",
      "epoch 91 | loss: 0.1765  |  0:00:02s\n",
      "epoch 92 | loss: 0.22043 |  0:00:02s\n",
      "epoch 93 | loss: 0.19152 |  0:00:02s\n",
      "epoch 94 | loss: 0.16126 |  0:00:02s\n",
      "epoch 95 | loss: 0.16295 |  0:00:02s\n",
      "epoch 96 | loss: 0.162   |  0:00:02s\n",
      "epoch 97 | loss: 0.18415 |  0:00:02s\n",
      "epoch 98 | loss: 0.158   |  0:00:02s\n",
      "epoch 99 | loss: 0.19899 |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.14388 |  0:00:00s\n",
      "epoch 1  | loss: 0.89723 |  0:00:00s\n",
      "epoch 2  | loss: 0.69746 |  0:00:00s\n",
      "epoch 3  | loss: 0.6257  |  0:00:00s\n",
      "epoch 4  | loss: 0.54578 |  0:00:00s\n",
      "epoch 5  | loss: 0.50075 |  0:00:00s\n",
      "epoch 6  | loss: 0.48841 |  0:00:00s\n",
      "epoch 7  | loss: 0.4566  |  0:00:00s\n",
      "epoch 8  | loss: 0.45196 |  0:00:00s\n",
      "epoch 9  | loss: 0.44603 |  0:00:00s\n",
      "epoch 10 | loss: 0.43221 |  0:00:00s\n",
      "epoch 11 | loss: 0.42888 |  0:00:00s\n",
      "epoch 12 | loss: 0.41101 |  0:00:00s\n",
      "epoch 13 | loss: 0.46823 |  0:00:00s\n",
      "epoch 14 | loss: 0.38838 |  0:00:00s\n",
      "epoch 15 | loss: 0.41759 |  0:00:00s\n",
      "epoch 16 | loss: 0.42271 |  0:00:00s\n",
      "epoch 17 | loss: 0.41529 |  0:00:00s\n",
      "epoch 18 | loss: 0.40009 |  0:00:00s\n",
      "epoch 19 | loss: 0.3952  |  0:00:00s\n",
      "epoch 20 | loss: 0.39043 |  0:00:00s\n",
      "epoch 21 | loss: 0.40033 |  0:00:00s\n",
      "epoch 22 | loss: 0.3784  |  0:00:00s\n",
      "epoch 23 | loss: 0.39438 |  0:00:00s\n",
      "epoch 24 | loss: 0.38257 |  0:00:00s\n",
      "epoch 25 | loss: 0.35514 |  0:00:00s\n",
      "epoch 26 | loss: 0.35462 |  0:00:00s\n",
      "epoch 27 | loss: 0.35964 |  0:00:00s\n",
      "epoch 28 | loss: 0.3585  |  0:00:00s\n",
      "epoch 29 | loss: 0.35029 |  0:00:00s\n",
      "epoch 30 | loss: 0.34978 |  0:00:00s\n",
      "epoch 31 | loss: 0.38334 |  0:00:00s\n",
      "epoch 32 | loss: 0.34735 |  0:00:00s\n",
      "epoch 33 | loss: 0.32819 |  0:00:00s\n",
      "epoch 34 | loss: 0.33406 |  0:00:00s\n",
      "epoch 35 | loss: 0.37022 |  0:00:00s\n",
      "epoch 36 | loss: 0.32495 |  0:00:00s\n",
      "epoch 37 | loss: 0.35525 |  0:00:01s\n",
      "epoch 38 | loss: 0.32423 |  0:00:01s\n",
      "epoch 39 | loss: 0.3333  |  0:00:01s\n",
      "epoch 40 | loss: 0.31114 |  0:00:01s\n",
      "epoch 41 | loss: 0.32103 |  0:00:01s\n",
      "epoch 42 | loss: 0.30919 |  0:00:01s\n",
      "epoch 43 | loss: 0.30802 |  0:00:01s\n",
      "epoch 44 | loss: 0.33474 |  0:00:01s\n",
      "epoch 45 | loss: 0.31337 |  0:00:01s\n",
      "epoch 46 | loss: 0.33857 |  0:00:01s\n",
      "epoch 47 | loss: 0.31736 |  0:00:01s\n",
      "epoch 48 | loss: 0.3121  |  0:00:01s\n",
      "epoch 49 | loss: 0.30068 |  0:00:01s\n",
      "epoch 50 | loss: 0.30088 |  0:00:01s\n",
      "epoch 51 | loss: 0.30176 |  0:00:01s\n",
      "epoch 52 | loss: 0.28566 |  0:00:01s\n",
      "epoch 53 | loss: 0.28166 |  0:00:01s\n",
      "epoch 54 | loss: 0.28044 |  0:00:01s\n",
      "epoch 55 | loss: 0.28488 |  0:00:01s\n",
      "epoch 56 | loss: 0.2911  |  0:00:01s\n",
      "epoch 57 | loss: 0.31696 |  0:00:01s\n",
      "epoch 58 | loss: 0.30229 |  0:00:01s\n",
      "epoch 59 | loss: 0.30852 |  0:00:01s\n",
      "epoch 60 | loss: 0.28393 |  0:00:01s\n",
      "epoch 61 | loss: 0.32571 |  0:00:01s\n",
      "epoch 62 | loss: 0.29017 |  0:00:01s\n",
      "epoch 63 | loss: 0.31413 |  0:00:01s\n",
      "epoch 64 | loss: 0.32707 |  0:00:01s\n",
      "epoch 65 | loss: 0.29489 |  0:00:01s\n",
      "epoch 66 | loss: 0.27962 |  0:00:01s\n",
      "epoch 67 | loss: 0.288   |  0:00:01s\n",
      "epoch 68 | loss: 0.30005 |  0:00:01s\n",
      "epoch 69 | loss: 0.26915 |  0:00:01s\n",
      "epoch 70 | loss: 0.29053 |  0:00:01s\n",
      "epoch 71 | loss: 0.28065 |  0:00:01s\n",
      "epoch 72 | loss: 0.26508 |  0:00:01s\n",
      "epoch 73 | loss: 0.26636 |  0:00:01s\n",
      "epoch 74 | loss: 0.24647 |  0:00:01s\n",
      "epoch 75 | loss: 0.25206 |  0:00:01s\n",
      "epoch 76 | loss: 0.2631  |  0:00:02s\n",
      "epoch 77 | loss: 0.28959 |  0:00:02s\n",
      "epoch 78 | loss: 0.25933 |  0:00:02s\n",
      "epoch 79 | loss: 0.23962 |  0:00:02s\n",
      "epoch 80 | loss: 0.26336 |  0:00:02s\n",
      "epoch 81 | loss: 0.27483 |  0:00:02s\n",
      "epoch 82 | loss: 0.24054 |  0:00:02s\n",
      "epoch 83 | loss: 0.24584 |  0:00:02s\n",
      "epoch 84 | loss: 0.24271 |  0:00:02s\n",
      "epoch 85 | loss: 0.27928 |  0:00:02s\n",
      "epoch 86 | loss: 0.22439 |  0:00:02s\n",
      "epoch 87 | loss: 0.24698 |  0:00:02s\n",
      "epoch 88 | loss: 0.25    |  0:00:02s\n",
      "epoch 89 | loss: 0.24259 |  0:00:02s\n",
      "epoch 90 | loss: 0.26873 |  0:00:02s\n",
      "epoch 91 | loss: 0.27174 |  0:00:02s\n",
      "epoch 92 | loss: 0.23063 |  0:00:02s\n",
      "epoch 93 | loss: 0.22613 |  0:00:02s\n",
      "epoch 94 | loss: 0.24778 |  0:00:02s\n",
      "epoch 95 | loss: 0.28099 |  0:00:02s\n",
      "epoch 96 | loss: 0.25969 |  0:00:02s\n",
      "epoch 97 | loss: 0.24541 |  0:00:02s\n",
      "epoch 98 | loss: 0.24    |  0:00:02s\n",
      "epoch 99 | loss: 0.2292  |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.21223 |  0:00:00s\n",
      "epoch 1  | loss: 0.87819 |  0:00:00s\n",
      "epoch 2  | loss: 0.70984 |  0:00:00s\n",
      "epoch 3  | loss: 0.63242 |  0:00:00s\n",
      "epoch 4  | loss: 0.57082 |  0:00:00s\n",
      "epoch 5  | loss: 0.5723  |  0:00:00s\n",
      "epoch 6  | loss: 0.51698 |  0:00:00s\n",
      "epoch 7  | loss: 0.49174 |  0:00:00s\n",
      "epoch 8  | loss: 0.52504 |  0:00:00s\n",
      "epoch 9  | loss: 0.49583 |  0:00:00s\n",
      "epoch 10 | loss: 0.48261 |  0:00:00s\n",
      "epoch 11 | loss: 0.47199 |  0:00:00s\n",
      "epoch 12 | loss: 0.45805 |  0:00:00s\n",
      "epoch 13 | loss: 0.43621 |  0:00:00s\n",
      "epoch 14 | loss: 0.45828 |  0:00:00s\n",
      "epoch 15 | loss: 0.46122 |  0:00:00s\n",
      "epoch 16 | loss: 0.46421 |  0:00:00s\n",
      "epoch 17 | loss: 0.46103 |  0:00:00s\n",
      "epoch 18 | loss: 0.42791 |  0:00:00s\n",
      "epoch 19 | loss: 0.4442  |  0:00:00s\n",
      "epoch 20 | loss: 0.4371  |  0:00:00s\n",
      "epoch 21 | loss: 0.4434  |  0:00:00s\n",
      "epoch 22 | loss: 0.43782 |  0:00:00s\n",
      "epoch 23 | loss: 0.42046 |  0:00:00s\n",
      "epoch 24 | loss: 0.42313 |  0:00:00s\n",
      "epoch 25 | loss: 0.41187 |  0:00:00s\n",
      "epoch 26 | loss: 0.40361 |  0:00:00s\n",
      "epoch 27 | loss: 0.40549 |  0:00:00s\n",
      "epoch 28 | loss: 0.41495 |  0:00:00s\n",
      "epoch 29 | loss: 0.42918 |  0:00:00s\n",
      "epoch 30 | loss: 0.39408 |  0:00:00s\n",
      "epoch 31 | loss: 0.38405 |  0:00:00s\n",
      "epoch 32 | loss: 0.39785 |  0:00:00s\n",
      "epoch 33 | loss: 0.38963 |  0:00:00s\n",
      "epoch 34 | loss: 0.37971 |  0:00:00s\n",
      "epoch 35 | loss: 0.40018 |  0:00:00s\n",
      "epoch 36 | loss: 0.3848  |  0:00:00s\n",
      "epoch 37 | loss: 0.3735  |  0:00:00s\n",
      "epoch 38 | loss: 0.38657 |  0:00:01s\n",
      "epoch 39 | loss: 0.36437 |  0:00:01s\n",
      "epoch 40 | loss: 0.34957 |  0:00:01s\n",
      "epoch 41 | loss: 0.36583 |  0:00:01s\n",
      "epoch 42 | loss: 0.35743 |  0:00:01s\n",
      "epoch 43 | loss: 0.35991 |  0:00:01s\n",
      "epoch 44 | loss: 0.34265 |  0:00:01s\n",
      "epoch 45 | loss: 0.36637 |  0:00:01s\n",
      "epoch 46 | loss: 0.34918 |  0:00:01s\n",
      "epoch 47 | loss: 0.34867 |  0:00:01s\n",
      "epoch 48 | loss: 0.35374 |  0:00:01s\n",
      "epoch 49 | loss: 0.36779 |  0:00:01s\n",
      "epoch 50 | loss: 0.32087 |  0:00:01s\n",
      "epoch 51 | loss: 0.31894 |  0:00:01s\n",
      "epoch 52 | loss: 0.31359 |  0:00:01s\n",
      "epoch 53 | loss: 0.29764 |  0:00:01s\n",
      "epoch 54 | loss: 0.33959 |  0:00:01s\n",
      "epoch 55 | loss: 0.30287 |  0:00:01s\n",
      "epoch 56 | loss: 0.29573 |  0:00:01s\n",
      "epoch 57 | loss: 0.27475 |  0:00:01s\n",
      "epoch 58 | loss: 0.26935 |  0:00:01s\n",
      "epoch 59 | loss: 0.29964 |  0:00:01s\n",
      "epoch 60 | loss: 0.27582 |  0:00:01s\n",
      "epoch 61 | loss: 0.28169 |  0:00:01s\n",
      "epoch 62 | loss: 0.25304 |  0:00:01s\n",
      "epoch 63 | loss: 0.25285 |  0:00:01s\n",
      "epoch 64 | loss: 0.24227 |  0:00:01s\n",
      "epoch 65 | loss: 0.23789 |  0:00:01s\n",
      "epoch 66 | loss: 0.31485 |  0:00:01s\n",
      "epoch 67 | loss: 0.2339  |  0:00:01s\n",
      "epoch 68 | loss: 0.24728 |  0:00:01s\n",
      "epoch 69 | loss: 0.23099 |  0:00:01s\n",
      "epoch 70 | loss: 0.23711 |  0:00:01s\n",
      "epoch 71 | loss: 0.24435 |  0:00:01s\n",
      "epoch 72 | loss: 0.21632 |  0:00:01s\n",
      "epoch 73 | loss: 0.22612 |  0:00:01s\n",
      "epoch 74 | loss: 0.24474 |  0:00:01s\n",
      "epoch 75 | loss: 0.22412 |  0:00:01s\n",
      "epoch 76 | loss: 0.20393 |  0:00:02s\n",
      "epoch 77 | loss: 0.26486 |  0:00:02s\n",
      "epoch 78 | loss: 0.24851 |  0:00:02s\n",
      "epoch 79 | loss: 0.22705 |  0:00:02s\n",
      "epoch 80 | loss: 0.23325 |  0:00:02s\n",
      "epoch 81 | loss: 0.25519 |  0:00:02s\n",
      "epoch 82 | loss: 0.2802  |  0:00:02s\n",
      "epoch 83 | loss: 0.36811 |  0:00:02s\n",
      "epoch 84 | loss: 0.27459 |  0:00:02s\n",
      "epoch 85 | loss: 0.2828  |  0:00:02s\n",
      "epoch 86 | loss: 0.26676 |  0:00:02s\n",
      "epoch 87 | loss: 0.28093 |  0:00:02s\n",
      "epoch 88 | loss: 0.24391 |  0:00:02s\n",
      "epoch 89 | loss: 0.23762 |  0:00:02s\n",
      "epoch 90 | loss: 0.22856 |  0:00:02s\n",
      "epoch 91 | loss: 0.23273 |  0:00:02s\n",
      "epoch 92 | loss: 0.24983 |  0:00:02s\n",
      "epoch 93 | loss: 0.2268  |  0:00:02s\n",
      "epoch 94 | loss: 0.24761 |  0:00:02s\n",
      "epoch 95 | loss: 0.20858 |  0:00:02s\n",
      "epoch 96 | loss: 0.20279 |  0:00:02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97 | loss: 0.22683 |  0:00:02s\n",
      "epoch 98 | loss: 0.18218 |  0:00:02s\n",
      "epoch 99 | loss: 0.19652 |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.172   |  0:00:00s\n",
      "epoch 1  | loss: 0.87257 |  0:00:00s\n",
      "epoch 2  | loss: 0.72271 |  0:00:00s\n",
      "epoch 3  | loss: 0.59716 |  0:00:00s\n",
      "epoch 4  | loss: 0.58759 |  0:00:00s\n",
      "epoch 5  | loss: 0.54999 |  0:00:00s\n",
      "epoch 6  | loss: 0.52267 |  0:00:00s\n",
      "epoch 7  | loss: 0.50586 |  0:00:00s\n",
      "epoch 8  | loss: 0.53501 |  0:00:00s\n",
      "epoch 9  | loss: 0.5138  |  0:00:00s\n",
      "epoch 10 | loss: 0.46964 |  0:00:00s\n",
      "epoch 11 | loss: 0.47103 |  0:00:00s\n",
      "epoch 12 | loss: 0.47663 |  0:00:00s\n",
      "epoch 13 | loss: 0.46633 |  0:00:00s\n",
      "epoch 14 | loss: 0.46759 |  0:00:00s\n",
      "epoch 15 | loss: 0.47242 |  0:00:00s\n",
      "epoch 16 | loss: 0.46326 |  0:00:00s\n",
      "epoch 17 | loss: 0.47814 |  0:00:00s\n",
      "epoch 18 | loss: 0.4524  |  0:00:00s\n",
      "epoch 19 | loss: 0.45614 |  0:00:00s\n",
      "epoch 20 | loss: 0.44831 |  0:00:00s\n",
      "epoch 21 | loss: 0.43327 |  0:00:00s\n",
      "epoch 22 | loss: 0.43669 |  0:00:00s\n",
      "epoch 23 | loss: 0.42128 |  0:00:00s\n",
      "epoch 24 | loss: 0.42517 |  0:00:00s\n",
      "epoch 25 | loss: 0.43652 |  0:00:00s\n",
      "epoch 26 | loss: 0.42528 |  0:00:00s\n",
      "epoch 27 | loss: 0.44626 |  0:00:00s\n",
      "epoch 28 | loss: 0.43488 |  0:00:00s\n",
      "epoch 29 | loss: 0.41419 |  0:00:00s\n",
      "epoch 30 | loss: 0.43397 |  0:00:00s\n",
      "epoch 31 | loss: 0.41853 |  0:00:00s\n",
      "epoch 32 | loss: 0.39019 |  0:00:00s\n",
      "epoch 33 | loss: 0.39228 |  0:00:00s\n",
      "epoch 34 | loss: 0.40414 |  0:00:00s\n",
      "epoch 35 | loss: 0.40901 |  0:00:00s\n",
      "epoch 36 | loss: 0.41295 |  0:00:01s\n",
      "epoch 37 | loss: 0.38397 |  0:00:01s\n",
      "epoch 38 | loss: 0.38971 |  0:00:01s\n",
      "epoch 39 | loss: 0.37889 |  0:00:01s\n",
      "epoch 40 | loss: 0.37944 |  0:00:01s\n",
      "epoch 41 | loss: 0.37587 |  0:00:01s\n",
      "epoch 42 | loss: 0.38779 |  0:00:01s\n",
      "epoch 43 | loss: 0.36684 |  0:00:01s\n",
      "epoch 44 | loss: 0.36749 |  0:00:01s\n",
      "epoch 45 | loss: 0.38396 |  0:00:01s\n",
      "epoch 46 | loss: 0.38052 |  0:00:01s\n",
      "epoch 47 | loss: 0.37179 |  0:00:01s\n",
      "epoch 48 | loss: 0.37207 |  0:00:01s\n",
      "epoch 49 | loss: 0.38119 |  0:00:01s\n",
      "epoch 50 | loss: 0.3419  |  0:00:01s\n",
      "epoch 51 | loss: 0.37838 |  0:00:01s\n",
      "epoch 52 | loss: 0.3608  |  0:00:01s\n",
      "epoch 53 | loss: 0.33984 |  0:00:01s\n",
      "epoch 54 | loss: 0.40529 |  0:00:01s\n",
      "epoch 55 | loss: 0.39285 |  0:00:01s\n",
      "epoch 56 | loss: 0.38676 |  0:00:01s\n",
      "epoch 57 | loss: 0.39796 |  0:00:01s\n",
      "epoch 58 | loss: 0.37233 |  0:00:01s\n",
      "epoch 59 | loss: 0.39523 |  0:00:01s\n",
      "epoch 60 | loss: 0.37365 |  0:00:01s\n",
      "epoch 61 | loss: 0.33806 |  0:00:01s\n",
      "epoch 62 | loss: 0.35049 |  0:00:01s\n",
      "epoch 63 | loss: 0.36524 |  0:00:01s\n",
      "epoch 64 | loss: 0.37956 |  0:00:01s\n",
      "epoch 65 | loss: 0.34517 |  0:00:01s\n",
      "epoch 66 | loss: 0.34907 |  0:00:01s\n",
      "epoch 67 | loss: 0.33224 |  0:00:01s\n",
      "epoch 68 | loss: 0.36308 |  0:00:01s\n",
      "epoch 69 | loss: 0.33432 |  0:00:01s\n",
      "epoch 70 | loss: 0.33935 |  0:00:01s\n",
      "epoch 71 | loss: 0.35262 |  0:00:01s\n",
      "epoch 72 | loss: 0.36906 |  0:00:01s\n",
      "epoch 73 | loss: 0.33283 |  0:00:01s\n",
      "epoch 74 | loss: 0.34692 |  0:00:02s\n",
      "epoch 75 | loss: 0.33497 |  0:00:02s\n",
      "epoch 76 | loss: 0.32485 |  0:00:02s\n",
      "epoch 77 | loss: 0.38049 |  0:00:02s\n",
      "epoch 78 | loss: 0.33075 |  0:00:02s\n",
      "epoch 79 | loss: 0.30275 |  0:00:02s\n",
      "epoch 80 | loss: 0.27    |  0:00:02s\n",
      "epoch 81 | loss: 0.3002  |  0:00:02s\n",
      "epoch 82 | loss: 0.29877 |  0:00:02s\n",
      "epoch 83 | loss: 0.28095 |  0:00:02s\n",
      "epoch 84 | loss: 0.28852 |  0:00:02s\n",
      "epoch 85 | loss: 0.28446 |  0:00:02s\n",
      "epoch 86 | loss: 0.28281 |  0:00:02s\n",
      "epoch 87 | loss: 0.31374 |  0:00:02s\n",
      "epoch 88 | loss: 0.25249 |  0:00:02s\n",
      "epoch 89 | loss: 0.30047 |  0:00:02s\n",
      "epoch 90 | loss: 0.30456 |  0:00:02s\n",
      "epoch 91 | loss: 0.26111 |  0:00:02s\n",
      "epoch 92 | loss: 0.26394 |  0:00:02s\n",
      "epoch 93 | loss: 0.30038 |  0:00:02s\n",
      "epoch 94 | loss: 0.25937 |  0:00:02s\n",
      "epoch 95 | loss: 0.24524 |  0:00:02s\n",
      "epoch 96 | loss: 0.23194 |  0:00:02s\n",
      "epoch 97 | loss: 0.25711 |  0:00:02s\n",
      "epoch 98 | loss: 0.22663 |  0:00:02s\n",
      "epoch 99 | loss: 0.30931 |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.19003 |  0:00:00s\n",
      "epoch 1  | loss: 0.86111 |  0:00:00s\n",
      "epoch 2  | loss: 0.73708 |  0:00:00s\n",
      "epoch 3  | loss: 0.62128 |  0:00:00s\n",
      "epoch 4  | loss: 0.56783 |  0:00:00s\n",
      "epoch 5  | loss: 0.55992 |  0:00:00s\n",
      "epoch 6  | loss: 0.5113  |  0:00:00s\n",
      "epoch 7  | loss: 0.52854 |  0:00:00s\n",
      "epoch 8  | loss: 0.51943 |  0:00:00s\n",
      "epoch 9  | loss: 0.51316 |  0:00:00s\n",
      "epoch 10 | loss: 0.51208 |  0:00:00s\n",
      "epoch 11 | loss: 0.48697 |  0:00:00s\n",
      "epoch 12 | loss: 0.46374 |  0:00:00s\n",
      "epoch 13 | loss: 0.47411 |  0:00:00s\n",
      "epoch 14 | loss: 0.45557 |  0:00:00s\n",
      "epoch 15 | loss: 0.44847 |  0:00:00s\n",
      "epoch 16 | loss: 0.45794 |  0:00:00s\n",
      "epoch 17 | loss: 0.46149 |  0:00:00s\n",
      "epoch 18 | loss: 0.45728 |  0:00:00s\n",
      "epoch 19 | loss: 0.44835 |  0:00:00s\n",
      "epoch 20 | loss: 0.45278 |  0:00:00s\n",
      "epoch 21 | loss: 0.43275 |  0:00:00s\n",
      "epoch 22 | loss: 0.42885 |  0:00:00s\n",
      "epoch 23 | loss: 0.43121 |  0:00:00s\n",
      "epoch 24 | loss: 0.427   |  0:00:00s\n",
      "epoch 25 | loss: 0.42241 |  0:00:00s\n",
      "epoch 26 | loss: 0.40385 |  0:00:00s\n",
      "epoch 27 | loss: 0.41202 |  0:00:00s\n",
      "epoch 28 | loss: 0.39633 |  0:00:00s\n",
      "epoch 29 | loss: 0.38933 |  0:00:00s\n",
      "epoch 30 | loss: 0.38947 |  0:00:00s\n",
      "epoch 31 | loss: 0.38509 |  0:00:00s\n",
      "epoch 32 | loss: 0.38273 |  0:00:00s\n",
      "epoch 33 | loss: 0.3729  |  0:00:00s\n",
      "epoch 34 | loss: 0.34838 |  0:00:00s\n",
      "epoch 35 | loss: 0.37011 |  0:00:00s\n",
      "epoch 36 | loss: 0.35993 |  0:00:00s\n",
      "epoch 37 | loss: 0.33945 |  0:00:00s\n",
      "epoch 38 | loss: 0.32807 |  0:00:00s\n",
      "epoch 39 | loss: 0.34747 |  0:00:01s\n",
      "epoch 40 | loss: 0.32756 |  0:00:01s\n",
      "epoch 41 | loss: 0.32915 |  0:00:01s\n",
      "epoch 42 | loss: 0.33624 |  0:00:01s\n",
      "epoch 43 | loss: 0.34755 |  0:00:01s\n",
      "epoch 44 | loss: 0.31404 |  0:00:01s\n",
      "epoch 45 | loss: 0.28281 |  0:00:01s\n",
      "epoch 46 | loss: 0.29044 |  0:00:01s\n",
      "epoch 47 | loss: 0.29779 |  0:00:01s\n",
      "epoch 48 | loss: 0.304   |  0:00:01s\n",
      "epoch 49 | loss: 0.29374 |  0:00:01s\n",
      "epoch 50 | loss: 0.28543 |  0:00:01s\n",
      "epoch 51 | loss: 0.27183 |  0:00:01s\n",
      "epoch 52 | loss: 0.24324 |  0:00:01s\n",
      "epoch 53 | loss: 0.34645 |  0:00:01s\n",
      "epoch 54 | loss: 0.28923 |  0:00:01s\n",
      "epoch 55 | loss: 0.24524 |  0:00:01s\n",
      "epoch 56 | loss: 0.24727 |  0:00:01s\n",
      "epoch 57 | loss: 0.25774 |  0:00:01s\n",
      "epoch 58 | loss: 0.25462 |  0:00:01s\n",
      "epoch 59 | loss: 0.24069 |  0:00:01s\n",
      "epoch 60 | loss: 0.26004 |  0:00:01s\n",
      "epoch 61 | loss: 0.24425 |  0:00:01s\n",
      "epoch 62 | loss: 0.21591 |  0:00:01s\n",
      "epoch 63 | loss: 0.24243 |  0:00:01s\n",
      "epoch 64 | loss: 0.19968 |  0:00:01s\n",
      "epoch 65 | loss: 0.20195 |  0:00:01s\n",
      "epoch 66 | loss: 0.20581 |  0:00:01s\n",
      "epoch 67 | loss: 0.22016 |  0:00:01s\n",
      "epoch 68 | loss: 0.22727 |  0:00:01s\n",
      "epoch 69 | loss: 0.24704 |  0:00:01s\n",
      "epoch 70 | loss: 0.21211 |  0:00:01s\n",
      "epoch 71 | loss: 0.22932 |  0:00:01s\n",
      "epoch 72 | loss: 0.19976 |  0:00:01s\n",
      "epoch 73 | loss: 0.21894 |  0:00:01s\n",
      "epoch 74 | loss: 0.20452 |  0:00:01s\n",
      "epoch 75 | loss: 0.19866 |  0:00:01s\n",
      "epoch 76 | loss: 0.1881  |  0:00:02s\n",
      "epoch 77 | loss: 0.21606 |  0:00:02s\n",
      "epoch 78 | loss: 0.17196 |  0:00:02s\n",
      "epoch 79 | loss: 0.1979  |  0:00:02s\n",
      "epoch 80 | loss: 0.17165 |  0:00:02s\n",
      "epoch 81 | loss: 0.17635 |  0:00:02s\n",
      "epoch 82 | loss: 0.19885 |  0:00:02s\n",
      "epoch 83 | loss: 0.18997 |  0:00:02s\n",
      "epoch 84 | loss: 0.18154 |  0:00:02s\n",
      "epoch 85 | loss: 0.13617 |  0:00:02s\n",
      "epoch 86 | loss: 0.17535 |  0:00:02s\n",
      "epoch 87 | loss: 0.16368 |  0:00:02s\n",
      "epoch 88 | loss: 0.14634 |  0:00:02s\n",
      "epoch 89 | loss: 0.18064 |  0:00:02s\n",
      "epoch 90 | loss: 0.19833 |  0:00:02s\n",
      "epoch 91 | loss: 0.14206 |  0:00:02s\n",
      "epoch 92 | loss: 0.1841  |  0:00:02s\n",
      "epoch 93 | loss: 0.1926  |  0:00:02s\n",
      "epoch 94 | loss: 0.18616 |  0:00:02s\n",
      "epoch 95 | loss: 0.15922 |  0:00:02s\n",
      "epoch 96 | loss: 0.14895 |  0:00:02s\n",
      "epoch 97 | loss: 0.13135 |  0:00:02s\n",
      "epoch 98 | loss: 0.1475  |  0:00:02s\n",
      "epoch 99 | loss: 0.14313 |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.14642 |  0:00:00s\n",
      "epoch 1  | loss: 0.86413 |  0:00:00s\n",
      "epoch 2  | loss: 0.74577 |  0:00:00s\n",
      "epoch 3  | loss: 0.65344 |  0:00:00s\n",
      "epoch 4  | loss: 0.56946 |  0:00:00s\n",
      "epoch 5  | loss: 0.51978 |  0:00:00s\n",
      "epoch 6  | loss: 0.52582 |  0:00:00s\n",
      "epoch 7  | loss: 0.50681 |  0:00:00s\n",
      "epoch 8  | loss: 0.50682 |  0:00:00s\n",
      "epoch 9  | loss: 0.47199 |  0:00:00s\n",
      "epoch 10 | loss: 0.46646 |  0:00:00s\n",
      "epoch 11 | loss: 0.48818 |  0:00:00s\n",
      "epoch 12 | loss: 0.47448 |  0:00:00s\n",
      "epoch 13 | loss: 0.46412 |  0:00:00s\n",
      "epoch 14 | loss: 0.4651  |  0:00:00s\n",
      "epoch 15 | loss: 0.47844 |  0:00:00s\n",
      "epoch 16 | loss: 0.45069 |  0:00:00s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 | loss: 0.44419 |  0:00:00s\n",
      "epoch 18 | loss: 0.431   |  0:00:00s\n",
      "epoch 19 | loss: 0.44782 |  0:00:00s\n",
      "epoch 20 | loss: 0.4242  |  0:00:00s\n",
      "epoch 21 | loss: 0.44444 |  0:00:00s\n",
      "epoch 22 | loss: 0.44009 |  0:00:00s\n",
      "epoch 23 | loss: 0.42399 |  0:00:00s\n",
      "epoch 24 | loss: 0.42752 |  0:00:00s\n",
      "epoch 25 | loss: 0.42908 |  0:00:00s\n",
      "epoch 26 | loss: 0.40942 |  0:00:00s\n",
      "epoch 27 | loss: 0.39835 |  0:00:00s\n",
      "epoch 28 | loss: 0.40739 |  0:00:00s\n",
      "epoch 29 | loss: 0.38986 |  0:00:00s\n",
      "epoch 30 | loss: 0.3954  |  0:00:00s\n",
      "epoch 31 | loss: 0.38535 |  0:00:00s\n",
      "epoch 32 | loss: 0.3909  |  0:00:00s\n",
      "epoch 33 | loss: 0.37537 |  0:00:00s\n",
      "epoch 34 | loss: 0.39894 |  0:00:00s\n",
      "epoch 35 | loss: 0.38761 |  0:00:00s\n",
      "epoch 36 | loss: 0.34671 |  0:00:00s\n",
      "epoch 37 | loss: 0.37642 |  0:00:01s\n",
      "epoch 38 | loss: 0.36799 |  0:00:01s\n",
      "epoch 39 | loss: 0.37477 |  0:00:01s\n",
      "epoch 40 | loss: 0.35551 |  0:00:01s\n",
      "epoch 41 | loss: 0.3664  |  0:00:01s\n",
      "epoch 42 | loss: 0.37406 |  0:00:01s\n",
      "epoch 43 | loss: 0.34447 |  0:00:01s\n",
      "epoch 44 | loss: 0.35993 |  0:00:01s\n",
      "epoch 45 | loss: 0.34617 |  0:00:01s\n",
      "epoch 46 | loss: 0.34125 |  0:00:01s\n",
      "epoch 47 | loss: 0.33313 |  0:00:01s\n",
      "epoch 48 | loss: 0.33445 |  0:00:01s\n",
      "epoch 49 | loss: 0.34089 |  0:00:01s\n",
      "epoch 50 | loss: 0.32457 |  0:00:01s\n",
      "epoch 51 | loss: 0.32825 |  0:00:01s\n",
      "epoch 52 | loss: 0.32914 |  0:00:01s\n",
      "epoch 53 | loss: 0.30668 |  0:00:01s\n",
      "epoch 54 | loss: 0.29958 |  0:00:01s\n",
      "epoch 55 | loss: 0.31286 |  0:00:01s\n",
      "epoch 56 | loss: 0.29496 |  0:00:01s\n",
      "epoch 57 | loss: 0.29437 |  0:00:01s\n",
      "epoch 58 | loss: 0.26604 |  0:00:01s\n",
      "epoch 59 | loss: 0.29253 |  0:00:01s\n",
      "epoch 60 | loss: 0.31587 |  0:00:01s\n",
      "epoch 61 | loss: 0.31583 |  0:00:01s\n",
      "epoch 62 | loss: 0.27601 |  0:00:01s\n",
      "epoch 63 | loss: 0.30701 |  0:00:01s\n",
      "epoch 64 | loss: 0.28274 |  0:00:01s\n",
      "epoch 65 | loss: 0.27005 |  0:00:01s\n",
      "epoch 66 | loss: 0.27923 |  0:00:01s\n",
      "epoch 67 | loss: 0.34103 |  0:00:01s\n",
      "epoch 68 | loss: 0.29744 |  0:00:01s\n",
      "epoch 69 | loss: 0.28966 |  0:00:01s\n",
      "epoch 70 | loss: 0.27521 |  0:00:01s\n",
      "epoch 71 | loss: 0.27196 |  0:00:01s\n",
      "epoch 72 | loss: 0.24044 |  0:00:01s\n",
      "epoch 73 | loss: 0.25799 |  0:00:01s\n",
      "epoch 74 | loss: 0.27426 |  0:00:01s\n",
      "epoch 75 | loss: 0.2468  |  0:00:02s\n",
      "epoch 76 | loss: 0.22965 |  0:00:02s\n",
      "epoch 77 | loss: 0.24868 |  0:00:02s\n",
      "epoch 78 | loss: 0.25666 |  0:00:02s\n",
      "epoch 79 | loss: 0.23598 |  0:00:02s\n",
      "epoch 80 | loss: 0.28033 |  0:00:02s\n",
      "epoch 81 | loss: 0.21264 |  0:00:02s\n",
      "epoch 82 | loss: 0.23183 |  0:00:02s\n",
      "epoch 83 | loss: 0.23987 |  0:00:02s\n",
      "epoch 84 | loss: 0.2211  |  0:00:02s\n",
      "epoch 85 | loss: 0.23608 |  0:00:02s\n",
      "epoch 86 | loss: 0.22989 |  0:00:02s\n",
      "epoch 87 | loss: 0.25369 |  0:00:02s\n",
      "epoch 88 | loss: 0.2466  |  0:00:02s\n",
      "epoch 89 | loss: 0.22167 |  0:00:02s\n",
      "epoch 90 | loss: 0.25888 |  0:00:02s\n",
      "epoch 91 | loss: 0.25213 |  0:00:02s\n",
      "epoch 92 | loss: 0.22467 |  0:00:02s\n",
      "epoch 93 | loss: 0.24669 |  0:00:02s\n",
      "epoch 94 | loss: 0.2058  |  0:00:02s\n",
      "epoch 95 | loss: 0.26894 |  0:00:02s\n",
      "epoch 96 | loss: 0.24693 |  0:00:02s\n",
      "epoch 97 | loss: 0.24751 |  0:00:02s\n",
      "epoch 98 | loss: 0.23084 |  0:00:02s\n",
      "epoch 99 | loss: 0.26395 |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.1655  |  0:00:00s\n",
      "epoch 1  | loss: 0.8672  |  0:00:00s\n",
      "epoch 2  | loss: 0.69909 |  0:00:00s\n",
      "epoch 3  | loss: 0.57431 |  0:00:00s\n",
      "epoch 4  | loss: 0.57597 |  0:00:00s\n",
      "epoch 5  | loss: 0.5457  |  0:00:00s\n",
      "epoch 6  | loss: 0.50577 |  0:00:00s\n",
      "epoch 7  | loss: 0.49657 |  0:00:00s\n",
      "epoch 8  | loss: 0.49768 |  0:00:00s\n",
      "epoch 9  | loss: 0.4934  |  0:00:00s\n",
      "epoch 10 | loss: 0.49811 |  0:00:00s\n",
      "epoch 11 | loss: 0.47361 |  0:00:00s\n",
      "epoch 12 | loss: 0.50291 |  0:00:00s\n",
      "epoch 13 | loss: 0.45774 |  0:00:00s\n",
      "epoch 14 | loss: 0.4575  |  0:00:00s\n",
      "epoch 15 | loss: 0.47197 |  0:00:00s\n",
      "epoch 16 | loss: 0.47661 |  0:00:00s\n",
      "epoch 17 | loss: 0.4666  |  0:00:00s\n",
      "epoch 18 | loss: 0.4678  |  0:00:00s\n",
      "epoch 19 | loss: 0.46586 |  0:00:00s\n",
      "epoch 20 | loss: 0.46581 |  0:00:00s\n",
      "epoch 21 | loss: 0.45534 |  0:00:00s\n",
      "epoch 22 | loss: 0.44384 |  0:00:00s\n",
      "epoch 23 | loss: 0.45804 |  0:00:00s\n",
      "epoch 24 | loss: 0.4288  |  0:00:00s\n",
      "epoch 25 | loss: 0.44474 |  0:00:00s\n",
      "epoch 26 | loss: 0.44373 |  0:00:00s\n",
      "epoch 27 | loss: 0.39996 |  0:00:00s\n",
      "epoch 28 | loss: 0.41721 |  0:00:00s\n",
      "epoch 29 | loss: 0.42807 |  0:00:00s\n",
      "epoch 30 | loss: 0.40709 |  0:00:00s\n",
      "epoch 31 | loss: 0.42399 |  0:00:00s\n",
      "epoch 32 | loss: 0.42035 |  0:00:00s\n",
      "epoch 33 | loss: 0.43053 |  0:00:00s\n",
      "epoch 34 | loss: 0.43248 |  0:00:00s\n",
      "epoch 35 | loss: 0.37836 |  0:00:00s\n",
      "epoch 36 | loss: 0.38385 |  0:00:00s\n",
      "epoch 37 | loss: 0.39998 |  0:00:00s\n",
      "epoch 38 | loss: 0.39246 |  0:00:01s\n",
      "epoch 39 | loss: 0.40647 |  0:00:01s\n",
      "epoch 40 | loss: 0.37119 |  0:00:01s\n",
      "epoch 41 | loss: 0.36315 |  0:00:01s\n",
      "epoch 42 | loss: 0.39085 |  0:00:01s\n",
      "epoch 43 | loss: 0.37298 |  0:00:01s\n",
      "epoch 44 | loss: 0.35385 |  0:00:01s\n",
      "epoch 45 | loss: 0.3846  |  0:00:01s\n",
      "epoch 46 | loss: 0.39607 |  0:00:01s\n",
      "epoch 47 | loss: 0.34614 |  0:00:01s\n",
      "epoch 48 | loss: 0.364   |  0:00:01s\n",
      "epoch 49 | loss: 0.3404  |  0:00:01s\n",
      "epoch 50 | loss: 0.30759 |  0:00:01s\n",
      "epoch 51 | loss: 0.36454 |  0:00:01s\n",
      "epoch 52 | loss: 0.34682 |  0:00:01s\n",
      "epoch 53 | loss: 0.37115 |  0:00:01s\n",
      "epoch 54 | loss: 0.36397 |  0:00:01s\n",
      "epoch 55 | loss: 0.33369 |  0:00:01s\n",
      "epoch 56 | loss: 0.3288  |  0:00:01s\n",
      "epoch 57 | loss: 0.33764 |  0:00:01s\n",
      "epoch 58 | loss: 0.33875 |  0:00:01s\n",
      "epoch 59 | loss: 0.31245 |  0:00:01s\n",
      "epoch 60 | loss: 0.30833 |  0:00:01s\n",
      "epoch 61 | loss: 0.28487 |  0:00:01s\n",
      "epoch 62 | loss: 0.31389 |  0:00:01s\n",
      "epoch 63 | loss: 0.29917 |  0:00:01s\n",
      "epoch 64 | loss: 0.28244 |  0:00:01s\n",
      "epoch 65 | loss: 0.30388 |  0:00:01s\n",
      "epoch 66 | loss: 0.28894 |  0:00:01s\n",
      "epoch 67 | loss: 0.28818 |  0:00:01s\n",
      "epoch 68 | loss: 0.27286 |  0:00:01s\n",
      "epoch 69 | loss: 0.33303 |  0:00:01s\n",
      "epoch 70 | loss: 0.26215 |  0:00:01s\n",
      "epoch 71 | loss: 0.27891 |  0:00:01s\n",
      "epoch 72 | loss: 0.30405 |  0:00:01s\n",
      "epoch 73 | loss: 0.27103 |  0:00:01s\n",
      "epoch 74 | loss: 0.36362 |  0:00:01s\n",
      "epoch 75 | loss: 0.29668 |  0:00:01s\n",
      "epoch 76 | loss: 0.31276 |  0:00:02s\n",
      "epoch 77 | loss: 0.33391 |  0:00:02s\n",
      "epoch 78 | loss: 0.2848  |  0:00:02s\n",
      "epoch 79 | loss: 0.30412 |  0:00:02s\n",
      "epoch 80 | loss: 0.32658 |  0:00:02s\n",
      "epoch 81 | loss: 0.28155 |  0:00:02s\n",
      "epoch 82 | loss: 0.27337 |  0:00:02s\n",
      "epoch 83 | loss: 0.25268 |  0:00:02s\n",
      "epoch 84 | loss: 0.28155 |  0:00:02s\n",
      "epoch 85 | loss: 0.27916 |  0:00:02s\n",
      "epoch 86 | loss: 0.26305 |  0:00:02s\n",
      "epoch 87 | loss: 0.32476 |  0:00:02s\n",
      "epoch 88 | loss: 0.31804 |  0:00:02s\n",
      "epoch 89 | loss: 0.25516 |  0:00:02s\n",
      "epoch 90 | loss: 0.27187 |  0:00:02s\n",
      "epoch 91 | loss: 0.28157 |  0:00:02s\n",
      "epoch 92 | loss: 0.26365 |  0:00:02s\n",
      "epoch 93 | loss: 0.25217 |  0:00:02s\n",
      "epoch 94 | loss: 0.28509 |  0:00:02s\n",
      "epoch 95 | loss: 0.27422 |  0:00:02s\n",
      "epoch 96 | loss: 0.25686 |  0:00:02s\n",
      "epoch 97 | loss: 0.25293 |  0:00:02s\n",
      "epoch 98 | loss: 0.23866 |  0:00:02s\n",
      "epoch 99 | loss: 0.20942 |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.12065 |  0:00:00s\n",
      "epoch 1  | loss: 0.91151 |  0:00:00s\n",
      "epoch 2  | loss: 0.7971  |  0:00:00s\n",
      "epoch 3  | loss: 0.63182 |  0:00:00s\n",
      "epoch 4  | loss: 0.58296 |  0:00:00s\n",
      "epoch 5  | loss: 0.52933 |  0:00:00s\n",
      "epoch 6  | loss: 0.5146  |  0:00:00s\n",
      "epoch 7  | loss: 0.55408 |  0:00:00s\n",
      "epoch 8  | loss: 0.57887 |  0:00:00s\n",
      "epoch 9  | loss: 0.53027 |  0:00:00s\n",
      "epoch 10 | loss: 0.52414 |  0:00:00s\n",
      "epoch 11 | loss: 0.55427 |  0:00:00s\n",
      "epoch 12 | loss: 0.52662 |  0:00:00s\n",
      "epoch 13 | loss: 0.49908 |  0:00:00s\n",
      "epoch 14 | loss: 0.50488 |  0:00:00s\n",
      "epoch 15 | loss: 0.50701 |  0:00:00s\n",
      "epoch 16 | loss: 0.48666 |  0:00:00s\n",
      "epoch 17 | loss: 0.48666 |  0:00:00s\n",
      "epoch 18 | loss: 0.4833  |  0:00:00s\n",
      "epoch 19 | loss: 0.49976 |  0:00:00s\n",
      "epoch 20 | loss: 0.48664 |  0:00:00s\n",
      "epoch 21 | loss: 0.47302 |  0:00:00s\n",
      "epoch 22 | loss: 0.48351 |  0:00:00s\n",
      "epoch 23 | loss: 0.45851 |  0:00:00s\n",
      "epoch 24 | loss: 0.47386 |  0:00:00s\n",
      "epoch 25 | loss: 0.46303 |  0:00:00s\n",
      "epoch 26 | loss: 0.4519  |  0:00:00s\n",
      "epoch 27 | loss: 0.44301 |  0:00:00s\n",
      "epoch 28 | loss: 0.45075 |  0:00:00s\n",
      "epoch 29 | loss: 0.44665 |  0:00:00s\n",
      "epoch 30 | loss: 0.43682 |  0:00:00s\n",
      "epoch 31 | loss: 0.44623 |  0:00:00s\n",
      "epoch 32 | loss: 0.40429 |  0:00:00s\n",
      "epoch 33 | loss: 0.43717 |  0:00:00s\n",
      "epoch 34 | loss: 0.41144 |  0:00:00s\n",
      "epoch 35 | loss: 0.42102 |  0:00:00s\n",
      "epoch 36 | loss: 0.39965 |  0:00:00s\n",
      "epoch 37 | loss: 0.40966 |  0:00:00s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38 | loss: 0.4047  |  0:00:01s\n",
      "epoch 39 | loss: 0.39923 |  0:00:01s\n",
      "epoch 40 | loss: 0.38749 |  0:00:01s\n",
      "epoch 41 | loss: 0.38736 |  0:00:01s\n",
      "epoch 42 | loss: 0.41259 |  0:00:01s\n",
      "epoch 43 | loss: 0.39071 |  0:00:01s\n",
      "epoch 44 | loss: 0.38804 |  0:00:01s\n",
      "epoch 45 | loss: 0.37909 |  0:00:01s\n",
      "epoch 46 | loss: 0.38868 |  0:00:01s\n",
      "epoch 47 | loss: 0.36714 |  0:00:01s\n",
      "epoch 48 | loss: 0.36451 |  0:00:01s\n",
      "epoch 49 | loss: 0.37248 |  0:00:01s\n",
      "epoch 50 | loss: 0.36943 |  0:00:01s\n",
      "epoch 51 | loss: 0.40854 |  0:00:01s\n",
      "epoch 52 | loss: 0.34882 |  0:00:01s\n",
      "epoch 53 | loss: 0.36423 |  0:00:01s\n",
      "epoch 54 | loss: 0.34542 |  0:00:01s\n",
      "epoch 55 | loss: 0.36567 |  0:00:01s\n",
      "epoch 56 | loss: 0.32572 |  0:00:01s\n",
      "epoch 57 | loss: 0.36903 |  0:00:01s\n",
      "epoch 58 | loss: 0.33391 |  0:00:01s\n",
      "epoch 59 | loss: 0.2989  |  0:00:01s\n",
      "epoch 60 | loss: 0.30131 |  0:00:01s\n",
      "epoch 61 | loss: 0.39298 |  0:00:01s\n",
      "epoch 62 | loss: 0.30661 |  0:00:01s\n",
      "epoch 63 | loss: 0.29269 |  0:00:01s\n",
      "epoch 64 | loss: 0.30603 |  0:00:01s\n",
      "epoch 65 | loss: 0.338   |  0:00:01s\n",
      "epoch 66 | loss: 0.33332 |  0:00:01s\n",
      "epoch 67 | loss: 0.3452  |  0:00:01s\n",
      "epoch 68 | loss: 0.33375 |  0:00:01s\n",
      "epoch 69 | loss: 0.30023 |  0:00:01s\n",
      "epoch 70 | loss: 0.30823 |  0:00:01s\n",
      "epoch 71 | loss: 0.32143 |  0:00:01s\n",
      "epoch 72 | loss: 0.318   |  0:00:01s\n",
      "epoch 73 | loss: 0.29559 |  0:00:01s\n",
      "epoch 74 | loss: 0.28536 |  0:00:02s\n",
      "epoch 75 | loss: 0.26461 |  0:00:02s\n",
      "epoch 76 | loss: 0.26068 |  0:00:02s\n",
      "epoch 77 | loss: 0.32104 |  0:00:02s\n",
      "epoch 78 | loss: 0.28613 |  0:00:02s\n",
      "epoch 79 | loss: 0.25881 |  0:00:02s\n",
      "epoch 80 | loss: 0.25688 |  0:00:02s\n",
      "epoch 81 | loss: 0.28233 |  0:00:02s\n",
      "epoch 82 | loss: 0.26843 |  0:00:02s\n",
      "epoch 83 | loss: 0.25353 |  0:00:02s\n",
      "epoch 84 | loss: 0.28695 |  0:00:02s\n",
      "epoch 85 | loss: 0.27986 |  0:00:02s\n",
      "epoch 86 | loss: 0.25483 |  0:00:02s\n",
      "epoch 87 | loss: 0.26936 |  0:00:02s\n",
      "epoch 88 | loss: 0.25551 |  0:00:02s\n",
      "epoch 89 | loss: 0.24763 |  0:00:02s\n",
      "epoch 90 | loss: 0.23598 |  0:00:02s\n",
      "epoch 91 | loss: 0.27488 |  0:00:02s\n",
      "epoch 92 | loss: 0.24706 |  0:00:02s\n",
      "epoch 93 | loss: 0.2046  |  0:00:02s\n",
      "epoch 94 | loss: 0.2056  |  0:00:02s\n",
      "epoch 95 | loss: 0.20558 |  0:00:02s\n",
      "epoch 96 | loss: 0.27235 |  0:00:02s\n",
      "epoch 97 | loss: 0.33238 |  0:00:02s\n",
      "epoch 98 | loss: 0.23966 |  0:00:02s\n",
      "epoch 99 | loss: 0.23231 |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.14236 |  0:00:00s\n",
      "epoch 1  | loss: 0.84336 |  0:00:00s\n",
      "epoch 2  | loss: 0.6799  |  0:00:00s\n",
      "epoch 3  | loss: 0.5665  |  0:00:00s\n",
      "epoch 4  | loss: 0.53452 |  0:00:00s\n",
      "epoch 5  | loss: 0.50227 |  0:00:00s\n",
      "epoch 6  | loss: 0.51612 |  0:00:00s\n",
      "epoch 7  | loss: 0.50503 |  0:00:00s\n",
      "epoch 8  | loss: 0.51753 |  0:00:00s\n",
      "epoch 9  | loss: 0.49768 |  0:00:00s\n",
      "epoch 10 | loss: 0.48721 |  0:00:00s\n",
      "epoch 11 | loss: 0.46768 |  0:00:00s\n",
      "epoch 12 | loss: 0.44964 |  0:00:00s\n",
      "epoch 13 | loss: 0.46215 |  0:00:00s\n",
      "epoch 14 | loss: 0.44461 |  0:00:00s\n",
      "epoch 15 | loss: 0.44361 |  0:00:00s\n",
      "epoch 16 | loss: 0.44784 |  0:00:00s\n",
      "epoch 17 | loss: 0.44213 |  0:00:00s\n",
      "epoch 18 | loss: 0.43792 |  0:00:00s\n",
      "epoch 19 | loss: 0.44551 |  0:00:00s\n",
      "epoch 20 | loss: 0.43324 |  0:00:00s\n",
      "epoch 21 | loss: 0.45076 |  0:00:00s\n",
      "epoch 22 | loss: 0.44102 |  0:00:00s\n",
      "epoch 23 | loss: 0.44405 |  0:00:00s\n",
      "epoch 24 | loss: 0.42978 |  0:00:00s\n",
      "epoch 25 | loss: 0.44885 |  0:00:00s\n",
      "epoch 26 | loss: 0.39755 |  0:00:00s\n",
      "epoch 27 | loss: 0.44039 |  0:00:00s\n",
      "epoch 28 | loss: 0.39953 |  0:00:00s\n",
      "epoch 29 | loss: 0.40791 |  0:00:00s\n",
      "epoch 30 | loss: 0.40891 |  0:00:00s\n",
      "epoch 31 | loss: 0.41349 |  0:00:00s\n",
      "epoch 32 | loss: 0.39699 |  0:00:00s\n",
      "epoch 33 | loss: 0.3791  |  0:00:00s\n",
      "epoch 34 | loss: 0.37499 |  0:00:00s\n",
      "epoch 35 | loss: 0.38362 |  0:00:00s\n",
      "epoch 36 | loss: 0.38758 |  0:00:00s\n",
      "epoch 37 | loss: 0.39131 |  0:00:01s\n",
      "epoch 38 | loss: 0.36078 |  0:00:01s\n",
      "epoch 39 | loss: 0.37103 |  0:00:01s\n",
      "epoch 40 | loss: 0.34108 |  0:00:01s\n",
      "epoch 41 | loss: 0.3441  |  0:00:01s\n",
      "epoch 42 | loss: 0.34409 |  0:00:01s\n",
      "epoch 43 | loss: 0.32398 |  0:00:01s\n",
      "epoch 44 | loss: 0.3516  |  0:00:01s\n",
      "epoch 45 | loss: 0.32311 |  0:00:01s\n",
      "epoch 46 | loss: 0.31081 |  0:00:01s\n",
      "epoch 47 | loss: 0.3473  |  0:00:01s\n",
      "epoch 48 | loss: 0.31511 |  0:00:01s\n",
      "epoch 49 | loss: 0.32112 |  0:00:01s\n",
      "epoch 50 | loss: 0.31953 |  0:00:01s\n",
      "epoch 51 | loss: 0.28516 |  0:00:01s\n",
      "epoch 52 | loss: 0.33286 |  0:00:01s\n",
      "epoch 53 | loss: 0.31733 |  0:00:01s\n",
      "epoch 54 | loss: 0.29439 |  0:00:01s\n",
      "epoch 55 | loss: 0.302   |  0:00:01s\n",
      "epoch 56 | loss: 0.29741 |  0:00:01s\n",
      "epoch 57 | loss: 0.29843 |  0:00:01s\n",
      "epoch 58 | loss: 0.2714  |  0:00:01s\n",
      "epoch 59 | loss: 0.28082 |  0:00:01s\n",
      "epoch 60 | loss: 0.26567 |  0:00:01s\n",
      "epoch 61 | loss: 0.26398 |  0:00:01s\n",
      "epoch 62 | loss: 0.24425 |  0:00:01s\n",
      "epoch 63 | loss: 0.2861  |  0:00:01s\n",
      "epoch 64 | loss: 0.27003 |  0:00:01s\n",
      "epoch 65 | loss: 0.24617 |  0:00:01s\n",
      "epoch 66 | loss: 0.24331 |  0:00:01s\n",
      "epoch 67 | loss: 0.23185 |  0:00:01s\n",
      "epoch 68 | loss: 0.25137 |  0:00:01s\n",
      "epoch 69 | loss: 0.28114 |  0:00:01s\n",
      "epoch 70 | loss: 0.29879 |  0:00:01s\n",
      "epoch 71 | loss: 0.24932 |  0:00:01s\n",
      "epoch 72 | loss: 0.28181 |  0:00:01s\n",
      "epoch 73 | loss: 0.30245 |  0:00:01s\n",
      "epoch 74 | loss: 0.28657 |  0:00:02s\n",
      "epoch 75 | loss: 0.28603 |  0:00:02s\n",
      "epoch 76 | loss: 0.28883 |  0:00:02s\n",
      "epoch 77 | loss: 0.27804 |  0:00:02s\n",
      "epoch 78 | loss: 0.25438 |  0:00:02s\n",
      "epoch 79 | loss: 0.29675 |  0:00:02s\n",
      "epoch 80 | loss: 0.27683 |  0:00:02s\n",
      "epoch 81 | loss: 0.23962 |  0:00:02s\n",
      "epoch 82 | loss: 0.24014 |  0:00:02s\n",
      "epoch 83 | loss: 0.24484 |  0:00:02s\n",
      "epoch 84 | loss: 0.21953 |  0:00:02s\n",
      "epoch 85 | loss: 0.24533 |  0:00:02s\n",
      "epoch 86 | loss: 0.23809 |  0:00:02s\n",
      "epoch 87 | loss: 0.27921 |  0:00:02s\n",
      "epoch 88 | loss: 0.22942 |  0:00:02s\n",
      "epoch 89 | loss: 0.23213 |  0:00:02s\n",
      "epoch 90 | loss: 0.23952 |  0:00:02s\n",
      "epoch 91 | loss: 0.28385 |  0:00:02s\n",
      "epoch 92 | loss: 0.2306  |  0:00:02s\n",
      "epoch 93 | loss: 0.21669 |  0:00:02s\n",
      "epoch 94 | loss: 0.18263 |  0:00:02s\n",
      "epoch 95 | loss: 0.25046 |  0:00:02s\n",
      "epoch 96 | loss: 0.2212  |  0:00:02s\n",
      "epoch 97 | loss: 0.19673 |  0:00:02s\n",
      "epoch 98 | loss: 0.20683 |  0:00:02s\n",
      "epoch 99 | loss: 0.22145 |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.17999 |  0:00:00s\n",
      "epoch 1  | loss: 0.9133  |  0:00:00s\n",
      "epoch 2  | loss: 0.78409 |  0:00:00s\n",
      "epoch 3  | loss: 0.70066 |  0:00:00s\n",
      "epoch 4  | loss: 0.54941 |  0:00:00s\n",
      "epoch 5  | loss: 0.54785 |  0:00:00s\n",
      "epoch 6  | loss: 0.57269 |  0:00:00s\n",
      "epoch 7  | loss: 0.54003 |  0:00:00s\n",
      "epoch 8  | loss: 0.50537 |  0:00:00s\n",
      "epoch 9  | loss: 0.48702 |  0:00:00s\n",
      "epoch 10 | loss: 0.51199 |  0:00:00s\n",
      "epoch 11 | loss: 0.50925 |  0:00:00s\n",
      "epoch 12 | loss: 0.50561 |  0:00:00s\n",
      "epoch 13 | loss: 0.51083 |  0:00:00s\n",
      "epoch 14 | loss: 0.49443 |  0:00:00s\n",
      "epoch 15 | loss: 0.49369 |  0:00:00s\n",
      "epoch 16 | loss: 0.49352 |  0:00:00s\n",
      "epoch 17 | loss: 0.48098 |  0:00:00s\n",
      "epoch 18 | loss: 0.47266 |  0:00:00s\n",
      "epoch 19 | loss: 0.47284 |  0:00:00s\n",
      "epoch 20 | loss: 0.47435 |  0:00:00s\n",
      "epoch 21 | loss: 0.47607 |  0:00:00s\n",
      "epoch 22 | loss: 0.43773 |  0:00:00s\n",
      "epoch 23 | loss: 0.47548 |  0:00:00s\n",
      "epoch 24 | loss: 0.44782 |  0:00:00s\n",
      "epoch 25 | loss: 0.4612  |  0:00:00s\n",
      "epoch 26 | loss: 0.44555 |  0:00:00s\n",
      "epoch 27 | loss: 0.42668 |  0:00:00s\n",
      "epoch 28 | loss: 0.41964 |  0:00:00s\n",
      "epoch 29 | loss: 0.42022 |  0:00:00s\n",
      "epoch 30 | loss: 0.42956 |  0:00:00s\n",
      "epoch 31 | loss: 0.42526 |  0:00:00s\n",
      "epoch 32 | loss: 0.40473 |  0:00:00s\n",
      "epoch 33 | loss: 0.41514 |  0:00:00s\n",
      "epoch 34 | loss: 0.41458 |  0:00:00s\n",
      "epoch 35 | loss: 0.39197 |  0:00:00s\n",
      "epoch 36 | loss: 0.41301 |  0:00:00s\n",
      "epoch 37 | loss: 0.39018 |  0:00:01s\n",
      "epoch 38 | loss: 0.3949  |  0:00:01s\n",
      "epoch 39 | loss: 0.40221 |  0:00:01s\n",
      "epoch 40 | loss: 0.38341 |  0:00:01s\n",
      "epoch 41 | loss: 0.42331 |  0:00:01s\n",
      "epoch 42 | loss: 0.3866  |  0:00:01s\n",
      "epoch 43 | loss: 0.39205 |  0:00:01s\n",
      "epoch 44 | loss: 0.37618 |  0:00:01s\n",
      "epoch 45 | loss: 0.388   |  0:00:01s\n",
      "epoch 46 | loss: 0.37855 |  0:00:01s\n",
      "epoch 47 | loss: 0.36972 |  0:00:01s\n",
      "epoch 48 | loss: 0.3666  |  0:00:01s\n",
      "epoch 49 | loss: 0.38596 |  0:00:01s\n",
      "epoch 50 | loss: 0.36254 |  0:00:01s\n",
      "epoch 51 | loss: 0.36571 |  0:00:01s\n",
      "epoch 52 | loss: 0.37888 |  0:00:01s\n",
      "epoch 53 | loss: 0.3667  |  0:00:01s\n",
      "epoch 54 | loss: 0.33105 |  0:00:01s\n",
      "epoch 55 | loss: 0.37356 |  0:00:01s\n",
      "epoch 56 | loss: 0.3551  |  0:00:01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57 | loss: 0.3807  |  0:00:01s\n",
      "epoch 58 | loss: 0.35363 |  0:00:01s\n",
      "epoch 59 | loss: 0.3213  |  0:00:01s\n",
      "epoch 60 | loss: 0.35385 |  0:00:01s\n",
      "epoch 61 | loss: 0.31994 |  0:00:01s\n",
      "epoch 62 | loss: 0.33406 |  0:00:01s\n",
      "epoch 63 | loss: 0.3214  |  0:00:01s\n",
      "epoch 64 | loss: 0.30831 |  0:00:01s\n",
      "epoch 65 | loss: 0.35709 |  0:00:01s\n",
      "epoch 66 | loss: 0.30958 |  0:00:01s\n",
      "epoch 67 | loss: 0.29879 |  0:00:01s\n",
      "epoch 68 | loss: 0.32942 |  0:00:01s\n",
      "epoch 69 | loss: 0.29264 |  0:00:01s\n",
      "epoch 70 | loss: 0.29327 |  0:00:01s\n",
      "epoch 71 | loss: 0.26783 |  0:00:01s\n",
      "epoch 72 | loss: 0.30436 |  0:00:01s\n",
      "epoch 73 | loss: 0.35048 |  0:00:01s\n",
      "epoch 74 | loss: 0.31368 |  0:00:01s\n",
      "epoch 75 | loss: 0.33215 |  0:00:02s\n",
      "epoch 76 | loss: 0.30384 |  0:00:02s\n",
      "epoch 77 | loss: 0.3216  |  0:00:02s\n",
      "epoch 78 | loss: 0.29061 |  0:00:02s\n",
      "epoch 79 | loss: 0.3288  |  0:00:02s\n",
      "epoch 80 | loss: 0.30081 |  0:00:02s\n",
      "epoch 81 | loss: 0.32457 |  0:00:02s\n",
      "epoch 82 | loss: 0.3124  |  0:00:02s\n",
      "epoch 83 | loss: 0.25575 |  0:00:02s\n",
      "epoch 84 | loss: 0.28512 |  0:00:02s\n",
      "epoch 85 | loss: 0.25525 |  0:00:02s\n",
      "epoch 86 | loss: 0.28205 |  0:00:02s\n",
      "epoch 87 | loss: 0.29185 |  0:00:02s\n",
      "epoch 88 | loss: 0.33119 |  0:00:02s\n",
      "epoch 89 | loss: 0.3083  |  0:00:02s\n",
      "epoch 90 | loss: 0.27011 |  0:00:02s\n",
      "epoch 91 | loss: 0.24238 |  0:00:02s\n",
      "epoch 92 | loss: 0.29933 |  0:00:02s\n",
      "epoch 93 | loss: 0.30146 |  0:00:02s\n",
      "epoch 94 | loss: 0.29153 |  0:00:02s\n",
      "epoch 95 | loss: 0.29675 |  0:00:02s\n",
      "epoch 96 | loss: 0.30385 |  0:00:02s\n",
      "epoch 97 | loss: 0.2932  |  0:00:02s\n",
      "epoch 98 | loss: 0.26208 |  0:00:02s\n",
      "epoch 99 | loss: 0.26991 |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.1162  |  0:00:00s\n",
      "epoch 1  | loss: 0.84072 |  0:00:00s\n",
      "epoch 2  | loss: 0.67519 |  0:00:00s\n",
      "epoch 3  | loss: 0.60596 |  0:00:00s\n",
      "epoch 4  | loss: 0.54928 |  0:00:00s\n",
      "epoch 5  | loss: 0.5795  |  0:00:00s\n",
      "epoch 6  | loss: 0.55207 |  0:00:00s\n",
      "epoch 7  | loss: 0.53484 |  0:00:00s\n",
      "epoch 8  | loss: 0.53975 |  0:00:00s\n",
      "epoch 9  | loss: 0.54088 |  0:00:00s\n",
      "epoch 10 | loss: 0.55147 |  0:00:00s\n",
      "epoch 11 | loss: 0.56534 |  0:00:00s\n",
      "epoch 12 | loss: 0.50947 |  0:00:00s\n",
      "epoch 13 | loss: 0.51926 |  0:00:00s\n",
      "epoch 14 | loss: 0.49496 |  0:00:00s\n",
      "epoch 15 | loss: 0.46912 |  0:00:00s\n",
      "epoch 16 | loss: 0.48202 |  0:00:00s\n",
      "epoch 17 | loss: 0.46319 |  0:00:00s\n",
      "epoch 18 | loss: 0.46554 |  0:00:00s\n",
      "epoch 19 | loss: 0.45355 |  0:00:00s\n",
      "epoch 20 | loss: 0.44743 |  0:00:00s\n",
      "epoch 21 | loss: 0.4601  |  0:00:00s\n",
      "epoch 22 | loss: 0.44465 |  0:00:00s\n",
      "epoch 23 | loss: 0.45967 |  0:00:00s\n",
      "epoch 24 | loss: 0.44741 |  0:00:00s\n",
      "epoch 25 | loss: 0.46186 |  0:00:00s\n",
      "epoch 26 | loss: 0.43944 |  0:00:00s\n",
      "epoch 27 | loss: 0.43867 |  0:00:00s\n",
      "epoch 28 | loss: 0.43616 |  0:00:00s\n",
      "epoch 29 | loss: 0.41743 |  0:00:00s\n",
      "epoch 30 | loss: 0.42239 |  0:00:00s\n",
      "epoch 31 | loss: 0.40828 |  0:00:00s\n",
      "epoch 32 | loss: 0.41756 |  0:00:00s\n",
      "epoch 33 | loss: 0.41036 |  0:00:00s\n",
      "epoch 34 | loss: 0.41982 |  0:00:00s\n",
      "epoch 35 | loss: 0.39643 |  0:00:00s\n",
      "epoch 36 | loss: 0.39876 |  0:00:00s\n",
      "epoch 37 | loss: 0.39086 |  0:00:00s\n",
      "epoch 38 | loss: 0.38039 |  0:00:01s\n",
      "epoch 39 | loss: 0.39857 |  0:00:01s\n",
      "epoch 40 | loss: 0.40128 |  0:00:01s\n",
      "epoch 41 | loss: 0.3747  |  0:00:01s\n",
      "epoch 42 | loss: 0.37322 |  0:00:01s\n",
      "epoch 43 | loss: 0.37286 |  0:00:01s\n",
      "epoch 44 | loss: 0.35556 |  0:00:01s\n",
      "epoch 45 | loss: 0.35532 |  0:00:01s\n",
      "epoch 46 | loss: 0.36525 |  0:00:01s\n",
      "epoch 47 | loss: 0.35796 |  0:00:01s\n",
      "epoch 48 | loss: 0.36796 |  0:00:01s\n",
      "epoch 49 | loss: 0.34587 |  0:00:01s\n",
      "epoch 50 | loss: 0.36883 |  0:00:01s\n",
      "epoch 51 | loss: 0.33075 |  0:00:01s\n",
      "epoch 52 | loss: 0.30481 |  0:00:01s\n",
      "epoch 53 | loss: 0.33005 |  0:00:01s\n",
      "epoch 54 | loss: 0.3456  |  0:00:01s\n",
      "epoch 55 | loss: 0.32907 |  0:00:01s\n",
      "epoch 56 | loss: 0.30807 |  0:00:01s\n",
      "epoch 57 | loss: 0.33534 |  0:00:01s\n",
      "epoch 58 | loss: 0.30719 |  0:00:01s\n",
      "epoch 59 | loss: 0.32044 |  0:00:01s\n",
      "epoch 60 | loss: 0.28872 |  0:00:01s\n",
      "epoch 61 | loss: 0.30405 |  0:00:01s\n",
      "epoch 62 | loss: 0.30897 |  0:00:01s\n",
      "epoch 63 | loss: 0.33529 |  0:00:01s\n",
      "epoch 64 | loss: 0.32711 |  0:00:01s\n",
      "epoch 65 | loss: 0.30247 |  0:00:01s\n",
      "epoch 66 | loss: 0.28993 |  0:00:01s\n",
      "epoch 67 | loss: 0.28731 |  0:00:01s\n",
      "epoch 68 | loss: 0.29319 |  0:00:01s\n",
      "epoch 69 | loss: 0.30856 |  0:00:01s\n",
      "epoch 70 | loss: 0.31448 |  0:00:01s\n",
      "epoch 71 | loss: 0.27065 |  0:00:01s\n",
      "epoch 72 | loss: 0.26712 |  0:00:01s\n",
      "epoch 73 | loss: 0.25712 |  0:00:01s\n",
      "epoch 74 | loss: 0.26554 |  0:00:01s\n",
      "epoch 75 | loss: 0.28831 |  0:00:02s\n",
      "epoch 76 | loss: 0.27047 |  0:00:02s\n",
      "epoch 77 | loss: 0.26265 |  0:00:02s\n",
      "epoch 78 | loss: 0.28597 |  0:00:02s\n",
      "epoch 79 | loss: 0.25006 |  0:00:02s\n",
      "epoch 80 | loss: 0.3357  |  0:00:02s\n",
      "epoch 81 | loss: 0.27584 |  0:00:02s\n",
      "epoch 82 | loss: 0.29199 |  0:00:02s\n",
      "epoch 83 | loss: 0.26344 |  0:00:02s\n",
      "epoch 84 | loss: 0.27515 |  0:00:02s\n",
      "epoch 85 | loss: 0.2859  |  0:00:02s\n",
      "epoch 86 | loss: 0.26378 |  0:00:02s\n",
      "epoch 87 | loss: 0.24227 |  0:00:02s\n",
      "epoch 88 | loss: 0.25994 |  0:00:02s\n",
      "epoch 89 | loss: 0.26623 |  0:00:02s\n",
      "epoch 90 | loss: 0.23805 |  0:00:02s\n",
      "epoch 91 | loss: 0.27894 |  0:00:02s\n",
      "epoch 92 | loss: 0.21475 |  0:00:02s\n",
      "epoch 93 | loss: 0.2346  |  0:00:02s\n",
      "epoch 94 | loss: 0.26808 |  0:00:02s\n",
      "epoch 95 | loss: 0.27105 |  0:00:02s\n",
      "epoch 96 | loss: 0.2764  |  0:00:02s\n",
      "epoch 97 | loss: 0.2608  |  0:00:02s\n",
      "epoch 98 | loss: 0.26269 |  0:00:02s\n",
      "epoch 99 | loss: 0.25906 |  0:00:02s\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.17748 |  0:00:00s\n",
      "epoch 1  | loss: 0.90022 |  0:00:00s\n",
      "epoch 2  | loss: 0.68898 |  0:00:00s\n",
      "epoch 3  | loss: 0.59976 |  0:00:00s\n",
      "epoch 4  | loss: 0.5678  |  0:00:00s\n",
      "epoch 5  | loss: 0.54481 |  0:00:00s\n",
      "epoch 6  | loss: 0.52721 |  0:00:00s\n",
      "epoch 7  | loss: 0.51684 |  0:00:00s\n",
      "epoch 8  | loss: 0.53649 |  0:00:00s\n",
      "epoch 9  | loss: 0.50583 |  0:00:00s\n",
      "epoch 10 | loss: 0.5093  |  0:00:00s\n",
      "epoch 11 | loss: 0.51385 |  0:00:00s\n",
      "epoch 12 | loss: 0.47444 |  0:00:00s\n",
      "epoch 13 | loss: 0.47342 |  0:00:00s\n",
      "epoch 14 | loss: 0.48048 |  0:00:00s\n",
      "epoch 15 | loss: 0.45001 |  0:00:00s\n",
      "epoch 16 | loss: 0.46785 |  0:00:00s\n",
      "epoch 17 | loss: 0.45273 |  0:00:00s\n",
      "epoch 18 | loss: 0.4648  |  0:00:00s\n",
      "epoch 19 | loss: 0.47355 |  0:00:00s\n",
      "epoch 20 | loss: 0.42579 |  0:00:00s\n",
      "epoch 21 | loss: 0.45811 |  0:00:00s\n",
      "epoch 22 | loss: 0.43715 |  0:00:00s\n",
      "epoch 23 | loss: 0.43483 |  0:00:00s\n",
      "epoch 24 | loss: 0.43673 |  0:00:00s\n",
      "epoch 25 | loss: 0.41016 |  0:00:00s\n",
      "epoch 26 | loss: 0.43227 |  0:00:00s\n",
      "epoch 27 | loss: 0.42326 |  0:00:00s\n",
      "epoch 28 | loss: 0.40937 |  0:00:00s\n",
      "epoch 29 | loss: 0.40205 |  0:00:00s\n",
      "epoch 30 | loss: 0.42    |  0:00:00s\n",
      "epoch 31 | loss: 0.39153 |  0:00:00s\n",
      "epoch 32 | loss: 0.38129 |  0:00:00s\n",
      "epoch 33 | loss: 0.39865 |  0:00:00s\n",
      "epoch 34 | loss: 0.36466 |  0:00:00s\n",
      "epoch 35 | loss: 0.36914 |  0:00:00s\n",
      "epoch 36 | loss: 0.3592  |  0:00:00s\n",
      "epoch 37 | loss: 0.3616  |  0:00:00s\n",
      "epoch 38 | loss: 0.36712 |  0:00:00s\n",
      "epoch 39 | loss: 0.35417 |  0:00:01s\n",
      "epoch 40 | loss: 0.34093 |  0:00:01s\n",
      "epoch 41 | loss: 0.33485 |  0:00:01s\n",
      "epoch 42 | loss: 0.34182 |  0:00:01s\n",
      "epoch 43 | loss: 0.32362 |  0:00:01s\n",
      "epoch 44 | loss: 0.3298  |  0:00:01s\n",
      "epoch 45 | loss: 0.34527 |  0:00:01s\n",
      "epoch 46 | loss: 0.32773 |  0:00:01s\n",
      "epoch 47 | loss: 0.3404  |  0:00:01s\n",
      "epoch 48 | loss: 0.34541 |  0:00:01s\n",
      "epoch 49 | loss: 0.32048 |  0:00:01s\n",
      "epoch 50 | loss: 0.30811 |  0:00:01s\n",
      "epoch 51 | loss: 0.38088 |  0:00:01s\n",
      "epoch 52 | loss: 0.30853 |  0:00:01s\n",
      "epoch 53 | loss: 0.33095 |  0:00:01s\n",
      "epoch 54 | loss: 0.28567 |  0:00:01s\n",
      "epoch 55 | loss: 0.32389 |  0:00:01s\n",
      "epoch 56 | loss: 0.3131  |  0:00:01s\n",
      "epoch 57 | loss: 0.29108 |  0:00:01s\n",
      "epoch 58 | loss: 0.31969 |  0:00:01s\n",
      "epoch 59 | loss: 0.28412 |  0:00:01s\n",
      "epoch 60 | loss: 0.29286 |  0:00:01s\n",
      "epoch 61 | loss: 0.28018 |  0:00:01s\n",
      "epoch 62 | loss: 0.30171 |  0:00:01s\n",
      "epoch 63 | loss: 0.29022 |  0:00:01s\n",
      "epoch 64 | loss: 0.34131 |  0:00:01s\n",
      "epoch 65 | loss: 0.25332 |  0:00:01s\n",
      "epoch 66 | loss: 0.27224 |  0:00:01s\n",
      "epoch 67 | loss: 0.28213 |  0:00:01s\n",
      "epoch 68 | loss: 0.23207 |  0:00:01s\n",
      "epoch 69 | loss: 0.25561 |  0:00:01s\n",
      "epoch 70 | loss: 0.24679 |  0:00:01s\n",
      "epoch 71 | loss: 0.23201 |  0:00:01s\n",
      "epoch 72 | loss: 0.24676 |  0:00:01s\n",
      "epoch 73 | loss: 0.24954 |  0:00:01s\n",
      "epoch 74 | loss: 0.26971 |  0:00:01s\n",
      "epoch 75 | loss: 0.23461 |  0:00:01s\n",
      "epoch 76 | loss: 0.2717  |  0:00:01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77 | loss: 0.23618 |  0:00:01s\n",
      "epoch 78 | loss: 0.27278 |  0:00:02s\n",
      "epoch 79 | loss: 0.25246 |  0:00:02s\n",
      "epoch 80 | loss: 0.22864 |  0:00:02s\n",
      "epoch 81 | loss: 0.24284 |  0:00:02s\n",
      "epoch 82 | loss: 0.22272 |  0:00:02s\n",
      "epoch 83 | loss: 0.24044 |  0:00:02s\n",
      "epoch 84 | loss: 0.24995 |  0:00:02s\n",
      "epoch 85 | loss: 0.2082  |  0:00:02s\n",
      "epoch 86 | loss: 0.21936 |  0:00:02s\n",
      "epoch 87 | loss: 0.21863 |  0:00:02s\n",
      "epoch 88 | loss: 0.24448 |  0:00:02s\n",
      "epoch 89 | loss: 0.25571 |  0:00:02s\n",
      "epoch 90 | loss: 0.21951 |  0:00:02s\n",
      "epoch 91 | loss: 0.19346 |  0:00:02s\n",
      "epoch 92 | loss: 0.24176 |  0:00:02s\n",
      "epoch 93 | loss: 0.26809 |  0:00:02s\n",
      "epoch 94 | loss: 0.20535 |  0:00:02s\n",
      "epoch 95 | loss: 0.20927 |  0:00:02s\n",
      "epoch 96 | loss: 0.19486 |  0:00:02s\n",
      "epoch 97 | loss: 0.18917 |  0:00:02s\n",
      "epoch 98 | loss: 0.19364 |  0:00:02s\n",
      "epoch 99 | loss: 0.22146 |  0:00:02s\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "\n",
    "included_cols = ['CHILD_SEX','IDD_SCORE','AGE','HHID_count','HH_AGE','FOOD_EXPENSE_WEEKLY',\n",
    "                 'NON-FOOD_EXPENSE_WEEKLY','HDD_SCORE','FOOD_INSECURITY','YoungBoys','YoungGirls',\n",
    "                 'AverageMonthlyIncome','BEN_4PS','AREA_TYPE','FOOD_EXPENSE_WEEKLY_pc',\n",
    "                 'NON-FOOD_EXPENSE_WEEKLY_pc','AverageMonthlyIncome_pc']\n",
    "\n",
    "for task in TASKS_TO_RUN:\n",
    "    metric = train_kfold(NUM_FOLDS, task, included_cols, train_tabnet)\n",
    "    metrics[task] = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e53389b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2aii: ACCURACY: 0.7493548387096773 SENSITIVITY: 0.8687692307692307 SPECIFICITY: 0.17333333333333334\n",
      "2aiii: ACCURACY: 0.73247311827957 SENSITIVITY: 0.9034420289855072 SPECIFICITY: 0.10714285714285714\n"
     ]
    }
   ],
   "source": [
    "for task in TASKS_TO_RUN:\n",
    "    print(f'{task}: ACCURACY: {metrics[task][\"ACCURACY\"][\"MEAN\"]} SENSITIVITY: {metrics[task][\"SENSITIVITY\"][\"MEAN\"]} SPECIFICITY: {metrics[task][\"SPECIFICITY\"][\"MEAN\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7decd061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61.29032373428345,\n",
       " 67.7419364452362,\n",
       " 74.19354915618896,\n",
       " 69.9999988079071,\n",
       " 73.33333492279053,\n",
       " 80.0000011920929,\n",
       " 80.0000011920929,\n",
       " 73.33333492279053,\n",
       " 83.33333134651184,\n",
       " 83.33333134651184]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['2aii']['ACCURACY']['ALL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486f6811",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9717ce9",
   "metadata": {},
   "source": [
    "### Note: This runs evaluates the models with the testing set. Run only at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e2577108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(task, included_cols, models):\n",
    "    train_df = pd.read_csv(os.path.join(DATA_DIR, f'{task}_train.csv'), index_col=0)\n",
    "    test_df = pd.read_csv(os.path.join(DATA_DIR, f'{task}_test.csv'), index_col=0)\n",
    "    \n",
    "    # Generate feauture columns\n",
    "    feature_columns = []\n",
    "    for col in included_cols:\n",
    "        feature_columns.append(tf.feature_column.numeric_column(col))\n",
    "\n",
    "    # Generating a tensorflow dataset\n",
    "    train_ds = df_to_dataset(train_df, task)\n",
    "    test_ds = df_to_dataset(test_df, task)\n",
    "\n",
    "    # Building model\n",
    "    models[task] = tf.keras.Sequential([\n",
    "        tf.keras.layers.DenseFeatures(feature_columns),\n",
    "        tf.keras.layers.Dense(14, activation='relu'),\n",
    "        tf.keras.layers.Dense(14, activation='relu'),\n",
    "        tf.keras.layers.Dense(14, activation='relu'),\n",
    "        tf.keras.layers.Dense(14, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    models[task].compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy',\n",
    "                           tf.keras.metrics.TruePositives(),\n",
    "                           tf.keras.metrics.TrueNegatives(),\n",
    "                           tf.keras.metrics.FalsePositives(),\n",
    "                           tf.keras.metrics.FalseNegatives()\n",
    "                          ])\n",
    "\n",
    "    # Fitting Model\n",
    "    history = models[task].fit(train_ds, \n",
    "                        epochs=10, \n",
    "                        verbose=1)\n",
    "\n",
    "    # Evaluate Model\n",
    "    scores = models[task].evaluate(test_ds, verbose=0)\n",
    "    tp, tn, fp, fn = scores[2:]\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "\n",
    "    \n",
    "    metrics = {\n",
    "        'ACCURACY': scores[1]*100,\n",
    "        'SENSITIVITY': sensitivity,\n",
    "        'SPECIFICITY': specificity\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "21bd3e69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CHILD_SEX': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int64>, 'IDD_SCORE': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, 'AGE': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'HHID_count': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=int64>, 'HH_AGE': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'FOOD_EXPENSE_WEEKLY': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'NON-FOOD_EXPENSE_WEEKLY': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'HDD_SCORE': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'FOOD_INSECURITY': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int64>, 'YoungBoys': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float64>, 'YoungGirls': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, 'AverageMonthlyIncome': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'BEN_4PS': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=int64>, 'AREA_TYPE': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'FOOD_EXPENSE_WEEKLY_pc': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'NON-FOOD_EXPENSE_WEEKLY_pc': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, 'AverageMonthlyIncome_pc': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CHILD_SEX': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int64>, 'IDD_SCORE': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, 'AGE': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'HHID_count': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=int64>, 'HH_AGE': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'FOOD_EXPENSE_WEEKLY': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'NON-FOOD_EXPENSE_WEEKLY': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'HDD_SCORE': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'FOOD_INSECURITY': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int64>, 'YoungBoys': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float64>, 'YoungGirls': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, 'AverageMonthlyIncome': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'BEN_4PS': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=int64>, 'AREA_TYPE': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'FOOD_EXPENSE_WEEKLY_pc': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'NON-FOOD_EXPENSE_WEEKLY_pc': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, 'AverageMonthlyIncome_pc': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n",
      "38/38 [==============================] - 1s 8ms/step - loss: 19.6674 - accuracy: 0.7591 - true_positives_50: 225.0000 - true_negatives_25: 5.0000 - false_positives_25: 47.0000 - false_negatives_25: 26.0000  \n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 3.8524 - accuracy: 0.7492 - true_positives_50: 223.0000 - true_negatives_25: 4.0000 - false_positives_25: 48.0000 - false_negatives_25: 28.0000\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 2.4745 - accuracy: 0.7294 - true_positives_50: 217.0000 - true_negatives_25: 4.0000 - false_positives_25: 48.0000 - false_negatives_25: 34.0000\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.6355 - accuracy: 0.7822 - true_positives_50: 231.0000 - true_negatives_25: 6.0000 - false_positives_25: 46.0000 - false_negatives_25: 20.0000\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.5104 - accuracy: 0.7327 - true_positives_50: 217.0000 - true_negatives_25: 5.0000 - false_positives_25: 47.0000 - false_negatives_25: 34.0000\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.3308 - accuracy: 0.7591 - true_positives_50: 226.0000 - true_negatives_25: 4.0000 - false_positives_25: 48.0000 - false_negatives_25: 25.0000\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.6272 - accuracy: 0.7294 - true_positives_50: 214.0000 - true_negatives_25: 7.0000 - false_positives_25: 45.0000 - false_negatives_25: 37.0000\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.1628 - accuracy: 0.7855 - true_positives_50: 231.0000 - true_negatives_25: 7.0000 - false_positives_25: 45.0000 - false_negatives_25: 20.0000\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.1514 - accuracy: 0.7624 - true_positives_50: 217.0000 - true_negatives_25: 14.0000 - false_positives_25: 38.0000 - false_negatives_25: 34.0000\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.4104 - accuracy: 0.7459 - true_positives_50: 217.0000 - true_negatives_25: 9.0000 - false_positives_25: 43.0000 - false_negatives_25: 34.0000\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CHILD_SEX': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int64>, 'IDD_SCORE': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, 'AGE': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'HHID_count': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=int64>, 'HH_AGE': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'FOOD_EXPENSE_WEEKLY': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'NON-FOOD_EXPENSE_WEEKLY': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'HDD_SCORE': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'FOOD_INSECURITY': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int64>, 'YoungBoys': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float64>, 'YoungGirls': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, 'AverageMonthlyIncome': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'BEN_4PS': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=int64>, 'AREA_TYPE': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'FOOD_EXPENSE_WEEKLY_pc': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'NON-FOOD_EXPENSE_WEEKLY_pc': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, 'AverageMonthlyIncome_pc': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CHILD_SEX': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int64>, 'IDD_SCORE': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, 'AGE': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'HHID_count': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=int64>, 'HH_AGE': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'FOOD_EXPENSE_WEEKLY': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'NON-FOOD_EXPENSE_WEEKLY': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'HDD_SCORE': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'FOOD_INSECURITY': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int64>, 'YoungBoys': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float64>, 'YoungGirls': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, 'AverageMonthlyIncome': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'BEN_4PS': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=int64>, 'AREA_TYPE': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'FOOD_EXPENSE_WEEKLY_pc': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'NON-FOOD_EXPENSE_WEEKLY_pc': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, 'AverageMonthlyIncome_pc': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CHILD_SEX': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int64>, 'IDD_SCORE': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, 'AGE': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'HHID_count': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=int64>, 'HH_AGE': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'FOOD_EXPENSE_WEEKLY': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'NON-FOOD_EXPENSE_WEEKLY': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'HDD_SCORE': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'FOOD_INSECURITY': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int64>, 'YoungBoys': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float64>, 'YoungGirls': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, 'AverageMonthlyIncome': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'BEN_4PS': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=int64>, 'AREA_TYPE': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'FOOD_EXPENSE_WEEKLY_pc': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'NON-FOOD_EXPENSE_WEEKLY_pc': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, 'AverageMonthlyIncome_pc': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 7ms/step - loss: 18.4594 - accuracy: 0.7591 - true_positives_51: 228.0000 - true_negatives_26: 2.0000 - false_positives_26: 63.0000 - false_negatives_26: 10.0000 \n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 4.8151 - accuracy: 0.7129 - true_positives_51: 207.0000 - true_negatives_26: 9.0000 - false_positives_26: 56.0000 - false_negatives_26: 31.0000\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 2.0059 - accuracy: 0.6799 - true_positives_51: 190.0000 - true_negatives_26: 16.0000 - false_positives_26: 49.0000 - false_negatives_26: 48.0000\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.4519 - accuracy: 0.6700 - true_positives_51: 184.0000 - true_negatives_26: 19.0000 - false_positives_26: 46.0000 - false_negatives_26: 54.0000\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.8110 - accuracy: 0.7030 - true_positives_51: 208.0000 - true_negatives_26: 5.0000 - false_positives_26: 60.0000 - false_negatives_26: 30.0000\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.0580 - accuracy: 0.7195 - true_positives_51: 210.0000 - true_negatives_26: 8.0000 - false_positives_26: 57.0000 - false_negatives_26: 28.0000\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.1349 - accuracy: 0.6865 - true_positives_51: 202.0000 - true_negatives_26: 6.0000 - false_positives_26: 59.0000 - false_negatives_26: 36.0000\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.9764 - accuracy: 0.6865 - true_positives_51: 201.0000 - true_negatives_26: 7.0000 - false_positives_26: 58.0000 - false_negatives_26: 37.0000\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.9862 - accuracy: 0.6733 - true_positives_51: 200.0000 - true_negatives_26: 4.0000 - false_positives_26: 61.0000 - false_negatives_26: 38.0000\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.9567 - accuracy: 0.6997 - true_positives_51: 206.0000 - true_negatives_26: 6.0000 - false_positives_26: 59.0000 - false_negatives_26: 32.0000\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CHILD_SEX': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int64>, 'IDD_SCORE': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, 'AGE': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'HHID_count': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=int64>, 'HH_AGE': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'FOOD_EXPENSE_WEEKLY': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'NON-FOOD_EXPENSE_WEEKLY': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'HDD_SCORE': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'FOOD_INSECURITY': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int64>, 'YoungBoys': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float64>, 'YoungGirls': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, 'AverageMonthlyIncome': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'BEN_4PS': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=int64>, 'AREA_TYPE': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'FOOD_EXPENSE_WEEKLY_pc': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'NON-FOOD_EXPENSE_WEEKLY_pc': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, 'AverageMonthlyIncome_pc': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "metrics = {}\n",
    "included_cols = ['CHILD_SEX','IDD_SCORE','AGE','HHID_count','HH_AGE','FOOD_EXPENSE_WEEKLY',\n",
    "                 'NON-FOOD_EXPENSE_WEEKLY','HDD_SCORE','FOOD_INSECURITY','YoungBoys','YoungGirls',\n",
    "                 'AverageMonthlyIncome','BEN_4PS','AREA_TYPE','FOOD_EXPENSE_WEEKLY_pc',\n",
    "                 'NON-FOOD_EXPENSE_WEEKLY_pc','AverageMonthlyIncome_pc']\n",
    "\n",
    "for task in TASKS_TO_RUN:\n",
    "    metric = train_and_test(task, included_cols, models)\n",
    "    metrics[task] = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6e5580ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2aii - ACCURACY: 64.68647122383118 SENSITIVITY: 0.7 SPECIFICITY: 0.39622641509433965\n",
      "2aiii - ACCURACY: 74.25742745399475 SENSITIVITY: 0.9079497907949791 SPECIFICITY: 0.125\n"
     ]
    }
   ],
   "source": [
    "for task in TASKS_TO_RUN:\n",
    "    print(f'{task} - ACCURACY: {metrics[task][\"ACCURACY\"]} SENSITIVITY: {metrics[task][\"SENSITIVITY\"]} SPECIFICITY: {metrics[task][\"SPECIFICITY\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bbcb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisPU",
   "language": "python",
   "name": "thesispu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
